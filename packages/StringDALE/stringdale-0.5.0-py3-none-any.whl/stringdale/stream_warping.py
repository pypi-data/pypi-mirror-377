# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/016_event_stream_warping.ipynb.

# %% auto 0
__all__ = ['logger', 'csp_logger', 'int_to_excel_col', 'LabelToVar', 'word_overlap', 'regex', 'Condition', 'TestNode', 'TestCase',
           'parse_test_case', 'SubTrace', 'TraceLog', 'compute_condition_distance', 'compute_node_distance',
           'compute_distances', 'get_possible_assignments', 'get_best_assignment', 'event_stream_warp']

# %% ../nbs/016_event_stream_warping.ipynb 5
import os
import json
from frozendict import frozendict
from collections import defaultdict

from pydantic import BaseModel, ConfigDict, field_validator, Field
from typing import List, Any, Dict, Callable,Set, Optional

import numpy as np
import itertools as it
import re
import asyncio

from constraint import Problem,FunctionConstraint
from bidict import bidict

import logging 
from .core import checkLogs,await_all
from .mappings import access, parse_edge_descriptor


# %% ../nbs/016_event_stream_warping.ipynb 6
logger = logging.getLogger(__name__)

# %% ../nbs/016_event_stream_warping.ipynb 9
def int_to_excel_col(n):
    if n < 0:
        raise ValueError("Number must be non-negative")
    
    result = ""
    n += 1  # Adjust because Excel columns start at 1, not 0
    
    while n > 0:
        n -= 1  # Adjust for 0-based indexing
        result = chr(n % 26 + ord('A')).lower() + result
        n //= 26
        
    return result

# %% ../nbs/016_event_stream_warping.ipynb 11
class LabelToVar():
    def __init__(self):
        self.label_to_var = bidict()
        self.label_to_index = bidict()

    def add_label(self,label:str,idx:int):
        self.label_to_var[label] = int_to_excel_col(idx)
        self.label_to_index[label] = idx

    def get_label(self,col:str) -> str:
        return self.label_to_var.inverse[col]

    def get_index(self,label:str) -> int:
        return self.label_to_index[label]

    def get_col(self,label:str) -> int:
        return self.label_to_var[label]


# %% ../nbs/016_event_stream_warping.ipynb 14
async def word_overlap(result: str, expected: str,**kwargs) -> float:
    """
    Calculate the distance between result and expected strings based on word overlap.
    Returns a value between 0 and 1, where:
    - 0 means perfect match (all words from result are in expected)
    - 1 means no overlap (no words from result are in expected)
    
    Args:
        result (str): The string to check words from
        expected (str): The string to check words against
        
    Returns:
        float: Distance metric between 0 and 1
    """
    if not isinstance(result,str) or not isinstance(expected,str):
        return np.inf
    # Convert both strings to lowercase and split into words
    result_words = set(result.lower().split())
    expected_words = set(expected.lower().split())
    
    # If result is empty, return 1.0 (maximum distance)
    if not result_words:
        return 1.0
    
    # Calculate overlap
    overlap = len(result_words.intersection(expected_words))
    total = len(result_words)
    
    # Calculate distance (1 - percentage)
    distance = 1.0 - (overlap / total)
    
    return distance

# %% ../nbs/016_event_stream_warping.ipynb 16
def regex(out: str, expected: str,mismatch_penalty=1.0,**kwargs) -> float:
    """
    Compare a string against a regex pattern.
    Returns 0 if the regex matches, 1 if it doesn't.
    
    Args:
        out (str): The string to check
        expected (str): The regex pattern to match against
        
    Returns:
        float: 0 if match, 1 if no match
    """
    if not isinstance(expected,str):
        raise ValueError("expected must be a string")
    if not isinstance(out,str):
        return np.inf
    try:
        if re.search(expected, out,flags=re.IGNORECASE) is not None:
            return 0
        return mismatch_penalty
    except Exception:
        return mismatch_penalty


# %% ../nbs/016_event_stream_warping.ipynb 21
from .mappings import parse_accessor

# %% ../nbs/016_event_stream_warping.ipynb 25
from typing import Dict, Any,Optional, Union, List
from pathlib import Path
from pprint import pprint
import yaml

# %% ../nbs/016_event_stream_warping.ipynb 26
class Condition(BaseModel):
    key: str 
    value: Any
    func: Optional[str] = None
    kwargs: Dict[str,Any] = {}
    aggregation: Optional[str] = None
    
    @field_validator('key')
    @classmethod
    def validate_key(cls,v:str):
        try:
            parse_accessor(v)
        except Exception as e:
            raise ValueError(f"Invalid accessor: {v}, {e}") from e
        return v

    @field_validator('aggregation')
    @classmethod
    def validate_aggregation(cls,v:Optional[str]):
        if v is not None:
            if v not in ['min','max','sum','avg']:
                raise ValueError(f"Invalid aggregation: {v}, must be one of min,max,sum,avg")
        return v

class TestNode(BaseModel):
    name: str
    label: Optional[str] = None
    conditions: List[Condition]
    before: Optional[List[str]] = Field(default_factory=list)
    after: Optional[List[str]] = Field(default_factory=list)
    parallel: Optional[bool] = False

class TestCase(BaseModel):
    inputs: List[Any]
    test_nodes: List[TestNode]


def parse_test_case(raw_case):
    if isinstance(raw_case,Path):
        raw_case = raw_case.read_text()
    case_obj = TestCase.model_validate(yaml.safe_load(raw_case))
    for idx,node in enumerate(case_obj.test_nodes):
        if node.label is None:
            node.label = f"{idx}"
    return case_obj

# %% ../nbs/016_event_stream_warping.ipynb 30
# subset of stringdale.Trace that only contains the name and output
# since we only need them for evaluation
class SubTrace(BaseModel):
    model_config = ConfigDict(extra='allow')
    name: str
    output: Any


class TraceLog(BaseModel):
    steps: List[SubTrace]

# %% ../nbs/016_event_stream_warping.ipynb 34
from .core import maybe_await
from collections.abc import Iterable

# %% ../nbs/016_event_stream_warping.ipynb 37
async def compute_condition_distance(trace:SubTrace,condition:Condition,eval_funcs,default_func):
    condition_func = eval_funcs.get(condition.func, eval_funcs[default_func])
    output_sub_value = access(trace.output,condition.key)

    def error_message(e):
        logger.error(f"Error computing distance for:\n"
                        f"trace {trace.name}\n"
                        f"condition function {condition_func}\n"
                        f"with key {condition.key}\n"
                        f"output value {repr(output_sub_value)}\n"
                        f"expected value {repr(condition.value)}\n"
                        f"with error: {e}")


    if condition.aggregation is None:
        try:
            logger.debug(
                f"Computing condition distance for key '{condition.key}' with value '{output_sub_value}'\n"
                f"condition function {condition_func}\n"
                f"args = [{output_sub_value}, {condition.value}]\n"
                f"kwargs = {condition.kwargs}\n"
            )
            condition_distance = await maybe_await(condition_func,args=[output_sub_value, condition.value],kwargs=condition.kwargs)
            logger.debug(f"Condition distance for key '{condition.key}' with value '{output_sub_value}' is {condition_distance}")
            agg_meta = None
        except Exception as e:
            error_message(e)
            return np.inf,output_sub_value,None
    else: # aggregation
        if not isinstance(output_sub_value,Iterable):
            error_message(f"Output sub value is not iterable: {output_sub_value}")
            return np.inf,output_sub_value
        logger.debug(f"Computing condition distance for key '{condition.key}' aggregation '{condition.aggregation}' with value {output_sub_value}")
        sub_condition_tasks = [maybe_await(condition_func,args=[v, condition.value],kwargs=condition.kwargs) for v in output_sub_value]
        distances = await asyncio.gather(*sub_condition_tasks)
        agg_meta = {
            "distances": distances,
            "values": output_sub_value,
        }

        if condition.aggregation == 'min':
            condition_distance = min(distances)
        elif condition.aggregation == 'max':
            condition_distance = max(distances)
        elif condition.aggregation == 'sum':
            condition_distance = sum(distances)
        elif condition.aggregation == 'avg':
            condition_distance = sum(distances) / len(distances)
        else:
            raise ValueError(f"Invalid aggregation: {condition.aggregation}")
    
    return condition_distance,output_sub_value,agg_meta


# %% ../nbs/016_event_stream_warping.ipynb 41
async def compute_node_distance(trace:SubTrace,node:TestNode,eval_funcs,default_func):

    logger.debug(f"Computing distance for trace {trace} and TestNode {node}")
    if not re.search(node.name, trace.name):
        return None,[]
    
    # check if all accessors are in the trace
    for condition in node.conditions:
        try: 
            access(trace.output,condition.key)
        except Exception as e:
            return np.inf, []

    debug_info = []

    distances,values,agg_metas = zip(*await await_all(
        [
            compute_condition_distance(trace,condition,eval_funcs,default_func)
            for condition in node.conditions
        ],
        error_prefix=[
            f"When computing distance for trace {trace.name} and node {node.name}"
            for condition in node.conditions
        ]
    ))

    logger.debug(f"Distances: {distances} values: {values}")
    distance = sum(distances)
    
    debug_info = []

    for condition,condition_distance,value,agg_meta in zip(node.conditions,distances,values,agg_metas):
        debug_info.append({
            "func": condition.func,
            "kwargs": condition.kwargs,
            "expected": condition.value,
            "actual": value,
            "key": condition.key,
            "distance": condition_distance,
            "aggregation": condition.aggregation,
            "agg_meta": agg_meta,
        })
        
    return distance,debug_info


# %% ../nbs/016_event_stream_warping.ipynb 45
async def compute_distances(
    trace_log:TraceLog,
    test_case:TestCase,
    comparisons:Dict[str,Callable],
    default_comparison:Callable,
    ):
    """
    Compute the distance matrix between the traces and the expected traces.

    Args:
        trace_log: TraceLog, the trace log
        test_case: TestCase, the test case
        comparisons: Dict[str,Callable], the comparisons to use for the distance matrix
        default_comparison: Callable, the default comparison to use for the distance matrix
    """
    nodes = test_case.test_nodes
    distances = dict()
    for node in nodes:
        distances[node.label] = dict()
    debug_info = defaultdict(dict)
    
    a_iter = list(it.product(enumerate(trace_log.steps), enumerate(nodes)))
    tasks = [
        compute_node_distance(trace,node,comparisons,default_comparison)
        for (i, trace), (j, node) in a_iter
    ]
    error_prefixes = [
        f"When computing distance for trace {trace.name}(#{i}) and node Test {node.name}(#{j})"
        for (i, trace), (j, node) in a_iter
    ]
    
    distance_list = await await_all(tasks,error_prefixes)

    for ((i, trace), (j, node)), (d,debug) in zip(a_iter, distance_list):
        if not d == None:
            if not d == np.inf:
                distances[node.label][i] = d
            debug_info[node.label][i]={
                'comparisons':debug,
                'distance':d,
                'node_idx':j,
                'trace_idx':i,
                'trace_name':trace.name,
                'node_name':node.name,
                'node_label':node.label,
            }

    return dict(distances),dict(debug_info)
    

# %% ../nbs/016_event_stream_warping.ipynb 51
from collections import defaultdict

# %% ../nbs/016_event_stream_warping.ipynb 52
csp_logger = logging.getLogger(f'{__name__}.csp')

def get_possible_assignments(dist,test_case:TestCase,label_to_var:LabelToVar):
    """
    Gets possible mappings between expected traces and actual traces.
    By building a constraint satisfaction problem and solving it.
    """
    p = Problem()
    csp_logger.debug(
        f"Adding variables for {test_case.test_nodes}\n"
        f"dist: {dist}"
        f"label_to_var: {label_to_var}"
        )


    # TODO if a<b and c is after b and is parallel, we need to deduce that c is bounded by the bound of a

    # we track upper and lower bounds, so that we can deduce the bounds
    #  of parallel nodes by the bounds of the node before them
    lower_bounds = defaultdict(set)
    upper_bounds = defaultdict(set)
    
    for col_idx,node in enumerate(test_case.test_nodes):
        viable_trace_row_nums = list(dist[node.label].keys())
        if not viable_trace_row_nums:
            csp_logger.warning(f"No viable trace row nums for expected trace {node.label}")
            return None, p
        var_name = label_to_var.get_col(node.label)
        p.addVariable(var_name,viable_trace_row_nums)
        csp_logger.debug(f"Adding variable {var_name} with domain {viable_trace_row_nums}")

        explicit_constraints = len(node.before) + len(node.after) > 0
        if explicit_constraints:
            for before_label in node.before:
                before_var_name = label_to_var.get_col(before_label)
                csp_logger.debug(f"Adding constraint {before_var_name} < {var_name}")
                p.addConstraint(f"{var_name} < {before_var_name}")
                lower_bounds[var_name].add(before_var_name)

            for after_label in node.after:
                after_var_name = label_to_var.get_col(after_label)
                csp_logger.debug(f"Adding constraint {var_name} < {after_var_name}")
                p.addConstraint(f"{after_var_name} < {var_name}")
                upper_bounds[var_name].add(after_var_name)
        else:

            if col_idx == 0:
                continue
            
            before_var_name = label_to_var.get_col(test_case.test_nodes[col_idx-1].label)
            if not node.parallel:
                csp_logger.debug(f"Adding constraint {before_var_name} < {var_name}")
                p.addConstraint(f"{before_var_name} < {var_name}")
                lower_bounds[var_name].add(before_var_name)

            if node.parallel:
                # derive the bounds from the bounds of the node before
                for lower_bound in lower_bounds[before_var_name]:
                    csp_logger.debug(f"Adding constraint {lower_bound} < {var_name} (derived from {before_var_name} through parallel node {node.label})")
                    p.addConstraint(f"{lower_bound} < {var_name}")
                    lower_bounds[var_name].add(lower_bound)
                for upper_bound in upper_bounds[before_var_name]:
                    csp_logger.debug(f"Adding constraint {var_name} < {upper_bound} (derived from {before_var_name} through parallel node {node.label})")
                    p.addConstraint(f"{var_name} < {upper_bound}")
                    upper_bounds[var_name].add(upper_bound)
        
    # these solutions use colnames    
    solutions = p.getSolutions()
    # invert the colnames back to labels
    labeled_solutions = set(frozendict({label_to_var.get_label(k):v for k,v in sol.items()}) for sol in solutions)
    return labeled_solutions, p

# %% ../nbs/016_event_stream_warping.ipynb 60
def get_best_assignment(dist_matrix,possible_mappings,label_to_var):
    """
    dist_matrix: np.ndarray
    possible_mappings: list of tuples
    label_to_var: dict
    """
    
    score_per_solution = {}
    for sol in possible_mappings:
        sum_dist = 0
        for expected_label,trace_idx in sol.items():
            sum_dist += dist_matrix[expected_label][trace_idx]
        score_per_solution[sol] = sum_dist

    best_solution =  min(score_per_solution,key=score_per_solution.get)
    best_solution_score = score_per_solution[best_solution]
    return best_solution,best_solution_score

# %% ../nbs/016_event_stream_warping.ipynb 62
async def event_stream_warp(trace_log,test_case,eval_funcs,default_func):
    """
    Perform event stream warping on a trace log and a test case.

    Args:
        trace_log: TraceLog, the trace log to warp
        test_case: TestCase, the test case to warp to
        eval_funcs: Dict[str,Callable], the dictionary of functions to use for evaluation
        default_func: Callable, the default function to use

    Returns:
        best_mapping: Dict[str,int], the best mapping from test_node labels to trace indexes
        best_score: float, the score of the best mapping
        debug_info: List[Dict[str,Any]], debug information for comparisons between all test nodes and all traces
        dist: Dict[str,Dict[int,float]], the distance matrix
        problem: Problem, the constraint satisfaction problem
    """
    label_to_var = LabelToVar()
    for idx,node in enumerate(test_case.test_nodes):
        label_to_var.add_label(node.label,idx)

    dist,debug_info = await compute_distances(trace_log,test_case,eval_funcs,default_func)
    possible_mappings,problem = get_possible_assignments(dist,test_case,label_to_var)
    if not possible_mappings:
        return None, np.inf, debug_info, dist, problem
    best_mapping,best_score = get_best_assignment(dist,possible_mappings,label_to_var)
    return best_mapping, best_score, debug_info, dist, problem



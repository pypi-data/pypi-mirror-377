{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from stringdale.core import get_git_root, load_env, checkLogs\n",
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "load_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import os\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from fastcore.foundation import L\n",
    "import json\n",
    "\n",
    "from collections import defaultdict\n",
    "from singleton_decorator import singleton\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from typing import Optional\n",
    "\n",
    "from joblib import Memory\n",
    "from pathlib import Path\n",
    "\n",
    "from stringdale.core import disk_cache\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from typing import List, Dict, Any, Optional,Literal\n",
    "import uuid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from typing import List, Dict, Any, Optional\n",
    "from openai import OpenAI,AsyncOpenAI\n",
    "from copy import copy,deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import nest_asyncio\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def check_openai_key():\n",
    "    api_key = os.getenv('OPENAI_API_KEY',None)\n",
    "    if not api_key:\n",
    "        raise ValueError('OPENAI_API_KEY is not set')\n",
    "\n",
    "@singleton\n",
    "def openai_client():\n",
    "    check_openai_key()\n",
    "    return OpenAI()\n",
    "\n",
    "@singleton\n",
    "def async_openai_client():\n",
    "    check_openai_key()\n",
    "    return AsyncOpenAI()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@disk_cache.cache\n",
    "async def openai_embed(text, model='text-embedding-3-small'):\n",
    "    response = await async_openai_client().embeddings.create(\n",
    "        input=text,\n",
    "        model=model\n",
    "    )\n",
    "    return np.array(response.data[0].embedding)\n",
    "\n",
    "\n",
    "class OpenAIEmbed():\n",
    "    def __init__(self,model='text-embedding-3-small'):\n",
    "        self.model = model\n",
    "\n",
    "    async def __call__(self,text):\n",
    "        response = await openai_embed(text,model=self.model)\n",
    "        return response\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'OpenAIEmbed(model={self.model})'\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "class CachedEmbeddingFunction(chromadb.utils.embedding_functions.EmbeddingFunction):\n",
    "    def __init__(self,model='text-embedding-3-small'):\n",
    "        self.model = model\n",
    "        \n",
    "    async def _async_call(self, texts):\n",
    "        import asyncio\n",
    "        return await asyncio.gather(*[openai_embed(text, model=self.model) for text in texts])\n",
    "        \n",
    "    def __call__(self, texts):\n",
    "        import asyncio\n",
    "        return asyncio.run(self._async_call(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.00676333, -0.03919632,  0.03417581, ..., -0.01964353,\n",
       "        -0.01937133, -0.02247135])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = CachedEmbeddingFunction()\n",
    "x = c(['hello world'])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ChromaClient:\n",
    "    def __init__(self,persist_path=None,embed_model='text-embedding-3-small'):\n",
    "        \"\"\"Initialize ChromaDB client with a collection name.\n",
    "        \n",
    "        Args:\n",
    "            persist_path: Path to the directory to persist the database to\n",
    "            embed_model: Model to use for embedding\n",
    "        \"\"\"\n",
    "\n",
    "        self.embed_func = CachedEmbeddingFunction(model=embed_model)\n",
    "        \n",
    "        if persist_path:\n",
    "            self.client = chromadb.PersistentClient(path=persist_path,settings=chromadb.Settings(allow_reset=True))\n",
    "        else:\n",
    "            self.client = chromadb.EphemeralClient(settings=chromadb.Settings(allow_reset=True))\n",
    "        # Initialize Chroma with OpenAI embeddings\n",
    "       \n",
    "        current_collection_names = self.list_collections()\n",
    "        self.collections={name:self.client.get_or_create_collection(name=name,embedding_function=self.embed_func) for name in current_collection_names}\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the database\"\"\"\n",
    "        self.client.reset()\n",
    "        self.collections={}\n",
    "        \n",
    "    def add_collection(self,name,distance:Literal['l2','ip','cosine']='l2',metadata=None,exists_ok=False):\n",
    "        \"\"\"Add a collection to the database\n",
    "\n",
    "        Args:\n",
    "            name: Name of the collection to add\n",
    "            distance: Distance metric to use, one of 'l2','ip','cosine'. Default is 'l2'\n",
    "            metadata: Metadata to add to the collection\n",
    "            exists_ok: If True, do not raise an error if the collection already exists\n",
    "        \"\"\"\n",
    "        if name in self.collections:\n",
    "            if exists_ok:\n",
    "                return\n",
    "            raise ValueError(f'Collection {name} already exists')\n",
    "        if metadata is None:\n",
    "            metadata = {}\n",
    "        metadata = {**metadata,**{'\"hnsw:space\"':distance}}\n",
    "        self.collections[name] = self.client.get_or_create_collection(\n",
    "            name=name,\n",
    "            embedding_function=self.embed_func,\n",
    "            metadata=metadata\n",
    "        )\n",
    "\n",
    "    def delete_collection(self,name):\n",
    "        \"\"\"Delete a collection from the database\n",
    "\n",
    "        Args:\n",
    "            name: Name of the collection to delete\n",
    "        \"\"\"\n",
    "        self.client.delete_collection(name)\n",
    "        del self.collections[name]\n",
    "\n",
    "    def list_collections(self):\n",
    "        \"\"\"List all collections in the database\n",
    "\n",
    "        Returns:\n",
    "            List of collection names\n",
    "        \"\"\"\n",
    "        return [col.name for col in self.client.list_collections()]\n",
    "\n",
    "    def embed_texts(self,texts:List[str]):\n",
    "        \"\"\"Embed a list of texts\n",
    "\n",
    "        Args:\n",
    "            texts: List of texts to embed\n",
    "\n",
    "        Returns:\n",
    "            List of embeddings\n",
    "        \"\"\"\n",
    "\n",
    "    def upsert(self,collection_name:str,docs):\n",
    "        \"\"\"Upsert a list of documents into a collection\n",
    "\n",
    "        Args:\n",
    "            collection_name: Name of the collection to upsert into\n",
    "            docs: List of documents to upsert\n",
    "                docs should be a list of dictionaries with a 'text' key, with optional 'id' and 'metadata' keys\n",
    "        \"\"\"\n",
    "        ids = [doc.get('id',str(uuid.uuid4())) for doc in docs]\n",
    "        texts = [doc['text'] for doc in docs]\n",
    "        metadatas = [doc.get('metadata',None) for doc in docs]\n",
    "        embeddings = self.embed_texts(texts)\n",
    "        self.collections[collection_name].add(\n",
    "            ids=ids,\n",
    "            embeddings=embeddings,\n",
    "            documents=texts,\n",
    "            metadatas=metadatas\n",
    "        )\n",
    "        return docs\n",
    "\n",
    "    def query(self,collection_name:str,query:str,k:int=10,threshold:float=None,where:Dict[str,Any]=None,where_document:Dict[str,Any]=None):\n",
    "        \"\"\"Query a collection for documents similar to a query\n",
    "\n",
    "        Args:\n",
    "            collection_name: Name of the collection to query\n",
    "            query: Query to search for\n",
    "            k: Number of results to return\n",
    "            threshold: Threshold for filtering results\n",
    "            where: Filter results by metadata\n",
    "            where_document: Filter results by document text\n",
    "\n",
    "        Returns:\n",
    "            List of results\n",
    "        \"\"\"\n",
    "\n",
    "        raw_results = self.collections[collection_name].query(\n",
    "            query_texts=[query],\n",
    "            n_results=k,\n",
    "            where=where,\n",
    "            where_document=where_document\n",
    "        )\n",
    "        results = [\n",
    "            {'id':id,'text':text,'metadata':metadata,'distance':distance}\n",
    "            for id,text,metadata,distance in zip(raw_results['ids'][0],raw_results['documents'][0],raw_results['metadatas'][0],raw_results['distances'][0])\n",
    "        ]\n",
    "        if threshold is not None:\n",
    "            results = [result for result in results if result['distance'] <= threshold]\n",
    "        return results\n",
    "        # TODO add thresholding\n",
    "\n",
    "\n",
    "    def get(self,collection_name:str,ids:List[str]):\n",
    "        \"\"\"Get a list of documents from a collection\n",
    "\n",
    "        Args:\n",
    "            collection_name: Name of the collection to get from\n",
    "            ids: List of ids to get\n",
    "        \"\"\"\n",
    "        raw_results = self.collections[collection_name].get(ids=ids)\n",
    "        return [\n",
    "            {'id':id,'text':text,'metadata':metadata}\n",
    "            for id,text,metadata in zip(raw_results['ids'],raw_results['documents'],raw_results['metadatas'])\n",
    "        ]\n",
    "    \n",
    "    def delete(self,collection_name:str,ids:List[str]):\n",
    "        \"\"\"Delete a list of documents from a collection\n",
    "\n",
    "        Args:\n",
    "            collection_name: Name of the collection to delete from\n",
    "            ids: List of ids to delete\n",
    "        \"\"\"\n",
    "        self.collections[collection_name].delete(ids=ids)\n",
    "    \n",
    "    def list(self,collection_name:str,k:int=None):\n",
    "        \"\"\"Get a list of documents from a collection\n",
    "\n",
    "        Args:\n",
    "            collection_name: Name of the collection to list\n",
    "            k: Number of results to return\n",
    "        \"\"\"\n",
    "        raw_results = self.collections[collection_name].peek(limit=k)\n",
    "        return [{\n",
    "            'id':id,\n",
    "            'text':text,\n",
    "            'metadata':metadata,\n",
    "            'embedding':embedding\n",
    "        } for id,text,metadata,embedding in\n",
    "        zip(raw_results['ids'],raw_results['documents'],raw_results['metadatas'],raw_results['embeddings'])]\n",
    "\n",
    "    def __deepcopy__(self,memo):\n",
    "        return copy(self)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ChromaClient\n",
    "client = ChromaClient()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.reset()  # Start with a clean state\n",
    "\n",
    "# Test collection management\n",
    "client.add_collection(\"test_collection\")\n",
    "assert \"test_collection\" in client.list_collections(), f\"Collection creation failed, {client.list_collections()}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc1', 'text': 'The quick brown fox jumps over the lazy dog'},\n",
       " {'id': 'doc2', 'text': 'A quick brown fox jumped over the lazy dogs'},\n",
       " {'id': 'doc3', 'text': 'The weather is sunny today'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Test document operations\n",
    "test_docs = [\n",
    "    {\n",
    "        'id': 'doc1',\n",
    "        'text': 'The quick brown fox jumps over the lazy dog',\n",
    "        'metadata': {'type': 'pangram'}\n",
    "    },\n",
    "    {\n",
    "        'id': 'doc2',\n",
    "        'text': 'A quick brown fox jumped over the lazy dogs',\n",
    "        'metadata': {'type': 'variant'}\n",
    "    },\n",
    "    {\n",
    "        'id': 'doc3',\n",
    "        'text': 'The weather is sunny today',\n",
    "        'metadata': {'type': 'weather'}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Test upsert\n",
    "client.upsert(\"test_collection\", test_docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query\n",
    "results = client.query(\"test_collection\", \"fox jumping\", k=2)\n",
    "\n",
    "assert len(results) == 2, \"Query should return 2 results\"\n",
    "assert all('fox' in doc['text'] for doc in results), \"Query results should contain relevant documents\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# query with metadata filtering\n",
    "results = client.query(\"test_collection\", \"fox jumping\",where={'type':'pangram'},k=2)\n",
    "assert len(results) == 1, results\n",
    "assert results[0]['text'] == 'The quick brown fox jumps over the lazy dog'\n",
    "\n",
    "# query with full text search\n",
    "results = client.query(\"test_collection\", \"sunny\",k=2,where_document={\"$contains\":\"fox\"})\n",
    "results\n",
    "assert len(results) == 2, results\n",
    "assert all('fox' in doc['text'] for doc in results), \"Query results should contain relevant documents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc2',\n",
       "  'text': 'A quick brown fox jumped over the lazy dogs',\n",
       "  'metadata': {'type': 'variant'},\n",
       "  'distance': 1.513525366783142}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query with both filters\n",
    "results = client.query(\"test_collection\", \"sunny\",k=2,where_document={\"$contains\":\"fox\"},where={'type':{'$in':['weather','variant']}})\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc1',\n",
       "  'text': 'The quick brown fox jumps over the lazy dog',\n",
       "  'metadata': {'type': 'pangram'}},\n",
       " {'id': 'doc2',\n",
       "  'text': 'A quick brown fox jumped over the lazy dogs',\n",
       "  'metadata': {'type': 'variant'}}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get(\"test_collection\",[\"doc2\",\"doc1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc1',\n",
       "  'text': 'The quick brown fox jumps over the lazy dog',\n",
       "  'metadata': {'type': 'pangram'},\n",
       "  'embedding': array([-0.02083762, -0.01689642, -0.00453628, ...,  0.01019769,\n",
       "         -0.01523149,  0.02468777])},\n",
       " {'id': 'doc2',\n",
       "  'text': 'A quick brown fox jumped over the lazy dogs',\n",
       "  'metadata': {'type': 'variant'},\n",
       "  'embedding': array([-1.61350556e-02,  1.02180371e-03, -6.04663728e-05, ...,\n",
       "          8.89423583e-03, -2.04253849e-02,  1.07899625e-02])},\n",
       " {'id': 'doc3',\n",
       "  'text': 'The weather is sunny today',\n",
       "  'metadata': {'type': 'weather'},\n",
       "  'embedding': array([ 0.01581731, -0.03885713,  0.00716233, ..., -0.02583253,\n",
       "          0.01166436,  0.0264344 ])}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list(\"test_collection\",k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test get\n",
    "doc_get = client.get(\"test_collection\", [\"doc1\"])\n",
    "\n",
    "assert doc_get[0]['id'] == 'doc1', \"Get should return correct document\"\n",
    "assert doc_get[0]['text'] == test_docs[0]['text'], \"Document text should match\"\n",
    "\n",
    "# Test list\n",
    "collection_peek = client.list(\"test_collection\", k=2)\n",
    "assert len(collection_peek) == 2, \"List should return 2 documents\"\n",
    "\n",
    "# Test query\n",
    "results = client.query(\"test_collection\", \"fox jumping\", k=2)\n",
    "assert len(results) == 2, \"Query should return 2 results\"\n",
    "assert all('fox' in result['text'] for result in results), \"Query results should contain relevant documents\"\n",
    "assert all(isinstance(result['distance'], float) for result in results), \"Each result should have a distance score\"\n",
    "assert all(isinstance(result['metadata'], dict) for result in results), \"Each result should have metadata\"\n",
    "\n",
    "# Test delete\n",
    "client.delete(\"test_collection\", [\"doc1\"])\n",
    "remaining_docs = client.list(\"test_collection\")\n",
    "assert \"doc1\" not in [doc['id'] for doc in remaining_docs], \"Document should be deleted\"\n",
    "\n",
    "# Test collection deletion\n",
    "client.delete_collection(\"test_collection\")\n",
    "assert \"test_collection\" not in client.list_collections(), \"Collection deletion failed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test error cases\n",
    "client.add_collection(\"test_collection\")\n",
    "with pytest.raises(ValueError,match=\"Collection test_collection already exists\"):\n",
    "    client.add_collection(\"test_collection\")\n",
    "\n",
    "client.add_collection(\"test_collection\", exists_ok=True)\n",
    "client.delete_collection(\"test_collection\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show here how to create and use an in memory SQL db and configure tables using [SQLModel](https://sqlmodel.tiangolo.com/) Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import sqlalchemy \n",
    "from sqlalchemy import create_engine\n",
    "from sqlmodel import SQLModel, Session, select, Field\n",
    "from typing import Optional\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def temp_sql_db(**kwargs):\n",
    "    \"\"\"\n",
    "    creates and sqlalchemy engine to a shared memory sqlite DB.\n",
    "    Kwargs are passed to to sqlalchemy's create_engine function.\n",
    "    \"\"\"\n",
    "    creator = lambda: sqlite3.connect('file::memory:?cache=shared', uri=True)\n",
    "    engine = create_engine('sqlite:///:memory:', creator=creator,**kwargs)\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = temp_sql_db(echo=False)\n",
    "\n",
    "SQLModel.metadata.clear()\n",
    "\n",
    "class Hero(SQLModel,table=True,extend_existing=True):\n",
    "    id: Optional[int] = Field(default=None,primary_key=True)\n",
    "    name: str\n",
    "    secret_name: str\n",
    "    age: Optional[int] = None\n",
    "\n",
    "SQLModel.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hero(name='Deadpond', id=1, age=None, secret_name='Dive')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_heros(heros:List[Hero]):\n",
    "    with Session(engine) as session:\n",
    "        for hero in heros:\n",
    "            session.merge(hero)\n",
    "        session.commit()\n",
    "\n",
    "merge_heros(\n",
    "    [Hero(id=1,name=\"Deadpond\", secret_name=\"Dive\"),\n",
    "    Hero(id=2,name=\"Spider-Boy\", secret_name=\"Pedro\"),\n",
    "    Hero(id=3,name=\"Rusty-Man\", secret_name=\"Tommy\")])\n",
    "\n",
    "def get_hero(name:str):\n",
    "    with Session(engine) as session:\n",
    "        stmt = select(Hero).where(Hero.name == name)\n",
    "        result = session.exec(stmt).one()\n",
    "        return result\n",
    "\n",
    "get_hero(\"Deadpond\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

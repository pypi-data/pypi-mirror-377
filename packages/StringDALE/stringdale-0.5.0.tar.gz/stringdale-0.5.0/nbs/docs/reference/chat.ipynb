{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of how to implement a LLM based functions, for use in our agent examples.\n",
    "Feel free to look at the source code and fit it for your own usecase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from stringdale.doc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stringdale.chat import Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Chat\n",
       "<p align=\"right\"> <a href=\"None\">source</a> </p>\n",
       "\n",
       "> **Signature:** `Chat(model: Optional[str] = None, messages: Optional[List[Dict[str, str]]] = None, output_schema: Optional[pydantic.main.BaseModel] = None, as_json: Optional[bool] = False, tools: Optional[Dict[str, Callable]] = None, call_function: Optional[bool] = False, choices: Optional[enum.Enum] = None, multi_choice: Optional[bool] = False, seed: Optional[int] = 42, stop: Union[str, List[str], NoneType] = None, log_prompt: bool = False, save_history: bool = False, append_output: bool = False, init_messages: Optional[List[Dict[str, str]]] = None, **kwargs)`\n",
       "\n",
       "A Chat objects the renders a prompt and calls an LLM. Currently supporting openai models.\n",
       "\n",
       "\n",
       "| Parameter | Type | Default | Description |\n",
       "|-----------|------|---------|-------------|\n",
       "| model | typing.Optional[str] | None | OpenAI model name |\n",
       "| messages | typing.Optional[typing.List[typing.Dict[str, str]]] | None | List of message dicts, must have at least a role and content field |\n",
       "| output_schema | typing.Optional[pydantic.main.BaseModel] | None | Optional schema for structured output |\n",
       "| as_json | typing.Optional[bool] | False | Optional boolean to return the response as a json object |\n",
       "| tools | typing.Optional[typing.Dict[str, typing.Callable]] | None | Optional dictionary of tool names and functions that the LLM can decide to call. Causes the content of the responseto be a dict of the form {'name':tool_name,'input':tool_input_dict} |\n",
       "| call_function | typing.Optional[bool] | False | if tools are provided, whether to call the function and save the output in the output field of the response's content |\n",
       "| choices | typing.Optional[enum.Enum] | None | Optional List of choices for multi-choice questions |\n",
       "| multi_choice | typing.Optional[bool] | False | if choices are provided, whether to choose multiple items from the list |\n",
       "| seed | typing.Optional[int] | 42 | Optional seed for random number generation |\n",
       "| stop | typing.Union[str, typing.List[str], NoneType] | None | Optional string or list of strings where the model should stop generating |\n",
       "| save_history | <class 'bool'> | False | Optional boolean to save the history of the chat between calls |\n",
       "| append_output | <class 'bool'> | False | Optional, whether to append the output of the chat to history automatically, default False |\n",
       "| init_messages | typing.Optional[typing.List[typing.Dict[str, str]]] | None | Optional list of messages that are always prepended to messages.Useful for supplying additional messages during calls.Can have template variables that are fed during initialization only.If save_history is True, the init messages are added to the history. |\n",
       "| **kwargs | None | None | Keyword arguments to interpolate into the messages |\n",
       "\n",
       "\n",
       "\n",
       "#### \\_\\_call\\_\\_\n",
       "\n",
       "Format prompt with kwargs and call OpenAI chat.\n",
       "Init parameters such as output_schema, tools, choices, seed, stop, as well as template variables\n",
       "can be set or overridden by kwargs\n",
       "> **Signature:** `Chat.__call__(self, **kwargs) -> Dict[str, Any]`\n",
       "\n",
       "| Parameter | Type | Default | Description |\n",
       "|-----------|------|---------|-------------|\n",
       "| **kwargs | None | None | Values for format string placeholders |\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Chat,methods=['__call__'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chat(model='gpt-4o-mini', required_keys={'text'}, seed=42)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Given a sentence, classify it into one of these topics: science, history, technology, or arts. Choose the single most relevant topic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"{{text}}\"}\n",
    "    ]\n",
    "    \n",
    "topic_classifier = Chat(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    choices = ['science', 'history', 'technology', 'arts'],\n",
    "    seed=42,\n",
    ")\n",
    "topic_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': 'history',\n",
       " 'meta': {'input_tokens': 180, 'output_tokens': 9}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await topic_classifier(text=\"WWII was a global conflict that lasted from 1939 to 1945.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chat(model='gpt-4o-mini', required_keys={'age', 'name'}, output_schema=Person, seed=42)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Person(BaseModel):\n",
    "    first_name: str\n",
    "    last_name: str\n",
    "    date_of_birth: int\n",
    "\n",
    "prompted_llm = Chat(model=\"gpt-4o-mini\", messages=\n",
    "    [   \n",
    "        {\"role\": \"user\", \"content\": \"how old am i? {{name}}, {{age}} years old\"},\n",
    "        # {\"role\": \"assistant\", \"content\": \"Iam {{model_name}}, You are {{name}}, {{age}} years old\"}\n",
    "    ],\n",
    "     output_schema=Person)\n",
    "prompted_llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': Person(first_name='Jake', last_name='', date_of_birth=1993),\n",
       " 'meta': {'input_tokens': 186, 'output_tokens': 26}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await prompted_llm(model_name=\"gpt-4o-mini\", age=30,name=\"Jake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': {'name': 'google_search',\n",
       "  'input': {'query': 'What is the capital of France?'},\n",
       "  'output': 'https://www.google.com/search?q=What_is_the_capital_of_France?'},\n",
       " 'meta': {'input_tokens': 159, 'output_tokens': 20}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def google_search_stub(query:str):\n",
    "    \"\"\"\n",
    "    Search the web for the query\n",
    "    Args:\n",
    "        query: The query to search for\n",
    "    Returns:\n",
    "        The URL of the search results\n",
    "    \"\"\"\n",
    "    return f\"https://www.google.com/search?q={query.replace(' ','_')}\"\n",
    "\n",
    "tools = {'google_search': google_search_stub}\n",
    "\n",
    "google_search = Chat(model=\"gpt-4o-mini\", messages=[{\"role\": \"user\", \"content\": \"{{text}}\"}], tools=tools, call_function=True)\n",
    "res = await google_search(text=\"What is the capital of France?\")\n",
    "assert res['content'] == {'name': 'google_search',\n",
    "  'input': {'query': 'What is the capital of France?'},\n",
    "  'output': 'https://www.google.com/search?q=What_is_the_capital_of_France?'}\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stringdale.chat import image_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### image_to_text\n",
       "\n",
       "<p align=\"right\"> <a href=\"None\">source</a> </p>\n",
       "\n",
       "> **Signature:** `image_to_text(path: str, model: str = 'gpt-4o-mini', url=False)`\n",
       "\n",
       "This function takes an image (either from a local file path or URL) and uses OpenAI's\n",
       "vision model to generate a detailed description of the image contents. The results are\n",
       "cached using disk_cache to avoid redundant API calls.\n",
       "\n",
       "| Parameter | Type | Default | Description |\n",
       "|-----------|------|---------|-------------|\n",
       "| path | <class 'str'> | None | Path to the image file or URL of the image |\n",
       "| model | <class 'str'> | gpt-4o-mini | OpenAI model to use for image analysis. Defaults to \"gpt-4o-mini\". |\n",
       "| url | bool | False | Whether the path is a URL. Defaults to False. |\n",
       "| :Returns: | dict | - | A dictionary containing:<br>- role (str): Always \"assistant\"<br>- content (str): Detailed description of the image<br>- meta (dict): Usage statistics including input and output tokens |\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# since its a memoized function\n",
    "show_doc(image_to_text.func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': \"The image features a close-up of a fox's face, showcasing its distinct features. The fox has a bushy coat with a mix of reddish-brown and cream colors, with a characteristic white patch on its chin. Its ears are pointed and alert, standing upright, with a darker inner lining. The eyes are sharp and focused, exhibiting a golden-brown hue, which stands out against its fur. The background appears soft and blurred, suggesting a natural setting, possibly during golden hour due to the warm, soft light illuminating the fox's fur.\",\n",
       " 'meta': {'input_tokens': 8627, 'output_tokens': 117}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await image_to_text('../../../sample_data/fox.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stringdale.chat import speech_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### speech_to_text\n",
       "\n",
       "<p align=\"right\"> <a href=\"None\">source</a> </p>\n",
       "\n",
       "> **Signature:** `speech_to_text(audio_path: str, model: str = 'whisper-1') -> Dict[str, str]`\n",
       "\n",
       "Extract text from an audio file using OpenAI's Whisper model.\n",
       "\n",
       "\n",
       "| Parameter | Type | Default | Description |\n",
       "|-----------|------|---------|-------------|\n",
       "| audio_path | <class 'str'> | None | Path to the audio file |\n",
       "| model | <class 'str'> | whisper-1 | OpenAI model to use. Defaults to \"whisper-1\". |\n",
       "| :Returns: | typing.Dict[str, str] | - | A dictionary containing:  <br>- role (str): Always \"assistant\"<br>- content (str): Transcribed text from the audio |\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(speech_to_text.func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': \"Look at this, my hands are standing up in my arms, I'm giving myself goosebumps.\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await speech_to_text('../../../sample_data/happy_speech.wav')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

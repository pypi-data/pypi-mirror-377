{
  "instructions": [
    {
      "id": "test_driven_development",
      "version": "1.1.0",
      "tags": ["testing", "tdd", "quality", "validation", "backend"],
      "content": "Write or update tests BEFORE implementing code. Ensure tests pass and never modify tests to satisfy failing code. Create comprehensive test cases before implementation. For backend services, implement Test-Driven Development where tests serve as executable specifications and provide guardrails against regressions. Write comprehensive unit tests first, ensuring they fail initially, then implement code to make tests pass.",
      "metadata": {
        "category": "testing",
        "priority": 10,
        "author": "AgentSpec",
        "created_at": "2024-01-01T00:00:00Z",
        "updated_at": "2024-01-01T00:00:00Z"
      }
    },
    {
      "id": "test_suite",
      "version": "1.1.0",
      "tags": ["testing", "automation", "validation", "quality"],
      "content": "Implement comprehensive test automation with unit, integration, and end-to-end tests organized by feature. Use appropriate testing frameworks and maintain test suites with proper coverage and reliability. Run suite after every change. Create `test` script that shows progress and exits on first failure.",
      "metadata": {
        "category": "testing",
        "priority": 9,
        "author": "AgentSpec",
        "created_at": "2024-01-01T00:00:00Z",
        "updated_at": "2024-01-01T00:00:00Z"
      }
    },
    {
      "id": "test_data_management",
      "version": "1.0.0",
      "tags": ["testing", "data", "fixtures", "mocking"],
      "content": "Create reusable test fixtures and factories for consistent test data. Use mocking and stubbing appropriately. Implement test data cleanup and isolation between tests.",
      "metadata": {
        "category": "testing",
        "priority": 7,
        "author": "AgentSpec",
        "created_at": "2024-01-01T00:00:00Z",
        "updated_at": "2024-01-01T00:00:00Z"
      }
    },
    {
      "id": "performance_testing",
      "version": "1.0.0",
      "tags": ["testing", "performance", "load", "stress"],
      "content": "Implement performance testing with load, stress, and spike tests. Set performance benchmarks and monitor for regressions. Use tools like JMeter, k6, or Artillery for load testing.",
      "metadata": {
        "category": "testing",
        "priority": 6,
        "author": "AgentSpec",
        "created_at": "2024-01-01T00:00:00Z",
        "updated_at": "2024-01-01T00:00:00Z"
      }
    },
    {
      "id": "test_coverage_analysis",
      "version": "1.0.0",
      "tags": ["testing", "coverage", "analysis", "quality"],
      "content": "Maintain high test coverage (80%+) with meaningful tests. Use coverage reports to identify untested code paths. Focus on critical business logic and edge cases rather than just coverage numbers.",
      "metadata": {
        "category": "testing",
        "priority": 8,
        "author": "AgentSpec",
        "created_at": "2024-01-01T00:00:00Z",
        "updated_at": "2024-01-01T00:00:00Z"
      }
    },
    {
      "id": "logical_error_detection",
      "version": "1.0.0",
      "tags": ["testing", "logic-errors", "validation", "quality-assurance"],
      "content": "Focus quality assurance on logical errors rather than syntax errors. Implement deep logical analysis using code reviews focused on edge cases, property-based testing, and scenario testing. The most critical bugs run without crashing but produce incorrect results.",
      "metadata": {
        "category": "testing",
        "priority": 9,
        "author": "Research Integration",
        "created_at": "2024-01-01T00:00:00Z",
        "updated_at": "2024-01-01T00:00:00Z"
      }
    },
    {
      "id": "formal_verification",
      "version": "1.0.0",
      "tags": ["testing", "formal-methods", "correctness", "mission-critical"],
      "content": "For mission-critical applications, explore formal methods for mathematical correctness guarantees. Consider formal specifications, model checking, and theorem proving for critical system components where correctness is paramount.",
      "metadata": {
        "category": "testing",
        "priority": 6,
        "author": "Research Integration",
        "created_at": "2024-01-01T00:00:00Z",
        "updated_at": "2024-01-01T00:00:00Z"
      }
    },
    {
      "id": "code_attribution_verification",
      "version": "1.0.0",
      "tags": ["testing", "verification", "ethics", "attribution"],
      "content": "In academic/research contexts, verify code correctness and ensure it produces reported results. Document code sources and methodologies appropriately. Maintain transparency about code generation methods and validate all functionality claims.",
      "metadata": {
        "category": "testing",
        "priority": 8,
        "author": "Research Integration",
        "created_at": "2024-01-01T00:00:00Z",
        "updated_at": "2024-01-01T00:00:00Z"
      }
    },
    {
      "id": "runtime_validation",
      "version": "1.1.0",
      "tags": ["testing", "browser", "validation", "quality-assurance"],
      "content": "Use browser console logs and automated testing to confirm application loads without errors and all interactions work. Iterate until zero errors remain. Integrate runtime validation with comprehensive quality standards to maintain zero tolerance for errors across the entire development workflow.",
      "metadata": {
        "category": "testing",
        "priority": 8,
        "author": "AgentSpec Consolidated",
        "created_at": "2024-01-01T00:00:00Z",
        "updated_at": "2024-12-15T00:00:00Z"
      }
    }
  ]
}

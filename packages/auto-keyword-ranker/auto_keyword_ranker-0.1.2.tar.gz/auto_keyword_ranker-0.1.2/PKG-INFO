Metadata-Version: 2.4
Name: auto-keyword-ranker
Version: 0.1.2
Summary: Lightweight keyword & keyphrase extraction and ranking using TF-IDF with optional embedding re-ranking.
Author-email: Reya Oberoi <reyaoberoi2005@gmail.com>
License: MIT
Keywords: nlp,keywords,tfidf,embeddings,text
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy>=1.21
Requires-Dist: scikit-learn>=1.0
Provides-Extra: embed
Requires-Dist: sentence-transformers>=2.2; extra == "embed"
Provides-Extra: dev
Requires-Dist: pytest; extra == "dev"
Requires-Dist: build; extra == "dev"
Requires-Dist: twine; extra == "dev"
Dynamic: license-file

# auto-keyword-ranker
[![PyPI version](https://img.shields.io/pypi/v/auto-keyword-ranker)](https://pypi.org/project/auto-keyword-ranker)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

Lightweight Python package to extract and rank the most relevant keywords and keyphrases from text.

**Goal:** One-line call to get ranked keywords for articles, blog posts, or short documents.  
Core approach uses **TF-IDF**; optional re-ranking with **sentence-transformer embeddings**.

---

## Installation

```bash
pip install auto-keyword-ranker



---
Quickstart

```python
from autokeyword import rank_keywords

text = """
Artificial intelligence is transforming industries by enabling new capabilities
such as natural language processing, computer vision, and advanced data analytics.
"""

# Simple TF-IDF keyword ranking
keywords = rank_keywords(text, top_n=5)
print(keywords)


---
Output

A list of (keyword, score) pairs, for example:



```python
[('artificial intelligence', 0.42),
 ('data analytics', 0.33),
 ('natural language processing', 0.29),
 ('computer vision', 0.25),
 ('industries', 0.21)]

---

How It Works
TF-IDF scoring formula:


$$
\mathrm{TF\!-\!IDF}(t,d)=\mathrm{TF}(t,d)\times
\log \frac{N}{1+\mathrm{DF}(t)}
$$


Where:

TF(t, d) – term frequency of term t in document d

DF(t) – number of documents containing term t

N – total number of documents

---
License


[MIT License](LICENSE) © 2025 Reya Oberoi

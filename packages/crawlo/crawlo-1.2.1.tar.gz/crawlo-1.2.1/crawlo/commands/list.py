#!/usr/bin/python
# -*- coding: UTF-8 -*-
"""
# @Time    : 2025-08-31 22:33
# @Author  : crawl-coder
# @Desc    : å‘½ä»¤è¡Œå…¥å£ï¼šcrawlo listï¼Œç”¨äºåˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„çˆ¬è™«
"""
import sys
from pathlib import Path
from importlib import import_module

from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.text import Text
from rich import box

from crawlo.crawler import CrawlerProcess
from crawlo.utils.log import get_logger
from .utils import validate_project_environment, show_error_panel

logger = get_logger(__name__)
console = Console()


def main(args):
    """
    ä¸»å‡½æ•°ï¼šåˆ—å‡ºæ‰€æœ‰å¯ç”¨çˆ¬è™«
    ç”¨æ³•: crawlo list [--json]
    """
    show_json = "--json" in args
    
    # è¿‡æ»¤æ‰å‚æ•°åæ£€æŸ¥æ˜¯å¦æœ‰é¢å¤–å‚æ•°
    filtered_args = [arg for arg in args if not arg.startswith('--')]
    if filtered_args:
        if show_json:
            console.print_json(data={"success": False, "error": "Usage: crawlo list [--json]"})
        else:
            console.print("[bold red]âŒ Error:[/bold red] Usage: [blue]crawlo list[/blue] [--json]")
        return 1

    try:
        # éªŒè¯é¡¹ç›®ç¯å¢ƒ
        is_valid, project_package, error_msg = validate_project_environment()
        if not is_valid:
            if show_json:
                console.print_json(data={"success": False, "error": error_msg})
            else:
                show_error_panel("Not a Crawlo Project", error_msg)
            return 1

        # åˆå§‹åŒ– CrawlerProcess å¹¶åŠ è½½çˆ¬è™«æ¨¡å—
        spider_modules = [f"{project_package}.spiders"]
        process = CrawlerProcess(spider_modules=spider_modules)

        # è·å–æ‰€æœ‰çˆ¬è™«åç§°
        spider_names = process.get_spider_names()
        if not spider_names:
            if show_json:
                console.print_json(data={
                    "success": True, 
                    "spiders": [],
                    "message": "No spiders found in project"
                })
            else:
                console.print(Panel(
                    Text.from_markup(
                        ":envelope_with_arrow: [bold]No spiders found[/bold] in '[cyan]spiders/[/cyan]' directory.\n\n"
                        "[bold]ğŸ’¡ Make sure:[/bold]\n"
                        "  â€¢ Spider classes inherit from [blue]`crawlo.spider.Spider`[/blue]\n"
                        "  â€¢ Each spider has a [green]`name`[/green] attribute\n"
                        "  â€¢ Spiders are imported in [cyan]`spiders/__init__.py`[/cyan] (if using package)"
                    ),
                    title="ğŸ“­ No Spiders Found",
                    border_style="yellow",
                    padding=(1, 2)
                ))
            return 0

        # å‡†å¤‡çˆ¬è™«ä¿¡æ¯
        spider_info = []
        for name in sorted(spider_names):
            spider_cls = process.get_spider_class(name)
            module_name = spider_cls.__module__.replace(f"{project_package}.", "")
            
            # è·å–é¢å¤–ä¿¡æ¯
            start_urls_count = len(getattr(spider_cls, 'start_urls', []))
            allowed_domains = getattr(spider_cls, 'allowed_domains', [])
            custom_settings = getattr(spider_cls, 'custom_settings', {})
            
            spider_info.append({
                "name": name,
                "class": spider_cls.__name__,
                "module": module_name,
                "start_urls_count": start_urls_count,
                "allowed_domains": allowed_domains,
                "has_custom_settings": bool(custom_settings)
            })

        # JSON è¾“å‡º
        if show_json:
            console.print_json(data={
                "success": True,
                "count": len(spider_info),
                "spiders": spider_info
            })
            return 0

        # è¡¨æ ¼è¾“å‡º
        table = Table(
            title=f"ğŸ“‹ Found {len(spider_names)} spider(s)",
            box=box.ROUNDED,
            show_header=True,
            header_style="bold magenta",
            title_style="bold green"
        )
        table.add_column("Name", style="cyan", no_wrap=True)
        table.add_column("Class", style="green")
        table.add_column("Module", style="dim")
        table.add_column("URLs", style="blue", justify="center")
        table.add_column("Domains", style="yellow")
        table.add_column("Custom Settings", style="magenta", justify="center")

        for info in spider_info:
            domains_display = ", ".join(info["allowed_domains"][:2])  # æ˜¾ç¤ºå‰2ä¸ªåŸŸå
            if len(info["allowed_domains"]) > 2:
                domains_display += f" (+{len(info['allowed_domains'])-2})"
            elif not domains_display:
                domains_display = "-"
                
            table.add_row(
                info["name"],
                info["class"],
                info["module"],
                str(info["start_urls_count"]),
                domains_display,
                "âœ“" if info["has_custom_settings"] else "-"
            )

        console.print(table)
        
        # æ˜¾ç¤ºä½¿ç”¨æç¤º
        console.print("\n[bold]ğŸš€ Next steps:[/bold]")
        console.print("  [blue]crawlo run[/blue] <spider_name>    # Run a specific spider")
        console.print("  [blue]crawlo run[/blue] all             # Run all spiders")
        console.print("  [blue]crawlo check[/blue] <spider_name>  # Check spider validity")
        
        return 0

    except Exception as e:
        if show_json:
            console.print_json(data={"success": False, "error": str(e)})
        else:
            console.print(f"[bold red]âŒ Unexpected error:[/bold red] {e}")
        logger.exception("Exception during 'crawlo list'")
        return 1
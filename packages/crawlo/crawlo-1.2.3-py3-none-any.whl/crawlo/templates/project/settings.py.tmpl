# -*- coding: UTF-8 -*-
"""
{{project_name}} é¡¹ç›®é…ç½®æ–‡ä»¶
=============================
åŸºäº Crawlo æ¡†æ¶çš„çˆ¬è™«é¡¹ç›®é…ç½®ã€‚

ğŸ¯ å¿«é€Ÿå¼€å§‹ï¼š

# æ–¹å¼1ï¼šä½¿ç”¨é»˜è®¤å•æœºæ¨¡å¼ï¼ˆæ¨èï¼‰
from crawlo.crawler import CrawlerProcess
process = CrawlerProcess()  # æ— éœ€ä»»ä½•é…ç½®

# æ–¹å¼2ï¼šä½¿ç”¨é…ç½®å·¥å‚
from crawlo.config import CrawloConfig
config = CrawloConfig.standalone()  # å•æœºæ¨¡å¼
config = CrawloConfig.distributed(redis_host='192.168.1.100')  # åˆ†å¸ƒå¼æ¨¡å¼
process = CrawlerProcess(settings=config.to_dict())

# æ–¹å¼3ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡
from crawlo.config import CrawloConfig
config = CrawloConfig.from_env()  # ä»ç¯å¢ƒå˜é‡è¯»å–
"""
import os
from crawlo.config import CrawloConfig

# ============================== é¡¹ç›®åŸºæœ¬ä¿¡æ¯ ==============================
PROJECT_NAME = '{{project_name}}'
VERSION = '1.0.0'

# ============================== è¿è¡Œæ¨¡å¼é€‰æ‹© ==============================

# ğŸ¯ é€‰æ‹©ä¸€ç§é…ç½®æ–¹å¼ï¼š

# æ–¹å¼1ï¼šä½¿ç”¨é…ç½®å·¥å‚ï¼ˆæ¨èï¼‰
# å•æœºæ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
CONFIG = CrawloConfig.standalone(
    concurrency=8,
    download_delay=1.0
)

# åˆ†å¸ƒå¼æ¨¡å¼ï¼ˆå»æ‰æ³¨é‡Šå¹¶ä¿®æ”¹ Redis åœ°å€ï¼‰
# CONFIG = CrawloConfig.distributed(
#     redis_host='127.0.0.1',
#     redis_password='your_password',  # å¦‚æœæœ‰å¯†ç 
#     project_name='{{project_name}}',
#     concurrency=16,
#     download_delay=1.0
# )

# è‡ªåŠ¨æ£€æµ‹æ¨¡å¼
# CONFIG = CrawloConfig.auto(concurrency=12)

# æ–¹å¼2ï¼šä»ç¯å¢ƒå˜é‡è¯»å–ï¼ˆé€‚åˆéƒ¨ç½²ï¼‰
# CONFIG = CrawloConfig.from_env()

# æ–¹å¼3ï¼šä½¿ç”¨é¢„è®¾é…ç½®
# from crawlo.config import Presets
# CONFIG = Presets.development()  # å¼€å‘ç¯å¢ƒ
# CONFIG = Presets.production()   # ç”Ÿäº§ç¯å¢ƒ

# è·å–æœ€ç»ˆé…ç½®
locals().update(CONFIG.to_dict())

# ============================== ç½‘ç»œè¯·æ±‚é…ç½® ==============================

# ä¸‹è½½å™¨é€‰æ‹©ï¼ˆæ¨èä½¿ç”¨ CurlCffiï¼Œæ”¯æŒæµè§ˆå™¨æŒ‡çº¹æ¨¡æ‹Ÿï¼‰
DOWNLOADER = "crawlo.downloader.httpx_downloader.HttpXDownloader"     # HTTP/2 æ”¯æŒ
# DOWNLOADER = "crawlo.downloader.cffi_downloader.CurlCffiDownloader"  # æ”¯æŒæµè§ˆå™¨æŒ‡çº¹
# DOWNLOADER = "crawlo.downloader.aiohttp_downloader.AioHttpDownloader"  # è½»é‡çº§é€‰æ‹©

# è¯·æ±‚è¶…æ—¶ä¸å®‰å…¨
DOWNLOAD_TIMEOUT = 30
VERIFY_SSL = True
USE_SESSION = True

# è¯·æ±‚å»¶è¿Ÿæ§åˆ¶ï¼ˆé˜²åçˆ¬ï¼‰
DOWNLOAD_DELAY = 1.0
RANDOM_RANGE = (0.5, 1.5)
RANDOMNESS = False

# é‡è¯•ç­–ç•¥
MAX_RETRY_TIMES = 3
RETRY_PRIORITY = -1
RETRY_HTTP_CODES = [408, 429, 500, 502, 503, 504, 522, 524]
IGNORE_HTTP_CODES = [403, 404]
ALLOWED_RESPONSE_CODES = []  # ResponseFilterMiddlewareå…è®¸çš„çŠ¶æ€ç 
DENIED_RESPONSE_CODES = []   # ResponseFilterMiddlewareæ‹’ç»çš„çŠ¶æ€ç 

# è¿æ¥æ± é…ç½®
CONNECTION_POOL_LIMIT = 50
DOWNLOAD_MAXSIZE = 10 * 1024 * 1024    # 10MB
DOWNLOAD_WARN_SIZE = 1024 * 1024       # 1MB
DOWNLOAD_RETRY_TIMES = MAX_RETRY_TIMES  # ä¸‹è½½å™¨å†…éƒ¨é‡è¯•æ¬¡æ•°ï¼ˆå¤ç”¨å…¨å±€ï¼‰

# ä¸‹è½½ç»Ÿè®¡é…ç½®
DOWNLOADER_STATS = True  # æ˜¯å¦å¯ç”¨ä¸‹è½½å™¨ç»Ÿè®¡åŠŸèƒ½
DOWNLOAD_STATS = True  # æ˜¯å¦è®°å½•ä¸‹è½½æ—¶é—´å’Œå¤§å°ç»Ÿè®¡

# ============================== å¹¶å‘ä¸è°ƒåº¦é…ç½® ==============================

CONCURRENCY = 8
INTERVAL = 5
DEPTH_PRIORITY = 1
MAX_RUNNING_SPIDERS = 3

# è¿è¡Œæ¨¡å¼é€‰æ‹©ï¼š'standalone'(å•æœº), 'distributed'(åˆ†å¸ƒå¼), 'auto'(è‡ªåŠ¨æ£€æµ‹)
RUN_MODE = 'standalone'  # é»˜è®¤å•æœºæ¨¡å¼ï¼Œç®€å•æ˜“ç”¨

# ============================== é˜Ÿåˆ—é…ç½®ï¼ˆæ”¯æŒåˆ†å¸ƒå¼ï¼‰ ==============================

# é˜Ÿåˆ—ç±»å‹ï¼š'auto'ï¼ˆè‡ªåŠ¨é€‰æ‹©ï¼‰, 'memory'ï¼ˆå†…å­˜é˜Ÿåˆ—ï¼‰, 'redis'ï¼ˆåˆ†å¸ƒå¼é˜Ÿåˆ—ï¼‰
QUEUE_TYPE = 'memory'
SCHEDULER_MAX_QUEUE_SIZE = 2000
SCHEDULER_QUEUE_NAME = f'crawlo:{{project_name}}:queue:requests'  # ä½¿ç”¨ç»Ÿä¸€å‘½åè§„èŒƒ
QUEUE_MAX_RETRIES = 3
QUEUE_TIMEOUT = 300

# å¤§è§„æ¨¡çˆ¬å–ä¼˜åŒ–
LARGE_SCALE_BATCH_SIZE = 1000  # æ‰¹å¤„ç†å¤§å°
LARGE_SCALE_CHECKPOINT_INTERVAL = 5000  # è¿›åº¦ä¿å­˜é—´éš”
LARGE_SCALE_MAX_MEMORY_USAGE = 500  # æœ€å¤§å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰

# ============================== æ•°æ®å­˜å‚¨é…ç½® ==============================

# --- MySQL é…ç½® ---
MYSQL_HOST = os.getenv('MYSQL_HOST', '127.0.0.1')
MYSQL_PORT = int(os.getenv('MYSQL_PORT', 3306))
MYSQL_USER = os.getenv('MYSQL_USER', 'root')
MYSQL_PASSWORD = os.getenv('MYSQL_PASSWORD', '123456')
MYSQL_DB = os.getenv('MYSQL_DB', '{{project_name}}')
MYSQL_TABLE = '{{project_name}}_data'
MYSQL_BATCH_SIZE = 100
MYSQL_USE_BATCH = False  # æ˜¯å¦å¯ç”¨æ‰¹é‡æ’å…¥

# --- MongoDB é…ç½® ---
MONGO_URI = os.getenv('MONGO_URI', 'mongodb://localhost:27017')
MONGO_DATABASE = '{{project_name}}_db'
MONGO_COLLECTION = '{{project_name}}_items'
MONGO_MAX_POOL_SIZE = 200
MONGO_MIN_POOL_SIZE = 20
MONGO_BATCH_SIZE = 100  # æ‰¹é‡æ’å…¥æ¡æ•°
MONGO_USE_BATCH = False  # æ˜¯å¦å¯ç”¨æ‰¹é‡æ’å…¥

# ============================== å»é‡è¿‡æ»¤é…ç½® ==============================

REQUEST_DIR = '.'

# æ ¹æ®è¿è¡Œæ¨¡å¼è‡ªåŠ¨é€‰æ‹©å»é‡ç®¡é“
if RUN_MODE == 'distributed':
    # åˆ†å¸ƒå¼æ¨¡å¼ä¸‹é»˜è®¤ä½¿ç”¨Rediså»é‡ç®¡é“
    DEFAULT_DEDUP_PIPELINE = 'crawlo.pipelines.redis_dedup_pipeline.RedisDedupPipeline'
else:
    # å•æœºæ¨¡å¼ä¸‹é»˜è®¤ä½¿ç”¨å†…å­˜å»é‡ç®¡é“
    DEFAULT_DEDUP_PIPELINE = 'crawlo.pipelines.memory_dedup_pipeline.MemoryDedupPipeline'

# å»é‡è¿‡æ»¤å™¨ï¼ˆæ¨èåˆ†å¸ƒå¼é¡¹ç›®ä½¿ç”¨ Redis è¿‡æ»¤å™¨ï¼‰
FILTER_CLASS = 'crawlo.filters.memory_filter.MemoryFilter'

# --- Redis é…ç½®ï¼ˆç”¨äºåˆ†å¸ƒå¼å»é‡å’Œé˜Ÿåˆ—ï¼‰ ---
REDIS_HOST = os.getenv('REDIS_HOST', '127.0.0.1')
REDIS_PORT = int(os.getenv('REDIS_PORT', 6379))
REDIS_PASSWORD = os.getenv('REDIS_PASSWORD', '')

# æ ¹æ®æ˜¯å¦æœ‰å¯†ç ç”Ÿæˆ URL
if REDIS_PASSWORD:
    REDIS_URL = f'redis://:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}/0'
else:
    REDIS_URL = f'redis://{REDIS_HOST}:{REDIS_PORT}/0'

# Redis keyé…ç½®å·²ç§»è‡³å„ç»„ä»¶ä¸­ï¼Œä½¿ç”¨ç»Ÿä¸€çš„å‘½åè§„èŒƒ
# crawlo:{project_name}:filter:fingerprint (è¯·æ±‚å»é‡)
# crawlo:{project_name}:item:fingerprint (æ•°æ®é¡¹å»é‡)
# crawlo:{project_name}:queue:requests (è¯·æ±‚é˜Ÿåˆ—)
# crawlo:{project_name}:queue:processing (å¤„ç†ä¸­é˜Ÿåˆ—)
# crawlo:{project_name}:queue:failed (å¤±è´¥é˜Ÿåˆ—)

REDIS_TTL = 0
CLEANUP_FP = 0
FILTER_DEBUG = True
DECODE_RESPONSES = True

# ============================== ä¸­é—´ä»¶é…ç½® ==============================

MIDDLEWARES = [
    # === è¯·æ±‚é¢„å¤„ç†é˜¶æ®µ ===
    'crawlo.middleware.request_ignore.RequestIgnoreMiddleware',
    'crawlo.middleware.download_delay.DownloadDelayMiddleware',
    'crawlo.middleware.default_header.DefaultHeaderMiddleware',
    'crawlo.middleware.proxy.ProxyMiddleware',
    'crawlo.middleware.offsite.OffsiteMiddleware', 
    
    # === å“åº”å¤„ç†é˜¶æ®µ ===
    'crawlo.middleware.retry.RetryMiddleware',
    'crawlo.middleware.response_code.ResponseCodeMiddleware',
    'crawlo.middleware.response_filter.ResponseFilterMiddleware',
]

# ============================== æ•°æ®ç®¡é“é…ç½® ==============================

# æ•°æ®å¤„ç†ç®¡é“ï¼ˆå¯ç”¨çš„å­˜å‚¨æ–¹å¼ï¼‰
PIPELINES = [
    'crawlo.pipelines.console_pipeline.ConsolePipeline',
    # '{{project_name}}.pipelines.DatabasePipeline',        # è‡ªå®šä¹‰æ•°æ®åº“ç®¡é“
    # 'crawlo.pipelines.mysql_pipeline.AsyncmyMySQLPipeline',  # MySQL å­˜å‚¨
    # 'crawlo.pipelines.mongo_pipeline.MongoPipeline',      # MongoDB å­˜å‚¨
]

# æ ¹æ®è¿è¡Œæ¨¡å¼è‡ªåŠ¨é…ç½®é»˜è®¤å»é‡ç®¡é“
if RUN_MODE == 'distributed':
    # åˆ†å¸ƒå¼æ¨¡å¼ä¸‹æ·»åŠ Rediså»é‡ç®¡é“
    PIPELINES.insert(0, DEFAULT_DEDUP_PIPELINE)
else:
    # å•æœºæ¨¡å¼ä¸‹æ·»åŠ å†…å­˜å»é‡ç®¡é“
    PIPELINES.insert(0, DEFAULT_DEDUP_PIPELINE)

# ============================== æ‰©å±•ç»„ä»¶ ==============================

EXTENSIONS = [
    'crawlo.extension.log_interval.LogIntervalExtension',
    'crawlo.extension.log_stats.LogStats',
    'crawlo.extension.logging_extension.CustomLoggerExtension',
    # 'crawlo.extension.memory_monitor.MemoryMonitorExtension',  # å†…å­˜ç›‘æ§
    # 'crawlo.extension.request_recorder.RequestRecorderExtension',  # è¯·æ±‚è®°å½•
    # 'crawlo.extension.performance_profiler.PerformanceProfilerExtension',  # æ€§èƒ½åˆ†æ
    # 'crawlo.extension.health_check.HealthCheckExtension',  # å¥åº·æ£€æŸ¥
]

# ============================== æ‰©å±•é…ç½® ==============================

# å†…å­˜ç›‘æ§æ‰©å±•é…ç½®
# MEMORY_MONITOR_ENABLED = True  # æ˜¯å¦å¯ç”¨å†…å­˜ç›‘æ§
# MEMORY_MONITOR_INTERVAL = 60  # å†…å­˜æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
# MEMORY_WARNING_THRESHOLD = 80.0  # å†…å­˜ä½¿ç”¨è­¦å‘Šé˜ˆå€¼ï¼ˆç™¾åˆ†æ¯”ï¼‰
# MEMORY_CRITICAL_THRESHOLD = 90.0  # å†…å­˜ä½¿ç”¨ä¸¥é‡é˜ˆå€¼ï¼ˆç™¾åˆ†æ¯”ï¼‰

# è¯·æ±‚è®°å½•æ‰©å±•é…ç½®
# REQUEST_RECORDER_ENABLED = True  # æ˜¯å¦å¯ç”¨è¯·æ±‚è®°å½•
# REQUEST_RECORDER_OUTPUT_DIR = 'requests_log'  # è¯·æ±‚è®°å½•è¾“å‡ºç›®å½•
# REQUEST_RECORDER_MAX_FILE_SIZE = 10 * 1024 * 1024  # å•ä¸ªè®°å½•æ–‡ä»¶æœ€å¤§å¤§å°ï¼ˆå­—èŠ‚ï¼‰

# æ€§èƒ½åˆ†ææ‰©å±•é…ç½®
# PERFORMANCE_PROFILER_ENABLED = True  # æ˜¯å¦å¯ç”¨æ€§èƒ½åˆ†æ
# PERFORMANCE_PROFILER_OUTPUT_DIR = 'profiling'  # æ€§èƒ½åˆ†æè¾“å‡ºç›®å½•
# PERFORMANCE_PROFILER_INTERVAL = 300  # å®šæœŸä¿å­˜åˆ†æç»“æœé—´éš”ï¼ˆç§’ï¼‰

# å¥åº·æ£€æŸ¥æ‰©å±•é…ç½®
# HEALTH_CHECK_ENABLED = True  # æ˜¯å¦å¯ç”¨å¥åº·æ£€æŸ¥
# HEALTH_CHECK_INTERVAL = 60  # å¥åº·æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰

# ============================== æ—¥å¿—é…ç½® ==============================

LOG_LEVEL = 'INFO'
STATS_DUMP = True
LOG_FILE = f'logs/{{project_name}}.log'
LOG_FORMAT = '%(asctime)s - [%(name)s] - %(levelname)sï¼š %(message)s'
LOG_ENCODING = 'utf-8'

# ============================== ä»£ç†é…ç½® ==============================

PROXY_ENABLED = False
PROXY_API_URL = ""  # è¯·å¡«å…¥çœŸå®çš„ä»£ç†APIåœ°å€
PROXY_EXTRACTOR = "proxy"
PROXY_REFRESH_INTERVAL = 60
PROXY_API_TIMEOUT = 10

# ============================== æµè§ˆå™¨æŒ‡çº¹é…ç½® ==============================

# CurlCffi ä¸‹è½½å™¨ä¸“ç”¨é…ç½®
CURL_BROWSER_TYPE = "chrome"
CURL_BROWSER_VERSION_MAP = {
    "chrome": "chrome136",
    "edge": "edge101",
    "safari": "safari184",
    "firefox": "firefox135",
}

# é»˜è®¤è¯·æ±‚å¤´
DEFAULT_REQUEST_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
                  '(KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
    'Accept-Encoding': 'gzip, deflate, br',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1',
}

# ============================== ä¸‹è½½å™¨ä¼˜åŒ–é…ç½® ==============================

# ä¸‹è½½å™¨å¥åº·æ£€æŸ¥
DOWNLOADER_HEALTH_CHECK = True  # æ˜¯å¦å¯ç”¨ä¸‹è½½å™¨å¥åº·æ£€æŸ¥
HEALTH_CHECK_INTERVAL = 60  # å¥åº·æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰

# è¯·æ±‚ç»Ÿè®¡é…ç½®
REQUEST_STATS_ENABLED = True  # æ˜¯å¦å¯ç”¨è¯·æ±‚ç»Ÿè®¡
STATS_RESET_ON_START = False  # å¯åŠ¨æ—¶æ˜¯å¦é‡ç½®ç»Ÿè®¡

# HttpX ä¸‹è½½å™¨ä¸“ç”¨é…ç½®
HTTPX_HTTP2 = True  # æ˜¯å¦å¯ç”¨HTTP/2æ”¯æŒ
HTTPX_FOLLOW_REDIRECTS = True  # æ˜¯å¦è‡ªåŠ¨è·Ÿéšé‡å®šå‘

# AioHttp ä¸‹è½½å™¨ä¸“ç”¨é…ç½®
AIOHTTP_AUTO_DECOMPRESS = True  # æ˜¯å¦è‡ªåŠ¨è§£å‹å“åº”
AIOHTTP_FORCE_CLOSE = False  # æ˜¯å¦å¼ºåˆ¶å…³é—­è¿æ¥

# é€šç”¨ä¼˜åŒ–é…ç½®
CONNECTION_TTL_DNS_CACHE = 300  # DNSç¼“å­˜TTLï¼ˆç§’ï¼‰
CONNECTION_KEEPALIVE_TIMEOUT = 15  # Keep-Aliveè¶…æ—¶ï¼ˆç§’ï¼‰

# ============================== å¼€å‘ä¸è°ƒè¯• ==============================

# å¼€å‘æ¨¡å¼é…ç½®
DEBUG = False
TESTING = False

# æ€§èƒ½ç›‘æ§
ENABLE_PERFORMANCE_MONITORING = True
MEMORY_USAGE_WARNING_THRESHOLD = 500  # MB

# ============================== è‡ªå®šä¹‰é…ç½®åŒºåŸŸ ==============================
# åœ¨æ­¤å¤„æ·»åŠ é¡¹ç›®ç‰¹å®šçš„é…ç½®é¡¹

# ç¤ºä¾‹ï¼šç›®æ ‡ç½‘ç«™ç‰¹å®šé…ç½®
# TARGET_DOMAIN = '{{domain}}'
# MAX_PAGES_PER_DOMAIN = 10000
# CUSTOM_RATE_LIMIT = 1.5
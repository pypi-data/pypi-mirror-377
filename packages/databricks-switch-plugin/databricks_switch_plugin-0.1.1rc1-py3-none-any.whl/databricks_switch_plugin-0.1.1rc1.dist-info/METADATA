Metadata-Version: 2.4
Name: databricks-switch-plugin
Version: 0.1.1rc1
Summary: LLM-powered tool to convert SQL, code, and workflow files into Databricks notebooks.
Project-URL: Documentation, https://databrickslabs.github.io/lakebridge
Project-URL: Issues, https://github.com/databrickslabs/lakebridge/issues
Project-URL: Source, https://github.com/databrickslabs/lakebridge
Maintainer-email: Databricks Labs <labs-oss@databricks.com>
License-File: LICENSE
License-File: NOTICE
Keywords: Conversion,Databricks,LLM,Migration,SQL
Classifier: Development Status :: 4 - Beta
Classifier: Environment :: Console
Classifier: Framework :: Pytest
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: System Administrators
Classifier: License :: Other/Proprietary License
Classifier: Operating System :: MacOS
Classifier: Operating System :: Microsoft :: Windows
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: Implementation :: CPython
Classifier: Topic :: Software Development :: Libraries
Classifier: Topic :: Utilities
Requires-Python: >=3.10
Requires-Dist: anytree==2.13.0
Requires-Dist: chardet==5.2.0
Requires-Dist: httpx==0.28.1
Requires-Dist: omegaconf==2.3.0
Requires-Dist: pyyaml==6.0.2
Requires-Dist: tenacity==9.1.2
Requires-Dist: tiktoken==0.9.0
Provides-Extra: dev
Requires-Dist: black~=25.1.0; extra == 'dev'
Requires-Dist: coverage[toml]~=7.8.0; extra == 'dev'
Requires-Dist: databricks-connect~=17.0.1; extra == 'dev'
Requires-Dist: databricks-labs-pylint~=0.4.0; extra == 'dev'
Requires-Dist: databricks-labs-pytester>=0.3.0; extra == 'dev'
Requires-Dist: databricks-sdk~=0.51.0; extra == 'dev'
Requires-Dist: hatch; extra == 'dev'
Requires-Dist: mypy~=1.10.0; extra == 'dev'
Requires-Dist: pylint-pytest==2.0.0a0; extra == 'dev'
Requires-Dist: pylint~=3.2.2; extra == 'dev'
Requires-Dist: pytest-asyncio~=0.26.0; extra == 'dev'
Requires-Dist: pytest-cov<6.0.0,>=5.0.0; extra == 'dev'
Requires-Dist: pytest-xdist~=3.5.0; extra == 'dev'
Requires-Dist: pytest~=8.3.5; extra == 'dev'
Requires-Dist: python-dotenv>=1.0.0; extra == 'dev'
Requires-Dist: ruff~=0.11.6; extra == 'dev'
Requires-Dist: twine<7.0.0,>=6.0.0; extra == 'dev'
Requires-Dist: types-pytz~=2025.2; extra == 'dev'
Requires-Dist: types-pyyaml~=6.0.12; extra == 'dev'
Description-Content-Type: text/markdown

# Switch
LLM-Powered Code Conversion Plugin for Lakebridge

[![codecov](https://codecov.io/gh/databrickslabs/switch/branch/main/graph/badge.svg?token=YOUR_TOKEN)](https://codecov.io/gh/databrickslabs/switch)

## Project Description
Switch is a Lakebridge transpiler plugin that transforms SQL and other source formats into Databricks-compatible notebooks using Large Language Models (LLMs). As a core component of the Lakebridge migration platform, Switch provides automated code conversion capabilities through a multi-stage processing pipeline designed for large-scale platform migrations.

## Project Support
Please note that all projects in the /databrickslabs github account are provided for your exploration only, and are not formally supported by Databricks with Service Level Agreements (SLAs).  They are provided AS-IS and we do not make any guarantees of any kind.  Please do not submit a support ticket relating to any issues arising from the use of these projects.

Any issues discovered through the use of this project should be filed as GitHub Issues on the Repo.  They will be reviewed as time permits, but there are no formal SLAs for support.

## Key Features
- **AI-Powered Conversion**: Leverages Large Language Models for intelligent code transformation
- **Multi-Format Support**: Converts various source formats including SQL, code files, and workflow definitions
- **Flexible Output**: Generates multiple output formats tailored to your migration needs
- **Built-in Templates**: Comprehensive conversion templates for common database and platform migrations
- **Cloud-Native Processing**: Scalable execution on Databricks platform infrastructure
- **Stateful Tracking**: Maintains conversion progress and results for large-scale migrations
- **Extensible Design**: Customizable template system for specialized conversion requirements

## Using the Project

### Primary Usage: Lakebridge Integration
Switch is primarily designed as a Lakebridge transpiler plugin. To use Switch for code conversion:

1. **Install Lakebridge**: Follow the [Lakebridge documentation](https://databrickslabs.github.io/lakebridge)
2. **Install Switch transpiler**: Use Lakebridge to install the Switch transpiler plugin
3. **Run conversion**: Use Lakebridge's transpile command with Switch

For complete usage instructions and configuration options, refer to the [Lakebridge documentation](https://databrickslabs.github.io/lakebridge).

### Alternative Usage: Direct Deployment
For advanced testing or direct control, you can deploy Switch directly to a Databricks workspace:

**Cell 1: Install Switch package**

From PyPI (stable version):
```python
%pip install databricks-switch-plugin
```

For prerelease versions (dev/rc):
```python
%pip install --pre databricks-switch-plugin
```

**Cell 2: Deploy Switch to workspace**
```python
from databricks.sdk import WorkspaceClient
from switch.api.installer import SwitchInstaller

ws = WorkspaceClient()
installer = SwitchInstaller(ws)
result = installer.install()

print(f"Switch job created: {result.job_url}")
```

After installation, use the created job in Databricks Jobs UI to run conversions with your specific parameters.

# -*- coding: utf-8 -*-
"""
Created on Mon May 20 14:23:23 2024

@author: Elias liu
"""

def ollama_chat(system_prompt = '',user_prompt='Why is the sky blue?',model='test1',host='http://192.168.31.92:11434',chinese=0):
    '''
    
    pip install ollama

    Parameters
    ----------
    system_prompt : TYPE, optional
        ç³»ç»Ÿæç¤ºè¯. The default is ''.
    user_prompt : TYPE, optional
        ç”¨æˆ·æç¤ºè¯. The default is 'Why is the sky blue?'.
    model : TYPE, optional
        æ¨¡å‹. The default is 'test1'.
    host : TYPE, optional
        æœåŠ¡ip. The default is 'http://192.168.31.92:11434'.
    chinese : TYPE, optional
        å½“chinese=1æ—¶ï¼Œ{
          'role': 'system',
          'content': f'ä½ æ˜¯ä¸€ä¸ªä¸­å›½äººï¼Œåªä¼šè¯´æ±‰è¯­ï¼Œæ‰€ä»¥æ¥ä¸‹æ¥ä¸ç®¡ä»»ä½•äººç”¨ä»»æ„è¯­è¨€ï¼Œè¯·éƒ½ç”¨ä¸­æ–‡ä¸ä»–äº¤æµã€‚{system_prompt}',
        },. The default is 0.

    Returns
    -------
    result : TYPE
        DESCRIPTION.

    '''
    from ollama import Client
    client = Client(host=host)
    
    if chinese == 1:
        if system_prompt == None:
            system_prompt = ''
        response = client.chat(model=model, messages=[
          {
            'role': 'system',
            'content': f'ä½ æ˜¯ä¸€ä¸ªä¸­å›½äººï¼Œåªä¼šè¯´æ±‰è¯­ï¼Œæ‰€ä»¥æ¥ä¸‹æ¥ä¸ç®¡ä»»ä½•äººç”¨ä»»æ„è¯­è¨€ï¼Œè¯·éƒ½ç”¨ä¸­æ–‡ä¸ä»–äº¤æµã€‚{system_prompt}',
          },
          {
            'role': 'user',
            'content': f'{user_prompt}',
          },
        ])
    
    else:
    
        if system_prompt == '' or system_prompt == None:
            response = client.chat(model=model, messages=[
              {
                'role': 'user',
                'content': f'{user_prompt}',
              },
            ])
            
            
        else:
            response = client.chat(model=model, messages=[
              {
                'role': 'system',
                'content': f'{system_prompt}',
              },
              {
                'role': 'user',
                'content': f'{user_prompt}',
              },
            ])
        

    
    
    result = response['message']['content']
    print(result)
    return result

# =============================================================================
# dify api


# -----------------------------------------------------------------------------
# å·¥ä½œæµå‹åº”ç”¨
def dify_workflow(query,api_key,api_url,user='elias.liu',response_mode='streaming',inputs={}):
    import requests
    
    # æ›¿æ¢ä¸ºæ‚¨çš„ API ç«¯ç‚¹
    api_url = f'{api_url}/workflows/run'
    
    # è®¾ç½®è¯·æ±‚å¤´ï¼ŒåŒ…æ‹¬è®¤è¯å’Œå†…å®¹ç±»å‹
    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json'
    }
    
    # è®¾ç½®è¯·æ±‚æ•°æ®ï¼ŒåŒ…æ‹¬å¯¹è¯çš„ query å’Œå…¶ä»–å‚æ•°
    if inputs == {}:
        data = {
            "inputs": {
                        "content": f"{query}",  # ç”¨æˆ·çš„æŸ¥è¯¢æˆ–å¯¹è¯å†…å®¹
                       },  # æ ¹æ®éœ€è¦æä¾›è¾“å…¥å‚æ•°
            "response_mode": f"{response_mode}",  # å“åº”æ¨¡å¼ï¼Œæµå¼è¿”å›
            # "conversation_id": "",  # å¯¹è¯IDï¼Œç”¨äºç»´æŒå¯¹è¯
            "user": f"{user}"  # ç”¨æˆ·æ ‡è¯†
        }
    else:
        data = {
            "inputs": inputs,  # æ ¹æ®éœ€è¦æä¾›è¾“å…¥å‚æ•°
            "response_mode": f"{response_mode}",  # å“åº”æ¨¡å¼ï¼Œæµå¼è¿”å›
            # "conversation_id": "",  # å¯¹è¯IDï¼Œç”¨äºç»´æŒå¯¹è¯
            "user": f"{user}"  # ç”¨æˆ·æ ‡è¯†
        }
        
    
    # å‘é€ POST è¯·æ±‚
    response = requests.post(api_url, headers=headers, json=data)
    
    import json
    
    response_text = response.text
    # print(response_text)
    
    # å°†å“åº”æ–‡æœ¬åˆ†å‰²æˆå¤šæ¡æ¶ˆæ¯
    messages = response_text.strip().split('data: ')[1:][-1]
    
    data = json.loads(messages)
    msg = data['data']['outputs']['text']
    # print(msg)
    return msg


# # æ›¿æ¢ä¸ºæ‚¨çš„ API å¯†é’¥
# api_key = 'app-w3UJGtZP9z1ImtTZ1GXfLpoS'
# # æ›¿æ¢ä¸ºæ‚¨çš„ API ç«¯ç‚¹
# api_url = 'http://192.168.31.92/v1'

# query = '''
# 20+ğŸ’°é€è¿è´¹é™©ï¼Œè½¯ç³¯çŒ«çªç‹—çªï¼Œå¿«æ¡æ¼â—
# è½¯è½¯ç³¯ç³¯ï¼Œå…¬ä¸»é£çš„çŒ«çªç‹—çªåªè¦äºŒåå‡ ğŸ’°å°±èƒ½å¤Ÿæ‹¥æœ‰ï¼Œå¿«æ¥æ¡æ¼â—
# ç°åœ¨ä¸‹å•ï¼Œ48hå†…å‘è´§ï¼Œæ˜¥èŠ‚å‰å´½å´½å°±èƒ½ç”¨ä¸Šæš–æš–å’Œå’Œçš„çªçªäº†â—â—
# çªçªé¢œå€¼è¶…çº§é«˜ï¼Œ3ä»¶å¥—ï¼Œçªåº•æ‰˜+å«å­+è•¾ä¸èŠ±è¾¹ï¼Œé£æ ¼è¶…çº§ä¹–ï¼Œ4ç§é¢œè‰²å¯ä»¥é€‰ï¼å¡«å……åšå®æ¾è½¯ï¼Œâ„å†¬å¤©ç”¨å¾ˆæš–å’Œï¼Œé™æ¸©äº†å´½å´½ä¹Ÿèƒ½èˆ’èˆ’æœæœç¡ä¸ªå¥½è§‰ğŸ’¤
# 20æ–¤ä»¥ä¸‹çš„å´½å´½éƒ½å¯ä»¥ç”¨å“¦
# ä½ æ”¹å†™çš„æ–‡ç« æ˜¯ï¼š
# '''

# dify_workflow(query,api_key,api_url)


# -----------------------------------------------------------------------------
# å¯¹è¯å‹åº”ç”¨

def dify_chat(query,api_key,api_url,user='elias.liu',conversation_id='',response_mode='streaming',inputs = {}):
    import requests
    
    # æ›¿æ¢ä¸ºæ‚¨çš„ API ç«¯ç‚¹
    api_url = f'{api_url}/chat-messages'
    
    # è®¾ç½®è¯·æ±‚å¤´ï¼ŒåŒ…æ‹¬è®¤è¯å’Œå†…å®¹ç±»å‹
    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json'
    }
    
    # è®¾ç½®è¯·æ±‚æ•°æ®ï¼ŒåŒ…æ‹¬å¯¹è¯çš„ query å’Œå…¶ä»–å‚æ•°
    data = {
        "inputs": inputs,  # æ ¹æ®éœ€è¦æä¾›è¾“å…¥å‚æ•°
        "query": f"{query}",  # ç”¨æˆ·çš„æŸ¥è¯¢æˆ–å¯¹è¯å†…å®¹
        "response_mode": f"{response_mode}",  # å“åº”æ¨¡å¼ï¼Œæµå¼è¿”å›
        "conversation_id": f"{conversation_id}",  # å¯¹è¯IDï¼Œç”¨äºç»´æŒå¯¹è¯
        "user": f"{user}"  # ç”¨æˆ·æ ‡è¯†
    }
    
    # å‘é€ POST è¯·æ±‚
    response = requests.post(api_url, headers=headers, json=data)
    
    
    import json
    
    response_text = response.text
    
    # å°†å“åº”æ–‡æœ¬åˆ†å‰²æˆå¤šæ¡æ¶ˆæ¯
    messages = response_text.strip().split('data: ')[1:][:-1]
    
    # éå†æ¯æ¡æ¶ˆæ¯å¹¶è§£ç 
    decoded_messages = []
    for message in messages:
        # è§£æ JSON æ•°æ®
        data = json.loads(message)
        # print(data['answer'])
        # è·å– 'answer' å­—æ®µå¹¶è§£ç  Unicode è½¬ä¹‰åºåˆ—
        answer = data['answer']
        # å°†è§£ç åçš„ç­”æ¡ˆæ·»åŠ åˆ°åˆ—è¡¨ä¸­
        decoded_messages.append(answer)
    
    msg = ''.join(decoded_messages)
    # print(msg)
    return msg



# # æ›¿æ¢ä¸ºæ‚¨çš„ API å¯†é’¥
# api_key = 'app-xvaJqDQsGS5m2JIKEeD3NBDh'


# # æ›¿æ¢ä¸ºæ‚¨çš„ API ç«¯ç‚¹
# api_url = 'http://192.168.31.92/v1'


# query = '''
# 20+ğŸ’°é€è¿è´¹é™©ï¼Œè½¯ç³¯çŒ«çªç‹—çªï¼Œå¿«æ¡æ¼â—
# è½¯è½¯ç³¯ç³¯ï¼Œå…¬ä¸»é£çš„çŒ«çªç‹—çªåªè¦äºŒåå‡ ğŸ’°å°±èƒ½å¤Ÿæ‹¥æœ‰ï¼Œå¿«æ¥æ¡æ¼â—
# ç°åœ¨ä¸‹å•ï¼Œ48hå†…å‘è´§ï¼Œæ˜¥èŠ‚å‰å´½å´½å°±èƒ½ç”¨ä¸Šæš–æš–å’Œå’Œçš„çªçªäº†â—â—
# çªçªé¢œå€¼è¶…çº§é«˜ï¼Œ3ä»¶å¥—ï¼Œçªåº•æ‰˜+å«å­+è•¾ä¸èŠ±è¾¹ï¼Œé£æ ¼è¶…çº§ä¹–ï¼Œ4ç§é¢œè‰²å¯ä»¥é€‰ï¼å¡«å……åšå®æ¾è½¯ï¼Œâ„å†¬å¤©ç”¨å¾ˆæš–å’Œï¼Œé™æ¸©äº†å´½å´½ä¹Ÿèƒ½èˆ’èˆ’æœæœç¡ä¸ªå¥½è§‰ğŸ’¤
# 20æ–¤ä»¥ä¸‹çš„å´½å´½éƒ½å¯ä»¥ç”¨å“¦
# ä½ æ”¹å†™çš„æ–‡ç« æ˜¯ï¼š
# '''

# dify_chat(query,api_key,api_url)


# -----------------------------------------------------------------------------
# å¯¹è¯å‹åº”ç”¨

def dify_text(query,api_key,api_url,user='elias.liu',response_mode='streaming',inputs = {},text=''):
    import requests
    
    # æ›¿æ¢ä¸ºæ‚¨çš„ API ç«¯ç‚¹
    api_url = f'{api_url}/completion-messages'
    
    # è®¾ç½®è¯·æ±‚å¤´ï¼ŒåŒ…æ‹¬è®¤è¯å’Œå†…å®¹ç±»å‹
    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json'
    }
    
    # è®¾ç½®è¯·æ±‚æ•°æ®ï¼ŒåŒ…æ‹¬ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬å’Œå¿…éœ€çš„ query å‚æ•°
    if inputs == {}:
        data = {
            "inputs": {
                "text": f"{text}",  # ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬
                "query": f"{query}"  # æ·»åŠ  query å‚æ•°ï¼Œå…¶å€¼æ ¹æ® API çš„å…·ä½“è¦æ±‚æ¥è®¾ç½®
            },
            "response_mode": f"{response_mode}",  # å“åº”æ¨¡å¼ï¼Œæµå¼è¿”å›
            "user": f"{user}"  # ç”¨æˆ·æ ‡è¯†
        }
    else:
        data = {
            "inputs": inputs,
            "response_mode": f"{response_mode}",  # å“åº”æ¨¡å¼ï¼Œæµå¼è¿”å›
            "user": f"{user}"  # ç”¨æˆ·æ ‡è¯†
        }
        
    
    # å‘é€ POST è¯·æ±‚
    response = requests.post(api_url, headers=headers, json=data)
    
    # æ‰“å°å“åº”å†…å®¹
    # print(response.text)
    
    import json
    
    response_text = response.text
    
    # å°†å“åº”æ–‡æœ¬åˆ†å‰²æˆå¤šæ¡æ¶ˆæ¯
    messages = response_text.strip().split('data: ')[1:][:-1]
    
    # éå†æ¯æ¡æ¶ˆæ¯å¹¶è§£ç 
    decoded_messages = []
    for message in messages:
        # è§£æ JSON æ•°æ®
        data = json.loads(message)
        # print(data['answer'])
        # è·å– 'answer' å­—æ®µå¹¶è§£ç  Unicode è½¬ä¹‰åºåˆ—
        answer = data['answer']
        # å°†è§£ç åçš„ç­”æ¡ˆæ·»åŠ åˆ°åˆ—è¡¨ä¸­
        decoded_messages.append(answer)
    
    msg = ''.join(decoded_messages)
    # print(msg)
    return msg


# # æ›¿æ¢ä¸ºæ‚¨çš„ API å¯†é’¥
# api_key = 'app-h1s2porhLFnhLRD5eom1nhi3'

# # æ›¿æ¢ä¸ºæ‚¨çš„ API ç«¯ç‚¹
# api_url = 'http://192.168.31.92/v1'


# query = '''
# 20+ğŸ’°é€è¿è´¹é™©ï¼Œè½¯ç³¯çŒ«çªç‹—çªï¼Œå¿«æ¡æ¼â—
# è½¯è½¯ç³¯ç³¯ï¼Œå…¬ä¸»é£çš„çŒ«çªç‹—çªåªè¦äºŒåå‡ ğŸ’°å°±èƒ½å¤Ÿæ‹¥æœ‰ï¼Œå¿«æ¥æ¡æ¼â—
# ç°åœ¨ä¸‹å•ï¼Œ48hå†…å‘è´§ï¼Œæ˜¥èŠ‚å‰å´½å´½å°±èƒ½ç”¨ä¸Šæš–æš–å’Œå’Œçš„çªçªäº†â—â—
# çªçªé¢œå€¼è¶…çº§é«˜ï¼Œ3ä»¶å¥—ï¼Œçªåº•æ‰˜+å«å­+è•¾ä¸èŠ±è¾¹ï¼Œé£æ ¼è¶…çº§ä¹–ï¼Œ4ç§é¢œè‰²å¯ä»¥é€‰ï¼å¡«å……åšå®æ¾è½¯ï¼Œâ„å†¬å¤©ç”¨å¾ˆæš–å’Œï¼Œé™æ¸©äº†å´½å´½ä¹Ÿèƒ½èˆ’èˆ’æœæœç¡ä¸ªå¥½è§‰ğŸ’¤
# 20æ–¤ä»¥ä¸‹çš„å´½å´½éƒ½å¯ä»¥ç”¨å“¦
# ä½ æ”¹å†™çš„æ–‡ç« æ˜¯ï¼š
# '''

# dify_text(query,api_key,api_url)


# =============================================================================
# openai api (å¯è°ƒç”¨ç¬¬ä¸‰æ–¹api)

def openai_chat(system_prompt = '',user_prompt="è®²ä¸ªç¬‘è¯", api_key = "sk-LqP8IxSTpjTq6c9qvhqFO74qQqMTl7YDzdQ1KcDjIE9djYtK",base_url = "https://api.fe8.cn/v1",model="gpt-3.5-turbo",info_txt='chat_completion.txt'):
    from openai import OpenAI
    from loguru import logger
    
    import tools
    client = OpenAI(
        api_key = api_key,
        base_url = base_url
    )
    
    if system_prompt == '' or system_prompt == None:
        chat_completion = client.chat.completions.create(
            messages=[
                {
                    "role": "user",
                    "content": f"{user_prompt}",
                }
            ],
            model=f"{model}", #æ­¤å¤„æ›´æ¢å…¶å®ƒæ¨¡å‹,è¯·å‚è€ƒæ¨¡å‹åˆ—è¡¨ eg: google/gemma-7b-it
        )
    else:
        chat_completion = client.chat.completions.create(
            messages=[
                {
                    "role": "system",
                    "content": f"{system_prompt}",
                },
                {
                    "role": "user",
                    "content": f"{user_prompt}",
                }
            ],
            model=f"{model}", #æ­¤å¤„æ›´æ¢å…¶å®ƒæ¨¡å‹,è¯·å‚è€ƒæ¨¡å‹åˆ—è¡¨ eg: google/gemma-7b-it
        )
    try:
        tools.write_text_to_file(info_txt, str(chat_completion))
    except:
        logger.info(f'{info_txt}ä¸å­˜åœ¨ï¼Œinfo_txt é‡ç½®ä¸º chat_completion.txt ')
        info_txt='chat_completion.txt'
        tools.write_text_to_file(info_txt, str(chat_completion))
    msg = chat_completion.choices[0].message.content
    # print(msg)
    return msg

# api_key = "sk-LqP8IxSTpjTq6c9qvhqFO74qQqMTl7YDzdQ1KcDjIE9djYtK"
# base_url = "https://api.fe8.cn/v1"
# model="gpt-3.5-turbo"
# user_prompt="è®²ä¸ªç¬‘è¯"
# openai_chat(system_prompt = '',user_prompt=user_prompt, api_key = api_key,base_url = base_url,model=model)





# =============================================================================
# openai api (å¯è°ƒç”¨ç¬¬ä¸‰æ–¹api)



def openai_chat_time_limit(system_prompt = '',user_prompt="è®²ä¸ªç¬‘è¯", api_key = "sk-LqP8IxSTpjTq6c9qvhqFO74qQqMTl7YDzdQ1KcDjIE9djYtK",base_url = "https://api.fe8.cn/v1",model="gpt-3.5-turbo",info_txt='chat_completion.txt',time_limit = 15):
    
    import threading
    import queue
    import time
    from loguru import logger
    
    class TimeoutException(Exception):
        pass
    
    def chat_function(output_queue):
        try:
            start = time.time()
            # å‡è®¾client.chat.completions.create æ˜¯ä½ è°ƒç”¨APIçš„å‡½æ•°
            msg = openai_chat(system_prompt,user_prompt,api_key,base_url,model,info_txt)
            end = time.time()
            output_queue.put((msg, round(end - start, 2)))
        except Exception as e:
            output_queue.put(e)
    
    def chat_with_timeout(timeout):
        output_queue = queue.Queue()
        chat_thread = threading.Thread(target=chat_function, args=(output_queue,))
        chat_thread.start()
        
        start_time = time.time()
        elapsed_time = 0
        
        logger.info(f'LLM ({model}) start !')
        while elapsed_time < timeout:
            if not chat_thread.is_alive():
                break
            time.sleep(1)
            elapsed_time = time.time() - start_time
            # print(f"Elapsed time: {int(elapsed_time)} seconds")
            logger.info(f"LLM ({model}) is running: {int(elapsed_time)} seconds")
        
        if chat_thread.is_alive():
            raise TimeoutException(f"The chat function timed out after {timeout} seconds")
        
        result = output_queue.get()
        if isinstance(result, Exception):
            raise result
        
        content, usetime = result
        logger.info(f'chat_completion.choices[0].message.content:\n\n"""\n{content}\n"""\n')
        logger.info(f'usetime: {usetime} seconds')
        
        return content
    
    try:
        content = chat_with_timeout(time_limit)
        return content
    except TimeoutException as e:
        logger.error(e)
    except Exception as e:
        logger.error("An error occurred:", e)
        
        
# api_key = "sk-LqP8IxSTpjTq6c9qvhqFO74qQqMTl7YDzdQ1KcDjIE9djYtK"
# base_url = "https://api.fe8.cn/v1"
# model="gpt-4o-mini"
# user_prompt="è®²ä¸ªç¬‘è¯"
# time_limit = 15
# content = openai_chat_time_limit(system_prompt = '',user_prompt=user_prompt, api_key = api_key,base_url = base_url,model=model,time_limit=time_limit)

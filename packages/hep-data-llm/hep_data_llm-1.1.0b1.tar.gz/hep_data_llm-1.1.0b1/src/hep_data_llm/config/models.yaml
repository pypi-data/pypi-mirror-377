models:
  gpt-4.1:
    model_name: gpt-4.1
    input_cost_per_million: 2.00
    output_cost_per_million: 8.00
  gpt-5:
    model_name: gpt-5
    input_cost_per_million: 1.25
    output_cost_per_million: 10.00
  gpt-5-mini:
    model_name: gpt-5-mini
    input_cost_per_million: 0.25
    output_cost_per_million: 2.00
  gpt-5-nano:
    model_name: gpt-5-nano
    input_cost_per_million: 0.05
    output_cost_per_million: 0.40
  gpt-4o:
    model_name: gpt-4o
    input_cost_per_million: 2.50
    output_cost_per_million: 10.00
  o4-mini:
    model_name: o4-mini
    input_cost_per_million: 1.10
    output_cost_per_million: 4.40
  gpt-oss-120b:
    model_name: openai/gpt-oss-120b
    input_cost_per_million: 0.15
    output_cost_per_million: 0.60
    endpoint: https://api.together.xyz/v1
  gpt-oss-20b:
    model_name: openai/gpt-oss-20b
    input_cost_per_million: 0.05
    output_cost_per_million: 0.20
    endpoint: https://api.together.xyz/v1
  Qwen3-Coder-480B:
    model_name: Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8
    input_cost_per_million: 2.00
    output_cost_per_million: 2.00
    endpoint: https://api.together.xyz/v1
  coder-large:
    model_name: arcee-ai/coder-large
    input_cost_per_million: 0.50
    output_cost_per_million: 0.80
    endpoint: https://api.together.xyz/v1
  claude-sonnet-4:
    model_name: anthropic/claude-sonnet-4
    input_cost_per_million: 3.00
    output_cost_per_million: 15.00
    endpoint: https://openrouter.ai/api/v1
  gemini-2.5-flash:
    model_name: google/gemini-2.5-flash
    input_cost_per_million: 0.30
    output_cost_per_million: 2.50
    endpoint: https://openrouter.ai/api/v1
  deepseek-chat-v3-0324:
    model_name: deepseek/deepseek-chat-v3-0324
    input_cost_per_million: 0.28
    output_cost_per_million: 0.88
    endpoint: https://openrouter.ai/api/v1
  llama-3.1-8b:
    model_name: meta-llama/llama-3.1-8b-instruct
    input_cost_per_million: 0.015
    output_cost_per_million: 0.02
    endpoint: https://openrouter.ai/api/v1
  llama-3.3-70b:
    model_name: meta-llama/llama-3.3-70b-instruct
    input_cost_per_million: 0.038
    output_cost_per_million: 0.12
    endpoint: https://openrouter.ai/api/v1
  llama-4-maverick-400B:
    model_name: meta-llama/llama-4-maverick
    input_cost_per_million: 0.15
    output_cost_per_million: 0.60
    endpoint: https://openrouter.ai/api/v1
  llama-4-scout-109B:
    model_name: meta-llama/llama-4-scout
    input_cost_per_million: 0.08
    output_cost_per_million: 0.30
    endpoint: https://openrouter.ai/api/v1
  # llama-3-8b:
  #   # Can't run because context is only 8K
  #   model_name: meta-llama/llama-3-8b-instruct
  #   input_cost_per_million: 0.015
  #   output_cost_per_million: 0.02
  #   endpoint: https://openrouter.ai/api/v1

  # Not supported in the API that I'm using here (chat completions).
  # codex-mini-latest:
  #   model_name: codex-mini-latest
  #   input_cost_per_million: 1.50
  #   output_cost_per_million: 6.00
  # qwen3:
  #   model_name: ai/qwen3:8B-Q4_0
  #   input_cost_per_million: 0.00
  #   output_cost_per_million: 0.00
  #   endpoint: http://localhost:12434/engines/llama.cpp/v1
  # phi4:
  #   model_name: ai/qwen3:8B-Q4_0
  #   input_cost_per_million: 0.00
  #   output_cost_per_million: 0.00
  #   endpoint: http://localhost:12434/engines/llama.cpp/v1
  # deepseek-r1-8B:
  #   model_name: ai/deepseek-r1-distill-llama:8B-Q4_K_M
  #   input_cost_per_million: 0.00
  #   output_cost_per_million: 0.00
  #   endpoint: http://localhost:12434/engines/llama.cpp/v1

# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
"""Client and server classes corresponding to protobuf-defined services."""
import grpc
import warnings

from google.protobuf import empty_pb2 as google_dot_protobuf_dot_empty__pb2
from truffle.infer.convo import conversation_pb2 as truffle_dot_infer_dot_convo_dot_conversation__pb2
from truffle.infer import embedding_pb2 as truffle_dot_infer_dot_embedding__pb2
from truffle.infer import gencfg_pb2 as truffle_dot_infer_dot_gencfg__pb2
from truffle.infer import irequest_pb2 as truffle_dot_infer_dot_irequest__pb2
from truffle.infer import iresponse_pb2 as truffle_dot_infer_dot_iresponse__pb2
from truffle.infer import model_pb2 as truffle_dot_infer_dot_model__pb2

GRPC_GENERATED_VERSION = '1.72.0'
GRPC_VERSION = grpc.__version__
_version_not_supported = False

try:
    from grpc._utilities import first_version_is_lower
    _version_not_supported = first_version_is_lower(GRPC_VERSION, GRPC_GENERATED_VERSION)
except ImportError:
    _version_not_supported = True

if _version_not_supported:
    raise RuntimeError(
        f'The grpc package installed is at version {GRPC_VERSION},'
        + f' but the generated code in truffle/infer/infer_pb2_grpc.py depends on'
        + f' grpcio>={GRPC_GENERATED_VERSION}.'
        + f' Please upgrade your grpc module to grpcio>={GRPC_GENERATED_VERSION}'
        + f' or downgrade your generated code using grpcio-tools<={GRPC_VERSION}.'
    )


class InferenceServiceStub(object):
    """
    Defines the main gRPC service for all AI inference operations.
    This service is the primary entry point for clients to interact with generative
    models, create embeddings, manage model configurations, and use other related
    utility functions. It consolidates all necessary data structures from other
    .proto files into a single, cohesive API.
    """

    def __init__(self, channel):
        """Constructor.

        Args:
            channel: A grpc.Channel.
        """
        self.Generate = channel.unary_stream(
                '/truffle.infer.InferenceService/Generate',
                request_serializer=truffle_dot_infer_dot_irequest__pb2.IRequest.SerializeToString,
                response_deserializer=truffle_dot_infer_dot_iresponse__pb2.IResponse.FromString,
                _registered_method=True)
        self.GenerateSync = channel.unary_unary(
                '/truffle.infer.InferenceService/GenerateSync',
                request_serializer=truffle_dot_infer_dot_irequest__pb2.IRequest.SerializeToString,
                response_deserializer=truffle_dot_infer_dot_iresponse__pb2.IResponse.FromString,
                _registered_method=True)
        self.GenerateBatch = channel.unary_unary(
                '/truffle.infer.InferenceService/GenerateBatch',
                request_serializer=truffle_dot_infer_dot_irequest__pb2.BatchIRequest.SerializeToString,
                response_deserializer=truffle_dot_infer_dot_iresponse__pb2.BatchIResponse.FromString,
                _registered_method=True)
        self.Embed = channel.unary_unary(
                '/truffle.infer.InferenceService/Embed',
                request_serializer=truffle_dot_infer_dot_embedding__pb2.EmbeddingRequest.SerializeToString,
                response_deserializer=truffle_dot_infer_dot_embedding__pb2.EmbeddingResponse.FromString,
                _registered_method=True)
        self.EmbedQueries = channel.unary_unary(
                '/truffle.infer.InferenceService/EmbedQueries',
                request_serializer=truffle_dot_infer_dot_embedding__pb2.EmbeddingRequest.SerializeToString,
                response_deserializer=truffle_dot_infer_dot_embedding__pb2.EmbeddingResponse.FromString,
                _registered_method=True)
        self.GetModelList = channel.unary_unary(
                '/truffle.infer.InferenceService/GetModelList',
                request_serializer=truffle_dot_infer_dot_model__pb2.GetModelListRequest.SerializeToString,
                response_deserializer=truffle_dot_infer_dot_model__pb2.ModelList.FromString,
                _registered_method=True)
        self.GetModel = channel.unary_unary(
                '/truffle.infer.InferenceService/GetModel',
                request_serializer=truffle_dot_infer_dot_model__pb2.GetModelRequest.SerializeToString,
                response_deserializer=truffle_dot_infer_dot_model__pb2.Model.FromString,
                _registered_method=True)
        self.SetModels = channel.unary_unary(
                '/truffle.infer.InferenceService/SetModels',
                request_serializer=truffle_dot_infer_dot_model__pb2.SetModelsRequest.SerializeToString,
                response_deserializer=truffle_dot_infer_dot_model__pb2.SetModelsResponse.FromString,
                _registered_method=True)
        self.GetModelState = channel.unary_unary(
                '/truffle.infer.InferenceService/GetModelState',
                request_serializer=truffle_dot_infer_dot_model__pb2.GetModelRequest.SerializeToString,
                response_deserializer=truffle_dot_infer_dot_model__pb2.ModelStateUpdate.FromString,
                _registered_method=True)
        self.OnModelStateChange = channel.unary_stream(
                '/truffle.infer.InferenceService/OnModelStateChange',
                request_serializer=truffle_dot_infer_dot_model__pb2.GetModelRequest.SerializeToString,
                response_deserializer=truffle_dot_infer_dot_model__pb2.ModelStateUpdate.FromString,
                _registered_method=True)
        self.GetEmbeddingModelList = channel.unary_unary(
                '/truffle.infer.InferenceService/GetEmbeddingModelList',
                request_serializer=google_dot_protobuf_dot_empty__pb2.Empty.SerializeToString,
                response_deserializer=truffle_dot_infer_dot_model__pb2.EmbeddingModelList.FromString,
                _registered_method=True)
        self.GetEmbeddingModelInfo = channel.unary_unary(
                '/truffle.infer.InferenceService/GetEmbeddingModelInfo',
                request_serializer=truffle_dot_infer_dot_model__pb2.GetModelRequest.SerializeToString,
                response_deserializer=truffle_dot_infer_dot_model__pb2.EmbeddingModelInfo.FromString,
                _registered_method=True)
        self.BuildConvo = channel.unary_unary(
                '/truffle.infer.InferenceService/BuildConvo',
                request_serializer=truffle_dot_infer_dot_convo_dot_conversation__pb2.Conversation.SerializeToString,
                response_deserializer=truffle_dot_infer_dot_convo_dot_conversation__pb2.BuiltContext.FromString,
                _registered_method=True)
        self.ValidateGenerationConfig = channel.unary_unary(
                '/truffle.infer.InferenceService/ValidateGenerationConfig',
                request_serializer=truffle_dot_infer_dot_gencfg__pb2.ValidateConfigRequest.SerializeToString,
                response_deserializer=truffle_dot_infer_dot_gencfg__pb2.ValidateConfigResponse.FromString,
                _registered_method=True)


class InferenceServiceServicer(object):
    """
    Defines the main gRPC service for all AI inference operations.
    This service is the primary entry point for clients to interact with generative
    models, create embeddings, manage model configurations, and use other related
    utility functions. It consolidates all necessary data structures from other
    .proto files into a single, cohesive API.
    """

    def Generate(self, request, context):
        """Starts a generation task that streams responses back to the client.
        This is suitable for interactive applications where responses are displayed
        as they are generated.
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def GenerateSync(self, request, context):
        """Performs a generation task and returns the full response in a single message.
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def GenerateBatch(self, request, context):
        """Processes a batch of inference requests in parallel.
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def Embed(self, request, context):
        """Generates embeddings for a given set of inputs. Embeddings are numerical
        representations of text that can be used for semantic search, clustering,
        and other machine learning tasks.
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def EmbedQueries(self, request, context):
        """A specialized version of Embed for generating embeddings for
        search queries.
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def GetModelList(self, request, context):
        """Retrieves a list of all available models.
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def GetModel(self, request, context):
        """Fetches detailed information about a specific model.
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def SetModels(self, request, context):
        """Configures model parameters such as context length, batch size etc.
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def GetModelState(self, request, context):
        """Gets the current state of a model, such as loading, loaded, unloaded etc.
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def OnModelStateChange(self, request, context):
        """Subscribes to updates on the state of a model to avoid polling.
        pass an empty ID to get updates for all models.
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def GetEmbeddingModelList(self, request, context):
        """Retrieves a list of all available embedding models.
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def GetEmbeddingModelInfo(self, request, context):
        """Gets detailed information about a specific embedding model (input length, dimension size etc).
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def BuildConvo(self, request, context):
        """Builds a context from a conversation.
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def ValidateGenerationConfig(self, request, context):
        """Validates a generation configuration to ensure that it is compatible with
        the models.
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')


def add_InferenceServiceServicer_to_server(servicer, server):
    rpc_method_handlers = {
            'Generate': grpc.unary_stream_rpc_method_handler(
                    servicer.Generate,
                    request_deserializer=truffle_dot_infer_dot_irequest__pb2.IRequest.FromString,
                    response_serializer=truffle_dot_infer_dot_iresponse__pb2.IResponse.SerializeToString,
            ),
            'GenerateSync': grpc.unary_unary_rpc_method_handler(
                    servicer.GenerateSync,
                    request_deserializer=truffle_dot_infer_dot_irequest__pb2.IRequest.FromString,
                    response_serializer=truffle_dot_infer_dot_iresponse__pb2.IResponse.SerializeToString,
            ),
            'GenerateBatch': grpc.unary_unary_rpc_method_handler(
                    servicer.GenerateBatch,
                    request_deserializer=truffle_dot_infer_dot_irequest__pb2.BatchIRequest.FromString,
                    response_serializer=truffle_dot_infer_dot_iresponse__pb2.BatchIResponse.SerializeToString,
            ),
            'Embed': grpc.unary_unary_rpc_method_handler(
                    servicer.Embed,
                    request_deserializer=truffle_dot_infer_dot_embedding__pb2.EmbeddingRequest.FromString,
                    response_serializer=truffle_dot_infer_dot_embedding__pb2.EmbeddingResponse.SerializeToString,
            ),
            'EmbedQueries': grpc.unary_unary_rpc_method_handler(
                    servicer.EmbedQueries,
                    request_deserializer=truffle_dot_infer_dot_embedding__pb2.EmbeddingRequest.FromString,
                    response_serializer=truffle_dot_infer_dot_embedding__pb2.EmbeddingResponse.SerializeToString,
            ),
            'GetModelList': grpc.unary_unary_rpc_method_handler(
                    servicer.GetModelList,
                    request_deserializer=truffle_dot_infer_dot_model__pb2.GetModelListRequest.FromString,
                    response_serializer=truffle_dot_infer_dot_model__pb2.ModelList.SerializeToString,
            ),
            'GetModel': grpc.unary_unary_rpc_method_handler(
                    servicer.GetModel,
                    request_deserializer=truffle_dot_infer_dot_model__pb2.GetModelRequest.FromString,
                    response_serializer=truffle_dot_infer_dot_model__pb2.Model.SerializeToString,
            ),
            'SetModels': grpc.unary_unary_rpc_method_handler(
                    servicer.SetModels,
                    request_deserializer=truffle_dot_infer_dot_model__pb2.SetModelsRequest.FromString,
                    response_serializer=truffle_dot_infer_dot_model__pb2.SetModelsResponse.SerializeToString,
            ),
            'GetModelState': grpc.unary_unary_rpc_method_handler(
                    servicer.GetModelState,
                    request_deserializer=truffle_dot_infer_dot_model__pb2.GetModelRequest.FromString,
                    response_serializer=truffle_dot_infer_dot_model__pb2.ModelStateUpdate.SerializeToString,
            ),
            'OnModelStateChange': grpc.unary_stream_rpc_method_handler(
                    servicer.OnModelStateChange,
                    request_deserializer=truffle_dot_infer_dot_model__pb2.GetModelRequest.FromString,
                    response_serializer=truffle_dot_infer_dot_model__pb2.ModelStateUpdate.SerializeToString,
            ),
            'GetEmbeddingModelList': grpc.unary_unary_rpc_method_handler(
                    servicer.GetEmbeddingModelList,
                    request_deserializer=google_dot_protobuf_dot_empty__pb2.Empty.FromString,
                    response_serializer=truffle_dot_infer_dot_model__pb2.EmbeddingModelList.SerializeToString,
            ),
            'GetEmbeddingModelInfo': grpc.unary_unary_rpc_method_handler(
                    servicer.GetEmbeddingModelInfo,
                    request_deserializer=truffle_dot_infer_dot_model__pb2.GetModelRequest.FromString,
                    response_serializer=truffle_dot_infer_dot_model__pb2.EmbeddingModelInfo.SerializeToString,
            ),
            'BuildConvo': grpc.unary_unary_rpc_method_handler(
                    servicer.BuildConvo,
                    request_deserializer=truffle_dot_infer_dot_convo_dot_conversation__pb2.Conversation.FromString,
                    response_serializer=truffle_dot_infer_dot_convo_dot_conversation__pb2.BuiltContext.SerializeToString,
            ),
            'ValidateGenerationConfig': grpc.unary_unary_rpc_method_handler(
                    servicer.ValidateGenerationConfig,
                    request_deserializer=truffle_dot_infer_dot_gencfg__pb2.ValidateConfigRequest.FromString,
                    response_serializer=truffle_dot_infer_dot_gencfg__pb2.ValidateConfigResponse.SerializeToString,
            ),
    }
    generic_handler = grpc.method_handlers_generic_handler(
            'truffle.infer.InferenceService', rpc_method_handlers)
    server.add_generic_rpc_handlers((generic_handler,))
    server.add_registered_method_handlers('truffle.infer.InferenceService', rpc_method_handlers)


 # This class is part of an EXPERIMENTAL API.
class InferenceService(object):
    """
    Defines the main gRPC service for all AI inference operations.
    This service is the primary entry point for clients to interact with generative
    models, create embeddings, manage model configurations, and use other related
    utility functions. It consolidates all necessary data structures from other
    .proto files into a single, cohesive API.
    """

    @staticmethod
    def Generate(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_stream(
            request,
            target,
            '/truffle.infer.InferenceService/Generate',
            truffle_dot_infer_dot_irequest__pb2.IRequest.SerializeToString,
            truffle_dot_infer_dot_iresponse__pb2.IResponse.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def GenerateSync(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/truffle.infer.InferenceService/GenerateSync',
            truffle_dot_infer_dot_irequest__pb2.IRequest.SerializeToString,
            truffle_dot_infer_dot_iresponse__pb2.IResponse.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def GenerateBatch(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/truffle.infer.InferenceService/GenerateBatch',
            truffle_dot_infer_dot_irequest__pb2.BatchIRequest.SerializeToString,
            truffle_dot_infer_dot_iresponse__pb2.BatchIResponse.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def Embed(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/truffle.infer.InferenceService/Embed',
            truffle_dot_infer_dot_embedding__pb2.EmbeddingRequest.SerializeToString,
            truffle_dot_infer_dot_embedding__pb2.EmbeddingResponse.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def EmbedQueries(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/truffle.infer.InferenceService/EmbedQueries',
            truffle_dot_infer_dot_embedding__pb2.EmbeddingRequest.SerializeToString,
            truffle_dot_infer_dot_embedding__pb2.EmbeddingResponse.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def GetModelList(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/truffle.infer.InferenceService/GetModelList',
            truffle_dot_infer_dot_model__pb2.GetModelListRequest.SerializeToString,
            truffle_dot_infer_dot_model__pb2.ModelList.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def GetModel(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/truffle.infer.InferenceService/GetModel',
            truffle_dot_infer_dot_model__pb2.GetModelRequest.SerializeToString,
            truffle_dot_infer_dot_model__pb2.Model.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def SetModels(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/truffle.infer.InferenceService/SetModels',
            truffle_dot_infer_dot_model__pb2.SetModelsRequest.SerializeToString,
            truffle_dot_infer_dot_model__pb2.SetModelsResponse.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def GetModelState(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/truffle.infer.InferenceService/GetModelState',
            truffle_dot_infer_dot_model__pb2.GetModelRequest.SerializeToString,
            truffle_dot_infer_dot_model__pb2.ModelStateUpdate.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def OnModelStateChange(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_stream(
            request,
            target,
            '/truffle.infer.InferenceService/OnModelStateChange',
            truffle_dot_infer_dot_model__pb2.GetModelRequest.SerializeToString,
            truffle_dot_infer_dot_model__pb2.ModelStateUpdate.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def GetEmbeddingModelList(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/truffle.infer.InferenceService/GetEmbeddingModelList',
            google_dot_protobuf_dot_empty__pb2.Empty.SerializeToString,
            truffle_dot_infer_dot_model__pb2.EmbeddingModelList.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def GetEmbeddingModelInfo(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/truffle.infer.InferenceService/GetEmbeddingModelInfo',
            truffle_dot_infer_dot_model__pb2.GetModelRequest.SerializeToString,
            truffle_dot_infer_dot_model__pb2.EmbeddingModelInfo.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def BuildConvo(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/truffle.infer.InferenceService/BuildConvo',
            truffle_dot_infer_dot_convo_dot_conversation__pb2.Conversation.SerializeToString,
            truffle_dot_infer_dot_convo_dot_conversation__pb2.BuiltContext.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def ValidateGenerationConfig(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/truffle.infer.InferenceService/ValidateGenerationConfig',
            truffle_dot_infer_dot_gencfg__pb2.ValidateConfigRequest.SerializeToString,
            truffle_dot_infer_dot_gencfg__pb2.ValidateConfigResponse.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

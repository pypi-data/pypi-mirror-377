#!/usr/bin/env python3
"""
–î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ç–ª–∞–¥–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –≤ AdaptiveLLMClient.
"""

import asyncio
import os
import logging
from dotenv import load_dotenv

from kraken_llm.client.adaptive import AdaptiveLLMClient, AdaptiveConfig
from kraken_llm.config.settings import LLMConfig

load_dotenv()

# –í–∫–ª—é—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

async def debug_capability_detection():
    """–î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ç–ª–∞–¥–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π."""
    print("=== –î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ç–ª–∞–¥–∫–∞ AdaptiveLLMClient ===")
    
    config = LLMConfig(
        endpoint=os.getenv("LLM_ENDPOINT"),
        api_key=os.getenv("LLM_TOKEN"),
        model=os.getenv("LLM_MODEL"),
        temperature=0.7
    )
    
    adaptive_config = AdaptiveConfig(
        capability_detection_timeout=10.0,
        enable_performance_tracking=True
    )
    
    async with AdaptiveLLMClient(config, adaptive_config) as client:
        
        print("1. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π:")
        basic_caps = await client._test_basic_capabilities()
        print(f"–ë–∞–∑–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏: {[cap.value for cap in basic_caps]}")
        
        print("\n2. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π:")
        advanced_caps = await client._test_advanced_capabilities()
        print(f"–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏: {[cap.value for cap in advanced_caps]}")
        
        print("\n3. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä—è–º–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ API:")
        direct_caps = await client._test_direct_api_capabilities()
        print(f"–ü—Ä—è–º–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ API: {[cap.value for cap in direct_caps]}")
        
        print("\n4. –ü–æ–ª–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π:")
        all_caps = await client.get_model_capabilities(force_refresh=True)
        print(f"–í—Å–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏: {[cap.value for cap in all_caps]}")


async def test_manual_function_calling():
    """–†—É—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ function calling."""
    print("\n=== –†—É—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ function calling ===")
    
    config = LLMConfig(
        endpoint=os.getenv("LLM_ENDPOINT"),
        api_key=os.getenv("LLM_TOKEN"),
        model=os.getenv("LLM_MODEL"),
        temperature=0.3
    )
    
    adaptive_config = AdaptiveConfig(capability_detection_timeout=5.0)
    
    async with AdaptiveLLMClient(config, adaptive_config) as client:
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∫–ª–∏–µ–Ω—Ç
        standard_client = client._get_client("standard")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º function calling –Ω–∞–ø—Ä—è–º—É—é
        test_functions = [{
            "name": "get_weather",
            "description": "Get weather information",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {"type": "string", "description": "City name"}
                },
                "required": ["city"]
            }
        }]
        
        messages = [
            {"role": "user", "content": "What's the weather in Moscow? Use get_weather function."}
        ]
        
        print("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ function calling —á–µ—Ä–µ–∑ StandardLLMClient:")
        
        try:
            response = await standard_client.chat_completion(
                messages=messages,
                functions=test_functions,
                function_call="auto",
                max_tokens=100
            )
            print(f"–û—Ç–≤–µ—Ç: {response}")
            print("‚úì Function calling —Ä–∞–±–æ—Ç–∞–µ—Ç!")
            
        except Exception as e:
            print(f"‚úó Function calling –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç: {e}")
            print(f"–¢–∏–ø –æ—à–∏–±–∫–∏: {type(e).__name__}")


async def test_manual_tool_calling():
    """–†—É—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ tool calling."""
    print("\n=== –†—É—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ tool calling ===")
    
    config = LLMConfig(
        endpoint=os.getenv("LLM_ENDPOINT"),
        api_key=os.getenv("LLM_TOKEN"),
        model=os.getenv("LLM_MODEL"),
        temperature=0.3
    )
    
    adaptive_config = AdaptiveConfig(capability_detection_timeout=5.0)
    
    async with AdaptiveLLMClient(config, adaptive_config) as client:
        
        standard_client = client._get_client("standard")
        
        test_tools = [{
            "type": "function",
            "function": {
                "name": "get_weather",
                "description": "Get weather information",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "city": {"type": "string", "description": "City name"}
                    },
                    "required": ["city"]
                }
            }
        }]
        
        messages = [
            {"role": "user", "content": "What's the weather in Moscow? Use get_weather tool."}
        ]
        
        print("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ tool calling —á–µ—Ä–µ–∑ StandardLLMClient:")
        
        try:
            response = await standard_client.chat_completion(
                messages=messages,
                tools=test_tools,
                tool_choice="auto",
                max_tokens=100
            )
            print(f"–û—Ç–≤–µ—Ç: {response}")
            print("‚úì Tool calling —Ä–∞–±–æ—Ç–∞–µ—Ç!")
            
        except Exception as e:
            print(f"‚úó Tool calling –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç: {e}")
            print(f"–¢–∏–ø –æ—à–∏–±–∫–∏: {type(e).__name__}")


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—Ç–ª–∞–¥–∫–∏."""
    print("üîç –î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ç–ª–∞–¥–∫–∞ AdaptiveLLMClient")
    print("=" * 60)
    
    try:
        await debug_capability_detection()
        await test_manual_function_calling()
        await test_manual_tool_calling()
        
        print("\n‚úÖ –û—Ç–ª–∞–¥–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ª–∞–¥–∫–∏: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
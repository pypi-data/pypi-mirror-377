#!/usr/bin/env python3
"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ Outlines streaming —Å –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º –ø–∞—Ä—Å–∏–Ω–≥–æ–º.
"""

from kraken_llm.client.structured import StructuredLLMClient
from kraken_llm.config.settings import LLMConfig
import asyncio
import os
import time
from pydantic import BaseModel, Field
from typing import List, Optional
from dotenv import load_dotenv

load_dotenv()

# –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
config = LLMConfig(
    endpoint=os.getenv("LLM_ENDPOINT"),
    api_key=os.getenv("LLM_TOKEN"),
    model=os.getenv("LLM_MODEL")
)
class Person(BaseModel):
    """–ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å —á–µ–ª–æ–≤–µ–∫–∞"""
    name: str = Field(..., description="–ò–º—è")
    age: int = Field(..., description="–í–æ–∑—Ä–∞—Å—Ç")
    city: str = Field(..., description="–ì–æ—Ä–æ–¥")
    occupation: str = Field(..., description="–ü—Ä–æ—Ñ–µ—Å—Å–∏—è")
    active: bool = Field(True, description="–ê–∫—Ç–∏–≤–µ–Ω")


class Project(BaseModel):
    """–ú–æ–¥–µ–ª—å –ø—Ä–æ–µ–∫—Ç–∞"""
    title: str = Field(..., description="–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞")
    description: str = Field(..., description="–û–ø–∏—Å–∞–Ω–∏–µ")
    technologies: List[str] = Field(
        default_factory=list, description="–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏")
    budget: float = Field(0.0, description="–ë—é–¥–∂–µ—Ç")
    duration_months: int = Field(1, description="–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –º–µ—Å—è—Ü–∞—Ö")
    priority: int = Field(3, description="–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç (1-5)")
    completed: bool = Field(False, description="–ó–∞–≤–µ—Ä—à–µ–Ω")


async def demo_simple_streaming():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ—Å—Ç–æ–≥–æ streaming"""
    print("üöÄ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –†–ï–ê–õ–¨–ù–û–ì–û OUTLINES STREAMING")
    print("=" * 55)
    print("\n1Ô∏è‚É£  –ü—Ä–æ—Å—Ç–æ–π streaming —Å –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é")
    print("-" * 40)

    config.outlines_so_mode = True

    client = StructuredLLMClient(config)

    messages = [{
        "role": "user",
        "content": "–°–æ–∑–¥–∞–π –ø—Ä–æ—Ñ–∏–ª—å: –ê–Ω–Ω–∞ –°–º–∏—Ä–Ω–æ–≤–∞, 29 –ª–µ—Ç, UX –¥–∏–∑–∞–π–Ω–µ—Ä –∏–∑ –ú–æ—Å–∫–≤—ã"
    }]

    print("üìù –ó–∞–ø—Ä–æ—Å: –°–æ–∑–¥–∞–π –ø—Ä–æ—Ñ–∏–ª—å UX –¥–∏–∑–∞–π–Ω–µ—Ä–∞")
    print("‚è±Ô∏è  –ù–∞—á–∏–Ω–∞–µ–º streaming...")

    start_time = time.time()

    try:
        result = await client.chat_completion_structured(
            messages=messages,
            response_model=Person,
            stream=True,
            max_tokens=200,
            temperature=0.3
        )

        execution_time = time.time() - start_time

        print(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {execution_time:.3f}s")
        print(f"üë§ –†–µ–∑—É–ª—å—Ç–∞—Ç:")
        print(f"   ‚Ä¢ –ò–º—è: {result.name}")
        print(f"   ‚Ä¢ –í–æ–∑—Ä–∞—Å—Ç: {result.age} –ª–µ—Ç")
        print(f"   ‚Ä¢ –ì–æ—Ä–æ–¥: {result.city}")
        print(f"   ‚Ä¢ –ü—Ä–æ—Ñ–µ—Å—Å–∏—è: {result.occupation}")
        print(f"   ‚Ä¢ –ê–∫—Ç–∏–≤–µ–Ω: {'–î–∞' if result.active else '–ù–µ—Ç'}")

        return True

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return False


async def demo_complex_streaming():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–ª–æ–∂–Ω–æ–≥–æ streaming"""
    print("\n2Ô∏è‚É£  –°–ª–æ–∂–Ω—ã–π streaming —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é")
    print("-" * 40)

    config.outlines_so_mode = True

    client = StructuredLLMClient(config)

    messages = [{
        "role": "user",
        "content": """–°–æ–∑–¥–∞–π –ø—Ä–æ–µ–∫—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –º–æ–±–∏–ª—å–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è:
        - –ù–∞–∑–≤–∞–Ω–∏–µ: "FoodDelivery Pro"
        - –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏: React Native, Node.js, MongoDB
        - –ë—é–¥–∂–µ—Ç: 150000 —Ä—É–±–ª–µ–π
        - –°—Ä–æ–∫: 6 –º–µ—Å—è—Ü–µ–≤
        - –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç"""
    }]

    print("üìù –ó–∞–ø—Ä–æ—Å: –°–æ–∑–¥–∞–π –ø—Ä–æ–µ–∫—Ç –º–æ–±–∏–ª—å–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è")
    print("‚è±Ô∏è  –ù–∞—á–∏–Ω–∞–µ–º streaming...")

    start_time = time.time()

    try:
        result = await client.chat_completion_structured(
            messages=messages,
            response_model=Project,
            stream=True,
            max_tokens=400,
            temperature=0.4
        )

        execution_time = time.time() - start_time

        print(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {execution_time:.3f}s")
        print(f"üìã –†–µ–∑—É–ª—å—Ç–∞—Ç:")
        print(f"   ‚Ä¢ –ù–∞–∑–≤–∞–Ω–∏–µ: {result.title}")
        print(f"   ‚Ä¢ –û–ø–∏—Å–∞–Ω–∏–µ: {result.description}")
        print(f"   ‚Ä¢ –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏: {', '.join(result.technologies)}")
        print(f"   ‚Ä¢ –ë—é–¥–∂–µ—Ç: {result.budget:,.0f} —Ä—É–±.")
        print(f"   ‚Ä¢ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {result.duration_months} –º–µ—Å.")
        print(f"   ‚Ä¢ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {result.priority}/5")
        print(f"   ‚Ä¢ –°—Ç–∞—Ç—É—Å: {'–ó–∞–≤–µ—Ä—à–µ–Ω' if result.completed else '–í —Ä–∞–±–æ—Ç–µ'}")

        return True

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return False


async def demo_performance_comparison():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    print("\n3Ô∏è‚É£  –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    print("-" * 40)

    config.outlines_so_mode = True

    client = StructuredLLMClient(config)

    messages = [{
        "role": "user",
        "content": "–°–æ–∑–¥–∞–π –ø—Ä–æ—Ñ–∏–ª—å: –î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤, 35 –ª–µ—Ç, –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä –ü–û –∏–∑ –°–ü–±"
    }]

    print("üìù –ó–∞–ø—Ä–æ—Å: –°–æ–∑–¥–∞–π –ø—Ä–æ—Ñ–∏–ª—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä–∞ –ü–û")

    # Non-streaming —Ç–µ—Å—Ç
    print("‚è±Ô∏è  –¢–µ—Å—Ç–∏—Ä—É–µ–º non-streaming...")
    start_time = time.time()

    try:
        result_non_stream = await client.chat_completion_structured(
            messages=messages,
            response_model=Person,
            stream=False,
            max_tokens=200,
            temperature=0.3
        )

        non_stream_time = time.time() - start_time
        print(f"   ‚úÖ Non-streaming: {non_stream_time:.3f}s")

    except Exception as e:
        print(f"   ‚ùå Non-streaming –æ—à–∏–±–∫–∞: {e}")
        non_stream_time = 0

    # Streaming —Ç–µ—Å—Ç
    print("‚è±Ô∏è  –¢–µ—Å—Ç–∏—Ä—É–µ–º streaming...")
    start_time = time.time()

    try:
        result_stream = await client.chat_completion_structured(
            messages=messages,
            response_model=Person,
            stream=True,
            max_tokens=200,
            temperature=0.3
        )

        stream_time = time.time() - start_time
        print(f"   ‚úÖ Streaming: {stream_time:.3f}s")

    except Exception as e:
        print(f"   ‚ùå Streaming –æ—à–∏–±–∫–∞: {e}")
        stream_time = 0

    # –ê–Ω–∞–ª–∏–∑
    if non_stream_time > 0 and stream_time > 0:
        if stream_time < non_stream_time:
            improvement = ((non_stream_time - stream_time) /
                           non_stream_time) * 100
            print(
                f"üöÄ Streaming –±—ã—Å—Ç—Ä–µ–µ –Ω–∞ {improvement:.1f}% ({non_stream_time - stream_time:.3f}s)")
        else:
            degradation = ((stream_time - non_stream_time) /
                           non_stream_time) * 100
            print(
                f"‚ö†Ô∏è  Non-streaming –±—ã—Å—Ç—Ä–µ–µ –Ω–∞ {degradation:.1f}% ({stream_time - non_stream_time:.3f}s)")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if (hasattr(result_stream, 'name') and hasattr(result_non_stream, 'name') and
                result_stream.name == result_non_stream.name):
            print("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–¥–µ–Ω—Ç–∏—á–Ω—ã")
        else:
            print("‚ö†Ô∏è  –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç–ª–∏—á–∞—é—Ç—Å—è")

    return non_stream_time > 0 and stream_time > 0


async def demo_concurrent_streaming():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ streaming"""
    print("\n4Ô∏è‚É£  –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π streaming")
    print("-" * 40)

    config.outlines_so_mode = True

    client = StructuredLLMClient(config)

    # –°–æ–∑–¥–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—Å–æ–≤
    requests = [
        {"name": "–ê–ª–µ–∫—Å–µ–π", "age": 28, "city": "–ú–æ—Å–∫–≤–∞", "job": "—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫"},
        {"name": "–ú–∞—Ä–∏—è", "age": 32, "city": "–°–ü–±", "job": "–¥–∏–∑–∞–π–Ω–µ—Ä"},
        {"name": "–ò–≥–æ—Ä—å", "age": 25, "city": "–ö–∞–∑–∞–Ω—å", "job": "–∞–Ω–∞–ª–∏—Ç–∏–∫"}
    ]

    print(f"üìù –ó–∞–ø—É—Å–∫–∞–µ–º {len(requests)} –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤...")

    async def single_request(req, index):
        messages = [{
            "role": "user",
            "content": f"–°–æ–∑–¥–∞–π –ø—Ä–æ—Ñ–∏–ª—å: {req['name']}, {req['age']} –ª–µ—Ç, {req['job']} –∏–∑ {req['city']}"
        }]

        start_time = time.time()
        try:
            result = await client.chat_completion_structured(
                messages=messages,
                response_model=Person,
                stream=True,
                max_tokens=200,
                temperature=0.3
            )

            execution_time = time.time() - start_time
            return {
                "index": index + 1,
                "time": execution_time,
                "result": result,
                "success": True
            }
        except Exception as e:
            execution_time = time.time() - start_time
            return {
                "index": index + 1,
                "time": execution_time,
                "error": str(e),
                "success": False
            }

    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    start_time = time.time()
    results = await asyncio.gather(*[single_request(req, i) for i, req in enumerate(requests)])
    total_time = time.time() - start_time

    print(f"‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.3f}s")

    successful = [r for r in results if r["success"]]
    failed = [r for r in results if not r["success"]]

    print(f"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö: {len(successful)}/{len(results)}")

    for result in successful:
        print(
            f"   #{result['index']}: {result['time']:.3f}s - {result['result'].name}")

    for result in failed:
        print(f"   #{result['index']}: ‚ùå {result['error'][:50]}...")

    if successful:
        avg_time = sum(r["time"] for r in successful) / len(successful)
        sequential_time = sum(r["time"] for r in successful)
        speedup = sequential_time / total_time

        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ –∑–∞–ø—Ä–æ—Å: {avg_time:.3f}s")
        print(f"   ‚Ä¢ –£—Å–∫–æ—Ä–µ–Ω–∏–µ –æ—Ç –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞: {speedup:.1f}x")

    return len(successful) == len(results)


async def demo_incremental_parsing():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    print("\n5Ô∏è‚É£  –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ JSON")
    print("-" * 40)

    from kraken_llm.client.structured import IncrementalJSONParser

    parser = IncrementalJSONParser(Person)

    # –°–∏–º—É–ª–∏—Ä—É–µ–º –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–µ JSON –ø–æ —á–∞—Å—Ç—è–º
    json_parts = [
        '{"name": "Incremental',
        ' Parser", "age": 25,',
        ' "city": "Moscow",',
        ' "occupation": "Developer",',
        ' "active": true}'
    ]

    print("üìù –°–∏–º—É–ª–∏—Ä—É–µ–º –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–µ JSON –ø–æ —á–∞—Å—Ç—è–º:")

    for i, part in enumerate(json_parts, 1):
        print(f"   –ß–∞—Å—Ç—å {i}: '{part}'")
        result = parser.add_content(part)

        if result.is_complete:
            print(f"   ‚úÖ JSON –∑–∞–≤–µ—Ä—à–µ–Ω –ø–æ—Å–ª–µ —á–∞—Å—Ç–∏ {i}")
            print(f"   üìã –†–µ–∑—É–ª—å—Ç–∞—Ç: {result.parsed_object}")
            return True
        elif result.is_invalid:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {result.error}")
            return False
        else:
            print(
                f"   ‚è≥ –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ... (–±—É—Ñ–µ—Ä: {len(parser.content_buffer)} —Å–∏–º–≤–æ–ª–æ–≤)")

    # –§–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º
    final_result = parser.finalize()
    if final_result.is_complete:
        print(f"   ‚úÖ –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞: {final_result.parsed_object}")
        return True
    else:
        print(f"   ‚ùå –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å")
        return False


async def main():
    """–ì–ª–∞–≤–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è"""
    print("üéØ –ü–û–õ–ù–ê–Ø –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –†–ï–ê–õ–¨–ù–û–ì–û OUTLINES STREAMING")
    print("=" * 60)
    print("–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ JSON –ø–∞—Ä—Å–∏–Ω–≥–∞")
    print("–∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ streaming –¥–ª—è structured output")
    print()

    results = []

    # –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
    results.append(await demo_simple_streaming())
    results.append(await demo_complex_streaming())
    results.append(await demo_performance_comparison())
    results.append(await demo_concurrent_streaming())
    results.append(await demo_incremental_parsing())

    # –ü–æ–¥–≤–æ–¥–∏–º –∏—Ç–æ–≥–∏
    print("\n" + "=" * 60)
    print("üìä –ò–¢–û–ì–ò –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–ò")
    print("=" * 60)

    success_count = sum(results)
    total_demos = len(results)

    print(f"–£—Å–ø–µ—à–Ω—ã—Ö –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–π: {success_count}/{total_demos}")

    if success_count == total_demos:
        print("\nüéâ –í–°–ï –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–ò –ü–†–û–®–õ–ò –£–°–ü–ï–®–ù–û!")
        print("\n‚ú® –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ Outlines streaming:")
        print("   ‚Ä¢ ‚ö° –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ JSON –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏")
        print("   ‚Ä¢ üöÄ –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å—Ä–∞–≤–Ω–∏–º–∞—è –∏–ª–∏ –ª—É—á—à–µ non-streaming")
        print("   ‚Ä¢ üîÑ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")
        print("   ‚Ä¢ üõ°Ô∏è  –ù–∞–¥–µ–∂–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å fallback –º–µ—Ö–∞–Ω–∏–∑–º–∞–º–∏")
        print("   ‚Ä¢ üìä –î–µ—Ç–∞–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∏ –æ—Ç–ª–∞–¥–∫–∞")
        print("   ‚Ä¢ üéõÔ∏è  –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –ø—Ä–æ–¥–∞–∫—à–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
    elif success_count >= total_demos * 0.8:
        print("\n‚úÖ –ë–û–õ–¨–®–ò–ù–°–¢–í–û –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–ô –£–°–ü–ï–®–ù–´!")
        print("   –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –ø—Ä–æ–±–ª–µ–º–∞–º–∏")
    else:
        print("\n‚ö†Ô∏è  –¢–†–ï–ë–£–ï–¢–°–Ø –î–û–†–ê–ë–û–¢–ö–ê")
        print("   –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã, —Ç—Ä–µ–±—É—é—â–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è")

    print(f"\nüî¨ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è:")
    print("   ‚Ä¢ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π streaming –¥–ª—è Outlines")
    print("   ‚Ä¢ –°–æ–∑–¥–∞–Ω –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π JSON –ø–∞—Ä—Å–µ—Ä")
    print("   ‚Ä¢ –î–æ–±–∞–≤–ª–µ–Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏")
    print("   ‚Ä¢ –û–±–µ—Å–ø–µ—á–µ–Ω–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º API")
    print("   ‚Ä¢ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å")


if __name__ == "__main__":
    asyncio.run(main())

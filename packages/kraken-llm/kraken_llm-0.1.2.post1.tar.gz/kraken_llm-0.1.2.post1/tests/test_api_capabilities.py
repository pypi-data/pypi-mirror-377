#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π API endpoint.
"""

import asyncio
import json
import os
import aiohttp
from dotenv import load_dotenv

load_dotenv()

async def test_api_info():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± API."""
    endpoint = os.getenv("LLM_ENDPOINT")
    token = os.getenv("LLM_TOKEN")
    
    print(f"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ API: {endpoint}")
    
    # –¢–µ—Å—Ç 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
    async with aiohttp.ClientSession() as session:
        try:
            async with session.get(f"{endpoint}/") as response:
                print(f"GET /: {response.status}")
                text = await response.text()
                print(f"Response: {text[:200]}...")
        except Exception as e:
            print(f"GET /: –û—à–∏–±–∫–∞ - {e}")
        
        # –¢–µ—Å—Ç 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ /v1/models
        try:
            headers = {"Authorization": f"Bearer {token}"}
            async with session.get(f"{endpoint}/v1/models", headers=headers) as response:
                print(f"GET /v1/models: {response.status}")
                if response.status == 200:
                    data = await response.json()
                    print(f"Models: {json.dumps(data, indent=2)}")
                else:
                    text = await response.text()
                    print(f"Response: {text[:200]}...")
        except Exception as e:
            print(f"GET /v1/models: –û—à–∏–±–∫–∞ - {e}")
        
        # –¢–µ—Å—Ç 3: –ü—Ä–æ—Å—Ç–æ–π chat completion
        try:
            headers = {
                "Authorization": f"Bearer {token}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": os.getenv("LLM_MODEL"),
                "messages": [
                    {"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?"}
                ],
                "stream": False
            }
            
            async with session.post(f"{endpoint}/v1/chat/completions", 
                                  headers=headers, 
                                  json=payload) as response:
                print(f"POST /v1/chat/completions (non-stream): {response.status}")
                if response.status == 200:
                    data = await response.json()
                    print(f"Response: {json.dumps(data, indent=2)}")
                else:
                    text = await response.text()
                    print(f"Error response: {text[:500]}...")
        except Exception as e:
            print(f"POST /v1/chat/completions: –û—à–∏–±–∫–∞ - {e}")
        
        # –¢–µ—Å—Ç 4: Streaming chat completion
        try:
            payload = {
                "model": os.getenv("LLM_MODEL"),
                "messages": [
                    {"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?"}
                ],
                "stream": True
            }
            
            async with session.post(f"{endpoint}/v1/chat/completions", 
                                  headers=headers, 
                                  json=payload) as response:
                print(f"POST /v1/chat/completions (stream): {response.status}")
                if response.status == 200:
                    print("Streaming chunks:")
                    chunk_count = 0
                    async for line in response.content:
                        chunk_count += 1
                        line_str = line.decode('utf-8').strip()
                        if line_str and not line_str.startswith('data: [DONE]'):
                            print(f"  Chunk #{chunk_count}: {line_str[:100]}...")
                        if chunk_count >= 5:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤—ã–≤–æ–¥
                            print("  ... (–æ—Å—Ç–∞–ª—å–Ω—ã–µ chunks –ø—Ä–æ–ø—É—â–µ–Ω—ã)")
                            break
                else:
                    text = await response.text()
                    print(f"Error response: {text[:500]}...")
        except Exception as e:
            print(f"POST /v1/chat/completions (stream): –û—à–∏–±–∫–∞ - {e}")
        
        # –¢–µ—Å—Ç 5: Tool calling
        try:
            payload = {
                "model": os.getenv("LLM_MODEL"),
                "messages": [
                    {"role": "user", "content": "–ö–∞–∫–∞—è –ø–æ–≥–æ–¥–∞ –≤ –ú–æ—Å–∫–≤–µ? –ò—Å–ø–æ–ª—å–∑—É–π —Ñ—É–Ω–∫—Ü–∏—é get_weather."}
                ],
                "tools": [
                    {
                        "type": "function",
                        "function": {
                            "name": "get_weather",
                            "description": "–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–≥–æ–¥–µ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º –≥–æ—Ä–æ–¥–µ",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "city": {
                                        "type": "string",
                                        "description": "–ù–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞"
                                    }
                                },
                                "required": ["city"]
                            }
                        }
                    }
                ],
                "tool_choice": "auto",
                "stream": False
            }
            
            async with session.post(f"{endpoint}/v1/chat/completions", 
                                  headers=headers, 
                                  json=payload) as response:
                print(f"POST /v1/chat/completions (tools): {response.status}")
                if response.status == 200:
                    data = await response.json()
                    print(f"Tool calling response: {json.dumps(data, indent=2)}")
                else:
                    text = await response.text()
                    print(f"Tool calling error: {text[:500]}...")
        except Exception as e:
            print(f"POST /v1/chat/completions (tools): –û—à–∏–±–∫–∞ - {e}")


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."""
    print("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π API")
    print("=" * 50)
    
    await test_api_info()
    
    print("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")


if __name__ == "__main__":
    asyncio.run(main())
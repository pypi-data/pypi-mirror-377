#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –Ω–∞—Ç–∏–≤–Ω–æ–≥–æ OpenAI structured output –≤ —Ä–µ–∂–∏–º–µ –±–µ–∑ Outlines.
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ response_format –≤–º–µ—Å—Ç–æ –ø—Ä–æ–º–ø—Ç–æ–≤.
"""

import asyncio
import os
import time
from typing import List, Dict, Any
from pydantic import BaseModel, Field

from kraken_llm.config.settings import LLMConfig
from kraken_llm.client.structured import StructuredLLMClient

from dotenv import load_dotenv

load_dotenv()

# –ú–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è


class PersonModel(BaseModel):
    """–ú–æ–¥–µ–ª—å —á–µ–ª–æ–≤–µ–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    name: str = Field(..., description="–ò–º—è —á–µ–ª–æ–≤–µ–∫–∞")
    age: int = Field(..., ge=0, le=150, description="–í–æ–∑—Ä–∞—Å—Ç —á–µ–ª–æ–≤–µ–∫–∞")
    city: str = Field(..., description="–ì–æ—Ä–æ–¥ –ø—Ä–æ–∂–∏–≤–∞–Ω–∏—è")
    occupation: str = Field(..., description="–ü—Ä–æ—Ñ–µ—Å—Å–∏—è")


class ProductModel(BaseModel):
    """–ú–æ–¥–µ–ª—å –ø—Ä–æ–¥—É–∫—Ç–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    name: str = Field(..., description="–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞")
    price: float = Field(..., ge=0, description="–¶–µ–Ω–∞ –ø—Ä–æ–¥—É–∫—Ç–∞")
    category: str = Field(..., description="–ö–∞—Ç–µ–≥–æ—Ä–∏—è –ø—Ä–æ–¥—É–∫—Ç–∞")
    in_stock: bool = Field(..., description="–ù–∞–ª–∏—á–∏–µ –Ω–∞ —Å–∫–ª–∞–¥–µ")


async def test_native_openai_structured_output():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Ç–∏–≤–Ω–æ–≥–æ OpenAI structured output"""
    print("üîß –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Ç–∏–≤–Ω–æ–≥–æ OpenAI structured output...")

    config = LLMConfig(
        endpoint=os.getenv("LLM_ENDPOINT"),
        api_key=os.getenv("LLM_TOKEN"),
        model=os.getenv("LLM_MODEL")
    )
    # –û—Ç–∫–ª—é—á–∞–µ–º Outlines –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–∞—Ç–∏–≤–Ω–æ–≥–æ OpenAI
    config.outlines_so_mode = False
    client = StructuredLLMClient(config)

    # –ë–æ–ª–µ–µ —è–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —Ñ–æ—Ä–º–∞—Ç–∞
    messages = [{
        "role": "user",
        "content": """Create JSON data for a person with these details:
Name: Elena Vasilyeva
Age: 32
City: Novosibirsk  
Occupation: Doctor

Return only valid JSON with English keys: name, age, city, occupation"""
    }]

    try:
        start_time = time.time()
        result = await client.chat_completion_structured(
            messages=messages,
            response_model=PersonModel,
            max_tokens=200,
            temperature=0.1
        )
        duration = time.time() - start_time

        if isinstance(result, PersonModel):
            print(
                f"‚úÖ –ù–∞—Ç–∏–≤–Ω—ã–π OpenAI SO —Ä–∞–±–æ—Ç–∞–µ—Ç: {result.name}, {result.age} –ª–µ—Ç, {result.city}")
            print(f"   ‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.2f}—Å")
            return True
        else:
            print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {type(result)}")
            return False

    except Exception as e:
        print(
            f"‚ö†Ô∏è  –ù–∞—Ç–∏–≤–Ω—ã–π OpenAI SO –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è —Å–µ—Ä–≤–µ—Ä–æ–º: {type(e).__name__}")
        print(f"   –≠—Ç–æ –æ–∂–∏–¥–∞–µ–º–æ –¥–ª—è —Å–µ—Ä–≤–µ—Ä–æ–≤ –±–µ–∑ –Ω–∞—Ç–∏–≤–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏ response_format")
        return False


async def test_native_vs_outlines_comparison():
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–∞—Ç–∏–≤–Ω–æ–≥–æ OpenAI SO —Å Outlines"""
    print("\n‚öñÔ∏è  –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–∞—Ç–∏–≤–Ω–æ–≥–æ OpenAI SO —Å Outlines...")

    # –¢–µ—Å—Ç –Ω–∞—Ç–∏–≤–Ω–æ–≥–æ OpenAI
    config_native = LLMConfig(
        endpoint=os.getenv("LLM_ENDPOINT"),
        api_key=os.getenv("LLM_TOKEN"),
        model=os.getenv("LLM_MODEL")
    )
    config_native.outlines_so_mode = False
    client_native = StructuredLLMClient(config_native)

    # –¢–µ—Å—Ç Outlines
    config_outlines = LLMConfig(
        endpoint=os.getenv("LLM_ENDPOINT"),
        api_key=os.getenv("LLM_TOKEN"),
        model=os.getenv("LLM_MODEL")
    )
    config_outlines.outlines_so_mode = True
    client_outlines = StructuredLLMClient(config_outlines)

    messages = [{
        "role": "user",
        "content": "–°–æ–∑–¥–∞–π –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–¥—É–∫—Ç–∞: Samsung Galaxy, —Ü–µ–Ω–∞ 45000, –∫–∞—Ç–µ–≥–æ—Ä–∏—è –°–º–∞—Ä—Ç—Ñ–æ–Ω—ã, –≤ –Ω–∞–ª–∏—á–∏–∏"
    }]

    results = {}

    # –ë–æ–ª–µ–µ —è–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –Ω–∞—Ç–∏–≤–Ω–æ–≥–æ OpenAI
    native_messages = [{
        "role": "user",
        "content": """Create JSON for product:
Name: Samsung Galaxy
Price: 45000
Category: Smartphones  
In stock: true

Return only valid JSON with English keys: name, price, category, in_stock"""
    }]

    # –¢–µ—Å—Ç –Ω–∞—Ç–∏–≤–Ω–æ–≥–æ OpenAI
    try:
        start_time = time.time()
        result_native = await client_native.chat_completion_structured(
            messages=native_messages,
            response_model=ProductModel,
            max_tokens=200,
            temperature=0.1
        )
        native_time = time.time() - start_time

        if isinstance(result_native, ProductModel):
            results["native"] = {
                "success": True,
                "result": result_native,
                "time": native_time
            }
            print(
                f"‚úÖ –ù–∞—Ç–∏–≤–Ω—ã–π OpenAI: {result_native.name}, —Ü–µ–Ω–∞ {result_native.price} ({native_time:.2f}—Å)")
        else:
            results["native"] = {
                "success": False, "error": f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø: {type(result_native)}"}
            print(f"‚ùå –ù–∞—Ç–∏–≤–Ω—ã–π OpenAI: –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø {type(result_native)}")

    except Exception as e:
        results["native"] = {"success": False, "error": str(e)}
        print(f"‚ö†Ô∏è  –ù–∞—Ç–∏–≤–Ω—ã–π OpenAI: –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è ({type(e).__name__})")

    # –¢–µ—Å—Ç Outlines
    try:
        start_time = time.time()
        result_outlines = await client_outlines.chat_completion_structured(
            messages=messages,
            response_model=ProductModel,
            max_tokens=200,
            temperature=0.1
        )
        outlines_time = time.time() - start_time

        if isinstance(result_outlines, ProductModel):
            results["outlines"] = {
                "success": True,
                "result": result_outlines,
                "time": outlines_time
            }
            print(
                f"‚úÖ Outlines: {result_outlines.name}, —Ü–µ–Ω–∞ {result_outlines.price} ({outlines_time:.2f}—Å)")
        else:
            results["outlines"] = {
                "success": False, "error": f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø: {type(result_outlines)}"}
            print(f"‚ùå Outlines: –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø {type(result_outlines)}")

    except Exception as e:
        results["outlines"] = {"success": False, "error": str(e)}
        print(f"‚ùå Outlines: –æ—à–∏–±–∫–∞ {e}")

    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    native_success = results.get("native", {}).get("success", False)
    outlines_success = results.get("outlines", {}).get("success", False)

    if native_success and outlines_success:
        native_time = results["native"]["time"]
        outlines_time = results["outlines"]["time"]
        faster = "–Ω–∞—Ç–∏–≤–Ω—ã–π OpenAI" if native_time < outlines_time else "Outlines"
        time_diff = abs(native_time - outlines_time)
        print(f"üìä –û–±–∞ —Ä–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç–∞—é—Ç, –±—ã—Å—Ç—Ä–µ–µ: {faster} –Ω–∞ {time_diff:.2f}—Å")
        return True
    elif native_success:
        print(f"üìä –†–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –Ω–∞—Ç–∏–≤–Ω—ã–π OpenAI")
        return True
    elif outlines_success:
        print(f"üìä –†–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ Outlines")
        return True
    else:
        print(f"üìä –û–±–∞ —Ä–µ–∂–∏–º–∞ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç")
        return False


async def test_complex_schema_native():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ª–æ–∂–Ω–æ–π —Å—Ö–µ–º—ã —Å –Ω–∞—Ç–∏–≤–Ω—ã–º OpenAI SO"""
    print("\nüî¨ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ª–æ–∂–Ω–æ–π —Å—Ö–µ–º—ã —Å –Ω–∞—Ç–∏–≤–Ω—ã–º OpenAI SO...")

    class ComplexModel(BaseModel):
        """–°–ª–æ–∂–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        id: int = Field(..., description="–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä")
        title: str = Field(..., description="–ó–∞–≥–æ–ª–æ–≤–æ–∫")
        tags: List[str] = Field(..., description="–¢–µ–≥–∏")
        metadata: Dict[str, Any] = Field(..., description="–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ")
        is_active: bool = Field(..., description="–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å")
        price: float = Field(..., description="–¶–µ–Ω–∞")

    config = LLMConfig(
        endpoint=os.getenv("LLM_ENDPOINT"),
        api_key=os.getenv("LLM_TOKEN"),
        model=os.getenv("LLM_MODEL")
    )
    config.outlines_so_mode = False
    client = StructuredLLMClient(config)

    messages = [{
        "role": "user",
        "content": """
–°–æ–∑–¥–∞–π –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ç–∞—Ç—å–∏:
- ID: 123
- –ó–∞–≥–æ–ª–æ–≤–æ–∫: "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –≤ 2024"
- –¢–µ–≥–∏: ["AI", "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", "–±—É–¥—É—â–µ–µ"]
- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: –∞–≤—Ç–æ—Ä "–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤", –∫–∞—Ç–µ–≥–æ—Ä–∏—è "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏"
- –ê–∫—Ç–∏–≤–Ω–∞: –¥–∞
- –¶–µ–Ω–∞: 0 (–±–µ—Å–ø–ª–∞—Ç–Ω–∞—è)
"""
    }]

    try:
        result = await client.chat_completion_structured(
            messages=messages,
            response_model=ComplexModel,
            max_tokens=300,
            temperature=0.1
        )

        if isinstance(result, ComplexModel):
            print(
                f"‚úÖ –°–ª–æ–∂–Ω–∞—è —Å—Ö–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç: ID {result.id}, —Ç–µ–≥–∏: {len(result.tags)}, –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {len(result.metadata)}")
            return True
        else:
            print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {type(result)}")
            return False

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ —Å–ª–æ–∂–Ω–æ–π —Å—Ö–µ–º–æ–π: {e}")
        return False


async def test_english_keys_enforcement():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–Ω—É–∂–¥–µ–Ω–∏—è –∫ –∞–Ω–≥–ª–∏–π—Å–∫–∏–º –∫–ª—é—á–∞–º"""
    print("\nüåê –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–Ω—É–∂–¥–µ–Ω–∏—è –∫ –∞–Ω–≥–ª–∏–π—Å–∫–∏–º –∫–ª—é—á–∞–º...")

    config = LLMConfig(
        endpoint=os.getenv("LLM_ENDPOINT"),
        api_key=os.getenv("LLM_TOKEN"),
        model=os.getenv("LLM_MODEL")
    )
    config.outlines_so_mode = False
    client = StructuredLLMClient(config)

    # –Ø–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ–º –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –∫–ª—é—á–µ–π
    messages = [{
        "role": "user",
        "content": """Create JSON for person with these Russian details:
–ò–º—è: –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –ò–≤–∞–Ω–æ–≤ (Name: Alexander Ivanov)
–í–æ–∑—Ä–∞—Å—Ç: 29 –ª–µ—Ç (Age: 29)
–ì–æ—Ä–æ–¥: –ö–∞–∑–∞–Ω—å (City: Kazan)
–ü—Ä–æ—Ñ–µ—Å—Å–∏—è: –ü—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç (Occupation: Programmer)

IMPORTANT: Use only English keys in JSON: name, age, city, occupation
Return only valid JSON."""
    }]

    try:
        result = await client.chat_completion_structured(
            messages=messages,
            response_model=PersonModel,
            max_tokens=200,
            temperature=0.1
        )

        if isinstance(result, PersonModel):
            print(
                f"‚úÖ –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ –∫–ª—é—á–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è: {result.name}, {result.age} –ª–µ—Ç")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –ø–æ–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω—ã (–∑–Ω–∞—á–∏—Ç –∫–ª—é—á–∏ –±—ã–ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏)
            if all([result.name, result.age > 0, result.city, result.occupation]):
                print("‚úÖ –í—Å–µ –ø–æ–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã —Å –∞–Ω–≥–ª–∏–π—Å–∫–∏–º–∏ –∫–ª—é—á–∞–º–∏")
                return True
            else:
                print("‚ö†Ô∏è  –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ª—è –Ω–µ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã")
                return False
        else:
            print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {type(result)}")
            return False

    except Exception as e:
        print(
            f"‚ö†Ô∏è  –ü—Ä–∏–Ω—É–∂–¥–µ–Ω–∏–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –∫–ª—é—á–µ–π –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç: {type(e).__name__}")
        print("   –≠—Ç–æ –æ–∂–∏–¥–∞–µ–º–æ –±–µ–∑ –Ω–∞—Ç–∏–≤–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏ response_format")
        return False


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞—Ç–∏–≤–Ω–æ–≥–æ OpenAI SO"""
    print("üîß –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–ê–¢–ò–í–ù–û–ì–û OPENAI STRUCTURED OUTPUT")
    print("="*80)
    print("üéØ –¶–µ–ª—å: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ response_format –≤–º–µ—Å—Ç–æ –ø—Ä–æ–º–ø—Ç–æ–≤")
    print("üîß –†–µ–∂–∏–º: outlines_so_mode = False (–Ω–∞—Ç–∏–≤–Ω—ã–π OpenAI)")
    print("="*80)

    start_time = time.time()
    results = []

    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ —Ç–µ—Å—Ç—ã
    results.append(await test_native_openai_structured_output())
    results.append(await test_native_vs_outlines_comparison())
    results.append(await test_complex_schema_native())
    results.append(await test_english_keys_enforcement())

    # –ü–æ–¥–≤–æ–¥–∏–º –∏—Ç–æ–≥–∏
    duration = time.time() - start_time
    success_count = sum(results)
    total_tests = len(results)
    success_rate = success_count / total_tests

    print(f"\n{'='*80}")
    print(f"üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ù–ê–¢–ò–í–ù–û–ì–û OPENAI SO")
    print(f"{'='*80}")
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.2f} —Å–µ–∫—É–Ω–¥")
    print(f"üìà –í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {total_tests}")
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {success_count}")
    print(f"‚ùå –ù–µ—É–¥–∞—á–Ω–æ: {total_tests - success_count}")
    print(f"üìä –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {success_rate*100:.1f}%")

    if success_rate >= 0.9:
        print(f"\nüéâ –û–¢–õ–ò–ß–ù–û! –ù–∞—Ç–∏–≤–Ω—ã–π OpenAI structured output —Ä–∞–±–æ—Ç–∞–µ—Ç –∏–¥–µ–∞–ª—å–Ω–æ!")
        print(f"‚úÖ response_format –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        print(f"‚úÖ –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ –∫–ª—é—á–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è")
        print(f"‚úÖ –°–ª–æ–∂–Ω—ã–µ —Å—Ö–µ–º—ã –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è")
    elif success_rate >= 0.7:
        print(f"\nüëç –•–û–†–û–®–û! –ù–∞—Ç–∏–≤–Ω—ã–π OpenAI SO —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø—Ä–æ–±–ª–µ–º–∞–º–∏")
        print(f"üîß –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞")
    elif success_rate >= 0.5:
        print(f"\n‚ö†Ô∏è  –ß–ê–°–¢–ò–ß–ù–ê–Ø –ü–û–î–î–ï–†–ñ–ö–ê! –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ä–∞–±–æ—Ç–∞—é—Ç")
        print(f"ÔøΩ –°–µ—Ä–≤–µ—Ä –º—Ç–æ–∂–µ—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å –Ω–∞—Ç–∏–≤–Ω—ã–π response_format")
        print(f"üîß –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Outlines —Ä–µ–∂–∏–º –¥–ª—è –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    elif success_rate >= 0.25:
        print(f"\n‚ö†Ô∏è  –û–ì–†–ê–ù–ò–ß–ï–ù–ù–ê–Ø –ü–û–î–î–ï–†–ñ–ö–ê! –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å")
        print(f"üö® –°–µ—Ä–≤–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–∞—Ç–∏–≤–Ω—ã–π OpenAI response_format")
        print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Outlines —Ä–µ–∂–∏–º (outlines_so_mode = True)")
    else:
        print(f"\n‚ùå –ù–ï–¢ –ü–û–î–î–ï–†–ñ–ö–ò! –ù–∞—Ç–∏–≤–Ω—ã–π OpenAI SO –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")
        print(f"üö® –°–µ—Ä–≤–µ—Ä –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç response_format")
        print(f"‚úÖ –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Outlines —Ä–µ–∂–∏–º")

    print(f"\nüìã –ü–†–û–í–ï–†–ï–ù–ù–´–ï –í–û–ó–ú–û–ñ–ù–û–°–¢–ò:")
    print("- ‚úÖ –ù–∞—Ç–∏–≤–Ω—ã–π OpenAI structured output")
    print("- ‚úÖ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å Outlines —Ä–µ–∂–∏–º–æ–º")
    print("- ‚úÖ –°–ª–æ–∂–Ω—ã–µ JSON —Å—Ö–µ–º—ã")
    print("- ‚úÖ –ü—Ä–∏–Ω—É–∂–¥–µ–Ω–∏–µ –∫ –∞–Ω–≥–ª–∏–π—Å–∫–∏–º –∫–ª—é—á–∞–º")
    print("- ‚úÖ response_format –≤–º–µ—Å—Ç–æ –ø—Ä–æ–º–ø—Ç–æ–≤")

    print(f"\nüèÅ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–ê–¢–ò–í–ù–û–ì–û OPENAI SO –ó–ê–í–ï–†–®–ï–ù–û!")


if __name__ == "__main__":
    asyncio.run(main())

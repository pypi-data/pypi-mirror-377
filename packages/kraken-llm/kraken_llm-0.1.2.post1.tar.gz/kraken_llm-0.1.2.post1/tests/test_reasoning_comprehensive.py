#!/usr/bin/env python3
"""
–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Ç–µ—Å—Ç ReasoningLLMClient –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π —Ä–∞—Å—Å—É–∂–¥–∞—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π.

–≠—Ç–æ—Ç —Ç–µ—Å—Ç –ø—Ä–æ–≤–µ—Ä—è–µ—Ç:
- –ë–∞–∑–æ–≤–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ —Å Chain of Thought
- –†–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã –∑–∞–¥–∞—á (math, logic, coding, general)
- –ü–æ—Ç–æ–∫–æ–≤—ã–π —Ä–µ–∂–∏–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
- –í–∞–ª–∏–¥–∞—Ü–∏—é —Ü–µ–ø–æ—á–µ–∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
- –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
- –ö–∞—Å—Ç–æ–º–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã –ø—Ä–æ–º–ø—Ç–æ–≤
- –ü–æ–¥—Å—á–µ—Ç reasoning —Ç–æ–∫–µ–Ω–æ–≤
"""

import asyncio
import time
import os
from typing import List, Dict

from kraken_llm.client.reasoning import ReasoningLLMClient, ReasoningConfig, ReasoningChain
from kraken_llm.config.settings import LLMConfig
from kraken_llm.exceptions.validation import ValidationError

from dotenv import load_dotenv

load_dotenv()

async def test_basic_reasoning():
    """–¢–µ—Å—Ç –±–∞–∑–æ–≤–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è"""
    print("=== –¢–µ—Å—Ç –±–∞–∑–æ–≤–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è ===")
    
    config = LLMConfig(
        endpoint = os.getenv("LLM_ENDPOINT"),
        api_key = os.getenv("LLM_TOKEN"),
        model = os.getenv("LLM_MODEL"),
        temperature=0.1
    )
    
    reasoning_config = ReasoningConfig(
        enable_cot=True,
        max_reasoning_steps=5,
        extract_confidence=True
    )
    
    client = ReasoningLLMClient(config, reasoning_config)
    
    messages = [
        {
            "role": "user",
            "content": "–ï—Å–ª–∏ –≤ –∫–æ—Ä–∑–∏–Ω–µ 12 —è–±–ª–æ–∫, –∏ —è —Å—ä–µ–ª 3, –∞ –ø–æ—Ç–æ–º –∫—É–ø–∏–ª –µ—â–µ 5, —Å–∫–æ–ª—å–∫–æ —è–±–ª–æ–∫ —Å—Ç–∞–ª–æ –≤ –∫–æ—Ä–∑–∏–Ω–µ?"
        }
    ]
    
    try:
        start_time = time.time()
        chain = await client.reasoning_completion(
            messages=messages,
            problem_type="math",
            enable_streaming=False
        )
        end_time = time.time()
        
        print(f"‚úì –†–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –∑–∞ {end_time - start_time:.2f}s")
        print(f"‚úì –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤: {len(chain.steps)}")
        print(f"‚úì –ï—Å—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: {bool(chain.final_answer)}")
        print(f"‚úì –í—Ä–µ–º—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∑–∞–ø–∏—Å–∞–Ω–æ: {chain.reasoning_time is not None}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —à–∞–≥–æ–≤
        for i, step in enumerate(chain.steps):
            assert step.step_number == i + 1, f"–ù–µ–≤–µ—Ä–Ω–∞—è –Ω—É–º–µ—Ä–∞—Ü–∏—è —à–∞–≥–∞: {step.step_number} != {i + 1}"
            assert step.thought, f"–®–∞–≥ {step.step_number} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è"
        
        print(f"‚úì –í—Å–µ —à–∞–≥–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω—ã")
        print(f"–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: {chain.final_answer}")
        print()
        
        return True
        
    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ –≤ –±–∞–∑–æ–≤–æ–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–∏: {e}")
        return False


async def test_math_reasoning():
    """–¢–µ—Å—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è"""
    print("=== –¢–µ—Å—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è ===")
    
    config = LLMConfig(
        endpoint = os.getenv("LLM_ENDPOINT"),
        api_key = os.getenv("LLM_TOKEN"),
        model = os.getenv("LLM_MODEL")
    )
    
    client = ReasoningLLMClient(config)
    
    messages = [
        {
            "role": "user",
            "content": """
            –†–µ—à–∏ —Å–∏—Å—Ç–µ–º—É —É—Ä–∞–≤–Ω–µ–Ω–∏–π:
            x + y = 10
            2x - y = 5
            –ù–∞–π–¥–∏ x –∏ y, –ø–æ–∫–∞–∑–∞–≤ –≤—Å–µ —à–∞–≥–∏ —Ä–µ—à–µ–Ω–∏—è.
            """
        }
    ]
    
    try:
        chain = await client.reasoning_completion(
            messages=messages,
            problem_type="math",
            enable_streaming=False
        )
        
        print(f"‚úì –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–¥–∞—á–∞ —Ä–µ—à–µ–Ω–∞")
        print(f"‚úì –®–∞–≥–æ–≤ —Ä–µ—à–µ–Ω–∏—è: {len(chain.steps)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≤ —à–∞–≥–∞—Ö
        has_calculations = any(
            step.action and any(op in step.action for op in ['+', '-', '*', '/', '='])
            for step in chain.steps
        )
        
        if has_calculations:
            print("‚úì –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≤ —à–∞–≥–∞—Ö")
        else:
            print("‚ö† –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã —è–≤–Ω–æ")
        
        print(f"–†–µ—à–µ–Ω–∏–µ: {chain.final_answer}")
        print()
        
        return True
        
    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ –≤ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–∏: {e}")
        return False


async def test_logic_reasoning():
    """–¢–µ—Å—Ç –ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è"""
    print("=== –¢–µ—Å—Ç –ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è ===")
    
    config = LLMConfig(
        endpoint = os.getenv("LLM_ENDPOINT"),
        api_key = os.getenv("LLM_TOKEN"),
        model = os.getenv("LLM_MODEL")
    )
    
    client = ReasoningLLMClient(config)
    
    messages = [
        {
            "role": "user",
            "content": """
            –î–∞–Ω–æ:
            - –í—Å–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç—ã –ª—é–±—è—Ç –∫–æ—Ñ–µ
            - –ê–Ω–Ω–∞ - –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç
            - –ï—Å–ª–∏ –∫—Ç–æ-—Ç–æ –ª—é–±–∏—Ç –∫–æ—Ñ–µ, —Ç–æ –æ–Ω –Ω–µ —Å–ø–∏—Ç –ø–æ –Ω–æ—á–∞–º
            
            –í–æ–ø—Ä–æ—Å: –°–ø–∏—Ç –ª–∏ –ê–Ω–Ω–∞ –ø–æ –Ω–æ—á–∞–º? –û–±—ä—è—Å–Ω–∏ –ª–æ–≥–∏—á–µ—Å–∫—É—é —Ü–µ–ø–æ—á–∫—É.
            """
        }
    ]
    
    try:
        chain = await client.reasoning_completion(
            messages=messages,
            problem_type="logic",
            enable_streaming=False
        )
        
        print(f"‚úì –õ–æ–≥–∏—á–µ—Å–∫–∞—è –∑–∞–¥–∞—á–∞ —Ä–µ—à–µ–Ω–∞")
        print(f"‚úì –®–∞–≥–æ–≤ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è: {len(chain.steps)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Å–≤—è–∑–∫–∏
        logical_words = ['–µ—Å–ª–∏', '—Ç–æ', '—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ', '–∑–Ω–∞—á–∏—Ç', '–ø–æ—ç—Ç–æ–º—É', '—Ç–∞–∫ –∫–∞–∫']
        has_logic = any(
            any(word in step.thought.lower() for word in logical_words)
            for step in chain.steps
        )
        
        if has_logic:
            print("‚úì –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Å–≤—è–∑–∫–∏ –≤ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–∏")
        else:
            print("‚ö† –õ–æ–≥–∏—á–µ—Å–∫–∏–µ —Å–≤—è–∑–∫–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã —è–≤–Ω–æ")
        
        print(f"–õ–æ–≥–∏—á–µ—Å–∫–∏–π –≤—ã–≤–æ–¥: {chain.final_answer}")
        print()
        
        return True
        
    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ –≤ –ª–æ–≥–∏—á–µ—Å–∫–æ–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–∏: {e}")
        return False


async def test_coding_reasoning():
    """–¢–µ—Å—Ç —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –ø—Ä–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏"""
    print("=== –¢–µ—Å—Ç —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –ø—Ä–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏ ===")
    
    config = LLMConfig(
        endpoint = os.getenv("LLM_ENDPOINT"),
        api_key = os.getenv("LLM_TOKEN"),
        model = os.getenv("LLM_MODEL")
    )
    
    client = ReasoningLLMClient(config)
    
    messages = [
        {
            "role": "user",
            "content": """
            –ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤—Ç–æ—Ä–æ–≥–æ –ø–æ –≤–µ–ª–∏—á–∏–Ω–µ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤ –º–∞—Å—Å–∏–≤–µ.
            –û–±—ä—è—Å–Ω–∏ –∞–ª–≥–æ—Ä–∏—Ç–º –ø–æ—à–∞–≥–æ–≤–æ –∏ –ø–æ–∫–∞–∂–∏ –∫–æ–¥.
            """
        }
    ]
    
    try:
        chain = await client.reasoning_completion(
            messages=messages,
            problem_type="coding",
            enable_streaming=False
        )
        
        print(f"‚úì –ó–∞–¥–∞—á–∞ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ—à–µ–Ω–∞")
        print(f"‚úì –®–∞–≥–æ–≤ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: {len(chain.steps)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–¥–∞
        has_code = any(
            step.action and any(keyword in step.action for keyword in ['def', 'for', 'if', 'return'])
            for step in chain.steps
        )
        
        if has_code:
            print("‚úì –û–±–Ω–∞—Ä—É–∂–µ–Ω –∫–æ–¥ –≤ —à–∞–≥–∞—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è")
        else:
            print("‚ö† –ö–æ–¥ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω –≤ —à–∞–≥–∞—Ö")
        
        print(f"–†–µ—à–µ–Ω–∏–µ: {chain.final_answer[:200]}...")
        print()
        
        return True
        
    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ –≤ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–∏ –æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        return False


async def test_streaming_reasoning():
    """–¢–µ—Å—Ç –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è"""
    print("=== –¢–µ—Å—Ç –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è ===")
    
    config = LLMConfig(
        endpoint = os.getenv("LLM_ENDPOINT"),
        api_key = os.getenv("LLM_TOKEN"),
        model = os.getenv("LLM_MODEL")
    )
    
    client = ReasoningLLMClient(config)
    
    messages = [
        {
            "role": "user",
            "content": "–û–±—ä—è—Å–Ω–∏ –ø–æ—à–∞–≥–æ–≤–æ, –∫–∞–∫ –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å –æ–º–ª–µ—Ç. –ö–∞–∂–¥—ã–π —à–∞–≥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–º."
        }
    ]
    
    try:
        print("–ü–æ–ª—É—á–µ–Ω–∏–µ —à–∞–≥–æ–≤ –≤ –ø–æ—Ç–æ–∫–æ–≤–æ–º —Ä–µ–∂–∏–º–µ:")
        
        steps_received = 0
        start_time = time.time()
        
        async for step in client.reasoning_completion(
            messages=messages,
            problem_type="general",
            enable_streaming=True
        ):
            steps_received += 1
            print(f"  –ü–æ–ª—É—á–µ–Ω —à–∞–≥ {step.step_number}: {step.thought[:50]}...")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —à–∞–≥–∞
            assert step.step_number > 0, "–ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä —à–∞–≥–∞"
            assert step.thought, "–®–∞–≥ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è"
        
        end_time = time.time()
        
        print(f"‚úì –ü–æ—Ç–æ–∫–æ–≤–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {end_time - start_time:.2f}s")
        print(f"‚úì –ü–æ–ª—É—á–µ–Ω–æ —à–∞–≥–æ–≤: {steps_received}")
        print()
        
        return steps_received > 0
        
    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ –≤ –ø–æ—Ç–æ–∫–æ–≤–æ–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–∏: {e}")
        return False


async def test_reasoning_validation():
    """–¢–µ—Å—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ü–µ–ø–æ—á–µ–∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π"""
    print("=== –¢–µ—Å—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π ===")
    
    config = LLMConfig(
        endpoint = os.getenv("LLM_ENDPOINT"),
        api_key = os.getenv("LLM_TOKEN"),
        model = os.getenv("LLM_MODEL")
    )
    
    reasoning_config = ReasoningConfig(
        require_step_validation=True,
        max_reasoning_steps=4
    )
    
    client = ReasoningLLMClient(config, reasoning_config)
    
    messages = [
        {
            "role": "user",
            "content": "–û–±—ä—è—Å–Ω–∏, –ø–æ—á–µ–º—É 2+2=4. –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ—Å—Ç—ã–µ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ —à–∞–≥–∏."
        }
    ]
    
    try:
        chain = await client.reasoning_completion(
            messages=messages,
            problem_type="math",
            enable_streaming=False
        )
        
        print(f"‚úì –†–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –≤—ã–ø–æ–ª–Ω–µ–Ω–æ")
        print(f"‚úì –®–∞–≥–æ–≤: {len(chain.steps)}")
        print(f"‚úì –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ")
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        await client._validate_reasoning_chain(chain)
        print("‚úì –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ—à–ª–∞")
        print()
        
        return True
        
    except ValidationError as e:
        print(f"‚ö† –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–æ–∂–∏–¥–∞–µ–º–æ): {e}")
        return True  # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç
        
    except Exception as e:
        print(f"‚úó –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
        return False


async def test_custom_reasoning_template():
    """–¢–µ—Å—Ç –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ —à–∞–±–ª–æ–Ω–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π"""
    print("=== –¢–µ—Å—Ç –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ —à–∞–±–ª–æ–Ω–∞ ===")
    
    config = LLMConfig(
        endpoint = os.getenv("LLM_ENDPOINT"),
        api_key = os.getenv("LLM_TOKEN"),
        model = os.getenv("LLM_MODEL")
    )
    
    custom_template = """
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–æ–±–ª–µ–º—É –ø–æ —Å—Ö–µ–º–µ SWOT:
1. Strengths (–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã)
2. Weaknesses (–°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã)  
3. Opportunities (–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏)
4. Threats (–£–≥—Ä–æ–∑—ã)

–§–æ—Ä–º–∞—Ç:
–®–∞–≥ 1: [–∞–Ω–∞–ª–∏–∑ —Å–∏–ª—å–Ω—ã—Ö —Å—Ç–æ—Ä–æ–Ω]
–ê–Ω–∞–ª–∏–∑: [—á—Ç–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ]
–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: [0.0-1.0]

–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: [–æ–±—â–∏–π SWOT –∞–Ω–∞–ª–∏–∑]
"""
    
    reasoning_config = ReasoningConfig(
        reasoning_prompt_template=custom_template,
        max_reasoning_steps=4
    )
    
    client = ReasoningLLMClient(config, reasoning_config)
    
    messages = [
        {
            "role": "user",
            "content": "–ü—Ä–æ–≤–µ–¥–∏ SWOT –∞–Ω–∞–ª–∏–∑ –¥–ª—è –º–∞–ª–æ–≥–æ IT —Å—Ç–∞—Ä—Ç–∞–ø–∞, —Ä–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞—é—â–µ–≥–æ –º–æ–±–∏–ª—å–Ω—ã–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."
        }
    ]
    
    try:
        chain = await client.reasoning_completion(
            messages=messages,
            problem_type="general",
            enable_streaming=False
        )
        
        print(f"‚úì –ö–∞—Å—Ç–æ–º–Ω—ã–π —à–∞–±–ª–æ–Ω –ø—Ä–∏–º–µ–Ω–µ–Ω")
        print(f"‚úì –®–∞–≥–æ–≤ –∞–Ω–∞–ª–∏–∑–∞: {len(chain.steps)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è SWOT —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è
        swot_terms = ['—Å–∏–ª—å–Ω', '—Å–ª–∞–±', '–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç', '—É–≥—Ä–æ–∑', 'swot']
        has_swot = any(
            any(term in step.thought.lower() for term in swot_terms)
            for step in chain.steps
        )
        
        if has_swot:
            print("‚úì SWOT —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –≤ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–∏")
        else:
            print("‚ö† SWOT —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —è–≤–Ω–æ")
        
        print(f"SWOT –∞–Ω–∞–ª–∏–∑: {chain.final_answer[:150]}...")
        print()
        
        return True
        
    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ –≤ –∫–∞—Å—Ç–æ–º–Ω–æ–º —à–∞–±–ª–æ–Ω–µ: {e}")
        return False


async def test_reasoning_quality_analysis():
    """–¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π"""
    print("=== –¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π ===")
    
    config = LLMConfig(
        endpoint = os.getenv("LLM_ENDPOINT"),
        api_key = os.getenv("LLM_TOKEN"),
        model = os.getenv("LLM_MODEL")
    )
    
    client = ReasoningLLMClient(config)
    
    messages = [
        {
            "role": "user",
            "content": "–û–±—ä—è—Å–Ω–∏, –ø–æ—á–µ–º—É –≤–∞–∂–Ω–æ –∏–∑—É—á–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é. –ü—Ä–∏–≤–µ–¥–∏ 3-4 –≤–µ—Å–∫–∏—Ö –∞—Ä–≥—É–º–µ–Ω—Ç–∞."
        }
    ]
    
    try:
        # –í—ã–ø–æ–ª–Ω—è–µ–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ
        chain = await client.reasoning_completion(
            messages=messages,
            problem_type="general",
            enable_streaming=False
        )
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
        quality_analysis = await client.analyze_reasoning_quality(chain)
        
        print(f"‚úì –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω")
        print(f"‚úì –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤: {quality_analysis['total_steps']}")
        print(f"‚úì –ü–æ–ª–Ω–æ—Ç–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è: {quality_analysis['reasoning_completeness']:.2f}")
        print(f"‚úì –õ–æ–≥–∏—á–µ—Å–∫–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {quality_analysis['logical_consistency']:.2f}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∞–Ω–∞–ª–∏–∑–∞
        required_keys = ['total_steps', 'reasoning_completeness', 'logical_consistency', 'step_quality_scores']
        for key in required_keys:
            assert key in quality_analysis, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á –≤ –∞–Ω–∞–ª–∏–∑–µ: {key}"
        
        print(f"‚úì –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞
        for step_quality in quality_analysis['step_quality_scores']:
            assert 'step_number' in step_quality, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–æ–º–µ—Ä —à–∞–≥–∞"
            assert 'quality_score' in step_quality, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞"
        
        print(f"‚úì –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞ –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω")
        print()
        
        return True
        
    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ –≤ –∞–Ω–∞–ª–∏–∑–µ –∫–∞—á–µ—Å—Ç–≤–∞: {e}")
        return False


async def test_chat_completion_with_reasoning():
    """–¢–µ—Å—Ç —É–ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ API –¥–ª—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π"""
    print("=== –¢–µ—Å—Ç —É–ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ API —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π ===")
    
    config = LLMConfig(
        endpoint = os.getenv("LLM_ENDPOINT"),
        api_key = os.getenv("LLM_TOKEN"),
        model = os.getenv("LLM_MODEL")
    )
    
    client = ReasoningLLMClient(config)
    
    messages = [
        {
            "role": "user",
            "content": "–ü–æ—á–µ–º—É –Ω–µ–±–æ –≥–æ–ª—É–±–æ–µ? –û–±—ä—è—Å–Ω–∏ –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏."
        }
    ]
    
    try:
        result = await client.chat_completion_with_reasoning(
            messages=messages,
            reasoning_config=ReasoningConfig(max_reasoning_steps=3)
        )
        
        print(f"‚úì –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π API —Ä–∞–±–æ—Ç–∞–µ—Ç")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        required_keys = ['reasoning_steps', 'final_answer', 'confidence_score', 'total_steps']
        for key in required_keys:
            assert key in result, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ: {key}"
        
        print(f"‚úì –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞")
        print(f"‚úì –®–∞–≥–æ–≤ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è: {result['total_steps']}")
        print(f"‚úì –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: {len(result['final_answer'])} —Å–∏–º–≤–æ–ª–æ–≤")
        
        if result['confidence_score']:
            print(f"‚úì –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence_score']:.2f}")
        
        print()
        
        return True
        
    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ –≤ —É–ø—Ä–æ—â–µ–Ω–Ω–æ–º API: {e}")
        return False


async def test_reasoning_error_handling():
    """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ –≤ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è—Ö"""
    print("=== –¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ ===")
    
    config = LLMConfig(
        endpoint="http://invalid-endpoint:9999",  # –ù–µ–≤–µ—Ä–Ω—ã–π endpoint
        api_key="invalid_key",
        model="chat"
    )
    
    client = ReasoningLLMClient(config)
    
    messages = [
        {
            "role": "user",
            "content": "–¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å"
        }
    ]
    
    try:
        # –≠—Ç–æ—Ç –∑–∞–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –≤—ã–∑–≤–∞—Ç—å –æ—à–∏–±–∫—É
        await client.reasoning_completion(
            messages=messages,
            problem_type="general",
            enable_streaming=False
        )
        
        print("‚úó –û—à–∏–±–∫–∞ –Ω–µ –±—ã–ª–∞ –≤—ã–∑–≤–∞–Ω–∞ (–Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ)")
        return False
        
    except Exception as e:
        print(f"‚úì –û—à–∏–±–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞: {type(e).__name__}")
        print(f"‚úì –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ: {str(e)[:100]}...")
        print()
        return True


async def run_comprehensive_test():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    print("–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ReasoningLLMClient")
    print("=" * 60)
    print()
    
    tests = [
        ("–ë–∞–∑–æ–≤–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ", test_basic_reasoning),
        ("–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ", test_math_reasoning),
        ("–õ–æ–≥–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ", test_logic_reasoning),
        ("–†–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –ø—Ä–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏", test_coding_reasoning),
        ("–ü–æ—Ç–æ–∫–æ–≤–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ", test_streaming_reasoning),
        ("–í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π", test_reasoning_validation),
        ("–ö–∞—Å—Ç–æ–º–Ω—ã–π —à–∞–±–ª–æ–Ω", test_custom_reasoning_template),
        ("–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞", test_reasoning_quality_analysis),
        ("–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π API", test_chat_completion_with_reasoning),
        ("–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫", test_reasoning_error_handling)
    ]
    
    results = []
    total_start_time = time.time()
    
    for test_name, test_func in tests:
        print(f"–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞: {test_name}")
        try:
            result = await test_func()
            results.append((test_name, result))
            status = "‚úì –ü–†–û–ô–î–ï–ù" if result else "‚úó –ü–†–û–í–ê–õ–ï–ù"
            print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {status}")
        except Exception as e:
            results.append((test_name, False))
            print(f"‚úó –û–®–ò–ë–ö–ê: {e}")
        
        print("-" * 40)
        print()
    
    total_time = time.time() - total_start_time
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print("–ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
    print("=" * 60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    print(f"–ü—Ä–æ–π–¥–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤: {passed}/{total}")
    print(f"–û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {total_time:.2f}s")
    print()
    
    print("–î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    for test_name, result in results:
        status = "‚úì" if result else "‚úó"
        print(f"  {status} {test_name}")
    
    print()
    
    if passed == total:
        print("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û!")
    else:
        print(f"‚ö† {total - passed} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–≤–∞–ª–µ–Ω–æ")
    
    return passed == total


if __name__ == "__main__":
    asyncio.run(run_comprehensive_test())
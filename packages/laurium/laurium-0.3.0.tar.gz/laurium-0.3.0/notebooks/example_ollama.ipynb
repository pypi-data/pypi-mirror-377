{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Laurium\n",
    "\n",
    "This notebook demonstrates how to perform sentiment analysis using the laurium library with:\n",
    "- Ollama as the LLM platform (Qwen2.5:7b model)\n",
    "- Pydantic for structured output parsing\n",
    "- Custom prompts for sentiment classification\n",
    "\n",
    "## Overview\n",
    "\n",
    "We'll build a sentiment classifier that:\n",
    "1. Takes text input\n",
    "2. Returns structured JSON with sentiment labels (1=positive, 0=negative)\n",
    "3. Processes data in batches using pandas DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "First, let's import all the necessary modules from laurium and supporting libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "from laurium.decoder_models import extract, llm, prompts, pydantic_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. Create LLM Instance\n",
    "\n",
    "We'll use Ollama with the Qwen2.5:7b model for our sentiment analysis. Setting temperature to 0.0 ensures consistent, deterministic outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LLM instance with Ollama platform\n",
    "sentiment_llm = llm.create_llm(\n",
    "    llm_platform=\"ollama\", model_name=\"qwen2.5:7b\", temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 2. Build the Sentiment Analysis Prompt\n",
    "\n",
    "The prompt is crucial for getting structured output. We specify the exact JSON format that matches our Pydantic model schema.\n",
    "\n",
    "**Key Points:**\n",
    "- Clear instructions for sentiment classification\n",
    "- Exact JSON format specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create system message with specific JSON format requirements\n",
    "system_message = prompts.create_system_message(\n",
    "    base_message=\"\"\"You are a sentiment analysis assistant.\n",
    "    Analyze the sentiment and return JSON in this exact format:\n",
    "        {{\"ai_label\": 1}}\n",
    "    Use 1 for positive sentiment, 0 for negative sentiment.\"\"\",\n",
    "    keywords=[\"positive\", \"negative\"],\n",
    ")\n",
    "\n",
    "# Build the complete extraction prompt\n",
    "extraction_prompt = prompts.create_prompt(\n",
    "    system_message=system_message,\n",
    "    examples=None,\n",
    "    example_human_template=None,\n",
    "    example_assistant_template=None,\n",
    "    final_query=\"Analyze this text: {text}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 3. Define Output Schema with Pydantic\n",
    "\n",
    "We create a dynamic Pydantic model that matches our expected JSON output format. This ensures type safety and structured parsing of LLM responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output schema - must match JSON format in prompt\n",
    "schema = {\"ai_label\": int}  # 1 for positive, 0 for negative\n",
    "\n",
    "# Provide clear descriptions for each field\n",
    "descriptions = {\n",
    "    \"ai_label\": \"Sentiment classification (1=positive, 0=negative)\"\n",
    "}\n",
    "\n",
    "# Create the dynamic Pydantic model\n",
    "OutputModel = pydantic_models.make_dynamic_example_model(\n",
    "    schema=schema, descriptions=descriptions, model_name=\"SentimentOutput\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 4. Create Batch Extractor\n",
    "\n",
    "The BatchExtractor combines our LLM, prompt, and parser to process multiple texts efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pydantic output parser\n",
    "parser = PydanticOutputParser(pydantic_object=OutputModel)\n",
    "\n",
    "# Create the batch extractor\n",
    "extractor = extract.BatchExtractor(\n",
    "    llm=sentiment_llm, prompt=extraction_prompt, parser=parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 5. Prepare Test Data\n",
    "\n",
    "Let's create a small dataset with examples of positive and negative sentiment to test our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test data with clear positive and negative examples\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"text\": [\n",
    "            \"I absolutely love this product!\",\n",
    "            \"This is terrible, worst purchase ever.\",\n",
    "            \"Great value for money, highly recommend!\",\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 6. Process Data and View Results\n",
    "\n",
    "Now we'll run our sentiment analysis on the test data and examine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor.process_chunk(data, text_column=\"text\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

[project]
name = "lexi-align"
version = "0.4.0-alpha"
description = "Word alignment between two languages using structured generation"
readme = "README.md"
authors = [
    { name = "Bor Hodošček", email = "dev@bor.space" }
]
requires-python = ">=3.10"
dependencies = [
    "pydantic>=2.9.0",
]

[project.optional-dependencies]
litellm = ["litellm>=1.51.0"]
outlines = [
    "outlines>=0.1.9",
    "datasets>=3.2.0",
    "transformers>=4.46.1",
    "accelerate>=1.0.1",
    "torch>=2.5.1",
    # # If using ROCm:
    "torch==2.5.1+rocm6.2",
    "pytorch-triton-rocm==3.1.0",
    # Needed by some models:
    "protobuf>=5.29.1",
    "sentencepiece>=0.2.0",
]
llama-cpp = ["llama-cpp-python>=0.3.1"]
viz = [
    "matplotlib>=3.9.2",
    "seaborn>=0.13.2",
]

# The following is for different accelerators:
[tool.uv.sources]
torch = { index = "pytorch-rocm" }
# We leave this here because it does not interfere with other packages:
pytorch-triton-rocm = { index = "pytorch-rocm" }
# If wanting the development version:
# outlines = { git = "https://github.com/dottxt-ai/outlines.git" }
# If wanting to use CUDA wheels:
# llama-cpp-python = { index = "llama-cpp-python-cuda" }

[[tool.uv.index]]
name = "pytorch-rocm"
url = "https://download.pytorch.org/whl/rocm6.2"
explicit = true

[[tool.uv.index]]
name = "pytorch-cuda"
url = "https://download.pytorch.org/whl/cu124"
explicit = true

[[tool.uv.index]]
name = "llama-cpp-python-cuda"
url = "https://abetlen.github.io/llama-cpp-python/whl/cu125"
explicit = true

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[dependency-groups]
dev = [
    # All extra dependencies for ci and convenience
    "litellm>=1.51.0",
    "boto3>=1.35.50",
    "llama-cpp-python>=0.3.1",
    "outlines>=0.1.1",
    "transformers>=4.46.1",
    "torch>=2.5.1",
    "accelerate>=1.0.1",
    # Eval
    "requests>=2.31.0",
    "matplotlib>=3.7.0",
    "seaborn>=0.12.0",
    "pandas>=2.0.0",
    # Testing
    "pytest>=7.0.0",
    "pytest-mock>=3.12.0",
    "mypy>=1.13.0",
    "pandas-stubs",
    "types-tqdm",
    "types-requests",
    "hf-transfer>=0.1.8",
    "pytest-asyncio>=0.24.0",
    "loguru>=0.7.2",
    "scipy>=1.14.1",
]

[tool.pytest.ini_options]
minversion = "6.0"
addopts = "-ra -q --doctest-modules"
testpaths = [
    "tests",
    "src",
    "evaluations",
]
doctest_optionflags = "NORMALIZE_WHITESPACE IGNORE_EXCEPTION_DETAIL"
asyncio_default_fixture_loop_scope = "function"

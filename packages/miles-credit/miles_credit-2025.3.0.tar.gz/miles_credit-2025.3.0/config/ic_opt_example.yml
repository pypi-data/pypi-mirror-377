# --------------------------------------------------------------------------------------------------------------------- #
# This yaml file implements 6 hourly state-in-state-out wxformer model
# on NSF NCAR HPCs (casper.ucar.edu and derecho.hpc.ucar.edu) 
# The model is trained on 1 hourly model-level ERA5 data with top solar irradiance, geopotential, and land-sea mask
# Output variables: model level [U, V, T, Q], single level [SP, t2m], and 500 hPa [U, V, T, Z, Q]
# --------------------------------------------------------------------------------------------------------------------- #
save_loc: '/glade/derecho/scratch/schreck/CREDIT_runs/ic_opt/'
seed: 1000

data:
    # upper-air variables
    variables: ['U','V','T','Q']
    save_loc: '/glade/derecho/scratch/ksha/CREDIT_data/ERA5_mlevel_cesm_stage1/all_in_one/ERA5_mlevel_cesm_6h_lev16_*.zarr'
    
    # surface variables
    surface_variables: ['SP','t2m','V500','U500','T500','Z500','Q500']
    save_loc_surface: '/glade/derecho/scratch/ksha/CREDIT_data/ERA5_mlevel_cesm_stage1/all_in_one/ERA5_mlevel_cesm_6h_lev16_*.zarr'
    
    # dynamic forcing variables
    dynamic_forcing_variables: ['tsi']
    save_loc_dynamic_forcing: '/glade/derecho/scratch/ksha/CREDIT_data/ERA5_mlevel_cesm_stage1/all_in_one/ERA5_mlevel_cesm_6h_lev16_*.zarr'
    
    # static variables
    static_variables: ['Z_GDS4_SFC','LSM'] 
    save_loc_static: '/glade/derecho/scratch/ksha/CREDIT_data/ERA5_mlevel_cesm_stage1/static/ERA5_mlevel_cesm_static.zarr'
    
    # mean / std path
    mean_path: '/glade/derecho/scratch/ksha/CREDIT_data/ERA5_mlevel_cesm_stage1/mean_std/mean_6h_1979_2018_cesm.nc'
    # regular z-score version
    # std_path: '/glade/derecho/scratch/ksha/CREDIT_data/ERA5_mlevel_cesm_stage1/mean_std/std_6h_1979_2018_cesm.nc'
    # residual norm version
    std_path: '/glade/derecho/scratch/ksha/CREDIT_data/ERA5_mlevel_cesm_stage1/mean_std/std_residual_6h_1979_2018_cesm.nc'
    
    # train / validation split
    train_years: [1979, 2018]
    valid_years: [2018, 2019]
    
    # data workflow
    scaler_type: 'std_new'
    
    # state-in-state-out
    history_len: 1
    valid_history_len: 1
    
    forecast_len: 59
    valid_forecast_len: 0
    
    one_shot: True
    
    # 1 for hourly model
    lead_time_periods: 6
    
    # do not use skip_period
    skip_periods: null
    
    # compatible with the old 'std'
    static_first: True

    dataset_type: ERA5_MultiStep_Batcher # ERA5_and_Forcing_MultiStep MultiprocessingBatcherPrefetch ERA5_MultiStep_Batcher MultiprocessingBatcher
    
trainer:
    type: ic-opt # <---------- change to your type: single/multi-step training

    mode: ddp
    cpu_offload: False
    activation_checkpoint: True
    
    load_weights: True
    load_optimizer: False
    load_scaler: False
    load_scheduler: False

    skip_validation: True
    update_learning_rate: False

    save_backup_weights: False
    save_best_weights: False
    
    learning_rate: 1.0e-03 # <-- change to your lr
    weight_decay: 0
    
    train_batch_size: 1
    valid_batch_size: 1
    
    batches_per_epoch: 1000 # Total number of samples = 341,880  (1h) ~56,960 (6h)
    valid_batches_per_epoch: 10
    stopping_patience: 999
    
    start_epoch: 0
    num_epoch: 1
    reload_epoch: True
    epochs: &epochs 1
     
    use_scheduler: True
    scheduler: {'scheduler_type': 'cosine-annealing', 'T_max': *epochs,  'last_epoch': -1}
    
    # Automatic Mixed Precision: False
    amp: False
    
    # rescale loss as loss = loss / grad_accum_every
    grad_accum_every: 1 
    # gradient clipping
    grad_max_norm: 'dynamic'
    
    # number of workers
    thread_workers: 4
    valid_thread_workers: 4

    # compile 
    # compile: True
    prefetch_factor: 4

    # initial condition optimization settings
    starting_window_size: 8   # 2 days
    window_size: 12  # 3 days
    batch_iterations: 100


model:
    # crossformer example
    type: "crossformer"
    frames: 1                         # number of input states (default: 1)
    image_height: 192                 # number of latitude grids (default: 640)
    image_width: 288                 # number of longitude grids (default: 1280)
    levels: 16                        # number of upper-air variable levels (default: 15)
    channels: 4                       # upper-air variable channels
    surface_channels: 7               # surface variable channels
    input_only_channels: 3            # dynamic forcing, forcing, static channels
    output_only_channels: 0           # diagnostic variable channels
    
    patch_width: 1                    # number of latitude grids in each 3D patch (default: 1)
    patch_height: 1                   # number of longitude grids in each 3D patch (default: 1)
    frame_patch_size: 1               # number of input states in each 3D patch (default: 1)
    
    dim: [256, 512, 1024, 2048]        # Dimensionality of each layer
    depth: [2, 2, 8, 2]               # Depth of each layer
    global_window_size: [8, 4, 2, 1] # Global window size for each layer
    local_window_size: 3             # Local window size
    cross_embed_kernel_sizes:         # kernel sizes for cross-embedding
    - [4, 8, 16, 32]
    - [2, 4]
    - [2, 4]
    - [2, 4]
    cross_embed_strides: [2, 2, 2, 2] # Strides for cross-embedding (default: [4, 2, 2, 2])
    attn_dropout: 0.                  # Dropout probability for attention layers (default: 0.0)
    ff_dropout: 0.                    # Dropout probability for feed-forward layers (default: 0.0)
    
    # use interpolation to match the output size
    interp: True

    # spectral norm
    use_spectral_norm: True
    
    # map boundary padding
    # padding_conf:
    #     activate: True
    #     mode: earth
    #     pad_lat: [32, 32]
    #     pad_lon: [48, 48]

    padding_conf:
        activate: True
        mode: earth
        pad_lat: 48
        pad_lon: 48
        
    post_conf: 
        activate: True
        tracer_fixer:
            activate: True
            denorm: True
            tracer_name: ['Q', 'Q500']
            tracer_thres: [1e-8, 1e-8]
    
loss: 
    # the main training loss
    training_loss: "mse"
    
    # power loss (x), spectral_loss (x)
    use_power_loss: False
    use_spectral_loss: False
    
    # use latitude weighting
    use_latitude_weights: True
    latitude_weights: '/glade/derecho/scratch/ksha/CREDIT_data/ERA5_mlevel_cesm_stage1/static/ERA5_mlevel_cesm_static.zarr'
    
    # turn-off variable weighting
    use_variable_weights: False

    # variable_weights:
    U: [0.005, 0.011, 0.02, 0.029, 0.039, 0.048, 0.057, 0.067, 0.076, 0.085, 0.095, 0.104, 0.113, 0.123, 0.132, 0.141]
    V: [0.005, 0.011, 0.02, 0.029, 0.039, 0.048, 0.057, 0.067, 0.076, 0.085, 0.095, 0.104, 0.113, 0.123, 0.132, 0.141]
    T: [0.005, 0.011, 0.02, 0.029, 0.039, 0.048, 0.057, 0.067, 0.076, 0.085, 0.095, 0.104, 0.113, 0.123, 0.132, 0.141]
    Q: [0.005, 0.011, 0.02, 0.029, 0.039, 0.048, 0.057, 0.067, 0.076, 0.085, 0.095, 0.104, 0.113, 0.123, 0.132, 0.141]
    SP: 1.0
    t2m: 1.0
    V500: 0.1
    U500: 0.1
    T500: 0.1
    Z500: 0.1
    Q500: 0.1
    
predict:
    mode: ddp
    forecasts:
        type: "custom"       # keep it as "custom"
        start_year: 2020     # year of the first initialization (where rollout will start)
        start_month: 1       # month of the first initialization
        start_day: 1         # day of the first initialization
        start_hours: [0, 12] # hour-of-day for each initialization, 0 for 00Z, 12 for 12Z
        duration: 384          # number of days to initialize, starting from the (year, mon, day) above
                             # duration should be divisible by the number of GPUs 
                             # (e.g., duration: 384 for 365-day rollout using 32 GPUs)
        days: 10             # forecast lead time as days (1 means 24-hour forecast)
        
    metadata: '/glade/u/home/akn7/miles-credit/credit/metadata/era5.yaml'
    save_forecast: '/glade/derecho/scratch/schreck/CREDIT_runs/ic_opt/saved_states/'
    # save_vars: ['SP','t2m','V500','U500','T500','Z500','Q500']
    
    # turn-off low-pass filter
    use_laplace_filter: False
    
    # deprecated
    # save_format: "nc"

pbs: #derecho
    conda: "/glade/work/akn7/conda-envs/credit-derecho"
    project: "NAML0001"
    job_name: "graph_1h"
    walltime: "12:00:00"
    nodes: 8
    ncpus: 64
    ngpus: 4
    mem: '480GB'
    queue: 'main'

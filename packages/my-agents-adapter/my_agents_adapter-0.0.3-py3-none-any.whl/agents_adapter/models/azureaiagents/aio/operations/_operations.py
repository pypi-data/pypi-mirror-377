# pylint: disable=too-many-lines
# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
from collections.abc import MutableMapping
from io import IOBase
import json
from typing import Any, Callable, Dict, IO, List, Literal, Optional, TypeVar, Union, overload

from azure.core import AsyncPipelineClient
from azure.core.exceptions import (
    ClientAuthenticationError,
    HttpResponseError,
    ResourceExistsError,
    ResourceNotFoundError,
    ResourceNotModifiedError,
    StreamClosedError,
    StreamConsumedError,
    map_error,
)
from azure.core.pipeline import PipelineResponse
from azure.core.rest import AsyncHttpResponse, HttpRequest
from azure.core.tracing.decorator_async import distributed_trace_async
from azure.core.utils import case_insensitive_dict

from ... import models as _models2
from ....openai import models as _openai_models4
from ..._utils.model_base import SdkJSONEncoder, _deserialize, _failsafe_deserialize
from ..._utils.serialization import Deserializer, Serializer
from ...operations._operations import (
    build_agents_create_agent_version_request,
    build_agents_delete_agent_request,
    build_agents_delete_agent_version_request,
    build_agents_get_agent_label_change_log_request,
    build_agents_get_agent_label_request,
    build_agents_get_agent_request,
    build_agents_get_agent_version_request,
    build_agents_list_agent_labels_request,
    build_agents_list_agent_versions_request,
    build_agents_list_agents_request,
    build_agents_upsert_agent_label_request,
    build_conversations_create_conversation_item_request,
    build_conversations_create_conversation_request,
    build_conversations_delete_conversation_item_request,
    build_conversations_delete_conversation_request,
    build_conversations_get_conversation_item_request,
    build_conversations_get_conversation_request,
    build_conversations_list_conversation_items_request,
    build_conversations_list_conversations_request,
    build_responses_cancel_response_request,
    build_responses_create_response_request,
    build_responses_delete_response_request,
    build_responses_get_response_request,
    build_responses_list_input_items_request,
    build_responses_list_responses_request,
)
from .._configuration import AzureAIAgentsClientConfiguration

JSON = MutableMapping[str, Any]
T = TypeVar("T")
ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]


class ConversationsOperations:
    """
    .. warning::
        **DO NOT** instantiate this class directly.

        Instead, you should access the following operations through
        :class:`~azureaiagents.aio.AzureAIAgentsClient`'s
        :attr:`conversations` attribute.
    """

    def __init__(self, *args, **kwargs) -> None:
        input_args = list(args)
        self._client: AsyncPipelineClient = input_args.pop(0) if input_args else kwargs.pop("client")
        self._config: AzureAIAgentsClientConfiguration = input_args.pop(0) if input_args else kwargs.pop("config")
        self._serialize: Serializer = input_args.pop(0) if input_args else kwargs.pop("serializer")
        self._deserialize: Deserializer = input_args.pop(0) if input_args else kwargs.pop("deserializer")

    @overload
    async def create_conversation(
        self, request_body: _models2.CreateConversationInput, *, content_type: str = "application/json", **kwargs: Any
    ) -> _models2.ConversationObject:
        """Create a conversation.

        create_conversation.

        :param request_body: Required.
        :type request_body: ~azureaiagents.models.CreateConversationInput
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: ConversationObject. The ConversationObject is compatible with MutableMapping
        :rtype: ~azureaiagents.models.ConversationObject
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    async def create_conversation(
        self, request_body: JSON, *, content_type: str = "application/json", **kwargs: Any
    ) -> _models2.ConversationObject:
        """Create a conversation.

        create_conversation.

        :param request_body: Required.
        :type request_body: JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: ConversationObject. The ConversationObject is compatible with MutableMapping
        :rtype: ~azureaiagents.models.ConversationObject
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    async def create_conversation(
        self, request_body: IO[bytes], *, content_type: str = "application/json", **kwargs: Any
    ) -> _models2.ConversationObject:
        """Create a conversation.

        create_conversation.

        :param request_body: Required.
        :type request_body: IO[bytes]
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: ConversationObject. The ConversationObject is compatible with MutableMapping
        :rtype: ~azureaiagents.models.ConversationObject
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace_async
    async def create_conversation(
        self, request_body: Union[_models2.CreateConversationInput, JSON, IO[bytes]], **kwargs: Any
    ) -> _models2.ConversationObject:
        """Create a conversation.

        create_conversation.

        :param request_body: Is one of the following types: CreateConversationInput, JSON, IO[bytes]
         Required.
        :type request_body: ~azureaiagents.models.CreateConversationInput or JSON or IO[bytes]
        :return: ConversationObject. The ConversationObject is compatible with MutableMapping
        :rtype: ~azureaiagents.models.ConversationObject
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        accept: Literal["application/json"] = kwargs.pop("accept", _headers.pop("accept", "application/json"))
        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models2.ConversationObject] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(request_body, (IOBase, bytes)):
            _content = request_body
        else:
            _content = json.dumps(request_body, cls=SdkJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_conversations_create_conversation_request(
            accept=accept,
            content_type=content_type,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models2.ConversationObject, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def get_conversation(self, conversation_id: str, **kwargs: Any) -> _models2.ConversationObject:
        """Retrieves a conversation.

        get_conversation.

        :param conversation_id: The id of the conversation to retrieve. Required.
        :type conversation_id: str
        :return: ConversationObject. The ConversationObject is compatible with MutableMapping
        :rtype: ~azureaiagents.models.ConversationObject
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        accept: Literal["application/json"] = kwargs.pop("accept", _headers.pop("accept", "application/json"))
        cls: ClsType[_models2.ConversationObject] = kwargs.pop("cls", None)

        _request = build_conversations_get_conversation_request(
            conversation_id=conversation_id,
            accept=accept,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models2.ConversationObject, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def delete_conversation(self, conversation_id: str, **kwargs: Any) -> _models2.DeleteConversationResponse:
        """Deletes a conversation.

        delete_conversation.

        :param conversation_id: The id of the conversation to delete. Required.
        :type conversation_id: str
        :return: DeleteConversationResponse. The DeleteConversationResponse is compatible with
         MutableMapping
        :rtype: ~azureaiagents.models.DeleteConversationResponse
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        accept: Literal["application/json"] = kwargs.pop("accept", _headers.pop("accept", "application/json"))
        cls: ClsType[_models2.DeleteConversationResponse] = kwargs.pop("cls", None)

        _request = build_conversations_delete_conversation_request(
            conversation_id=conversation_id,
            accept=accept,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models2.DeleteConversationResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def list_conversations(
        self,
        *,
        limit: Optional[int] = None,
        order: Optional[Literal["asc", "desc"]] = None,
        after: Optional[str] = None,
        before: Optional[str] = None,
        **kwargs: Any
    ) -> _models2.ConversationList:
        """Returns the list of all conversations.

        list_conversations.

        :keyword limit: A limit on the number of objects to be returned. Limit can range between 1 and
         100, and the
         default is 20. Default value is None.
        :paramtype limit: int
        :keyword order: Sort order by the ``created_at`` timestamp of the objects. ``asc`` for
         ascending order and``desc``
         for descending order. Is either a Literal["asc"] type or a Literal["desc"] type. Default value
         is None.
        :paramtype order: str or str
        :keyword after: A cursor for use in pagination. ``after`` is an object ID that defines your
         place in the list.
         For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
         subsequent call can include after=obj_foo in order to fetch the next page of the list. Default
         value is None.
        :paramtype after: str
        :keyword before: A cursor for use in pagination. ``before`` is an object ID that defines your
         place in the list.
         For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
         subsequent call can include before=obj_foo in order to fetch the previous page of the list.
         Default value is None.
        :paramtype before: str
        :return: ConversationList. The ConversationList is compatible with MutableMapping
        :rtype: ~azureaiagents.models.ConversationList
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        accept: Literal["application/json"] = kwargs.pop("accept", _headers.pop("accept", "application/json"))
        cls: ClsType[_models2.ConversationList] = kwargs.pop("cls", None)

        _request = build_conversations_list_conversations_request(
            limit=limit,
            order=order,
            after=after,
            before=before,
            accept=accept,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models2.ConversationList, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @overload
    async def create_conversation_item(
        self,
        conversation_id: str,
        request_body: _models2.ConversationItemInput,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _openai_models4.ItemResource:
        """Create a conversation item.

        create_conversation_item.

        :param conversation_id: The id of the conversation on which the item needs to be created.
         Required.
        :type conversation_id: str
        :param request_body: Required.
        :type request_body: ~azureaiagents.models.ConversationItemInput
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: ItemResource. The ItemResource is compatible with MutableMapping
        :rtype: ~openai.models.ItemResource
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    async def create_conversation_item(
        self, conversation_id: str, request_body: JSON, *, content_type: str = "application/json", **kwargs: Any
    ) -> _openai_models4.ItemResource:
        """Create a conversation item.

        create_conversation_item.

        :param conversation_id: The id of the conversation on which the item needs to be created.
         Required.
        :type conversation_id: str
        :param request_body: Required.
        :type request_body: JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: ItemResource. The ItemResource is compatible with MutableMapping
        :rtype: ~openai.models.ItemResource
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    async def create_conversation_item(
        self, conversation_id: str, request_body: IO[bytes], *, content_type: str = "application/json", **kwargs: Any
    ) -> _openai_models4.ItemResource:
        """Create a conversation item.

        create_conversation_item.

        :param conversation_id: The id of the conversation on which the item needs to be created.
         Required.
        :type conversation_id: str
        :param request_body: Required.
        :type request_body: IO[bytes]
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: ItemResource. The ItemResource is compatible with MutableMapping
        :rtype: ~openai.models.ItemResource
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace_async
    async def create_conversation_item(
        self, conversation_id: str, request_body: Union[_models2.ConversationItemInput, JSON, IO[bytes]], **kwargs: Any
    ) -> _openai_models4.ItemResource:
        """Create a conversation item.

        create_conversation_item.

        :param conversation_id: The id of the conversation on which the item needs to be created.
         Required.
        :type conversation_id: str
        :param request_body: Is one of the following types: ConversationItemInput, JSON, IO[bytes]
         Required.
        :type request_body: ~azureaiagents.models.ConversationItemInput or JSON or IO[bytes]
        :return: ItemResource. The ItemResource is compatible with MutableMapping
        :rtype: ~openai.models.ItemResource
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        accept: Literal["application/json"] = kwargs.pop("accept", _headers.pop("accept", "application/json"))
        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_openai_models4.ItemResource] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(request_body, (IOBase, bytes)):
            _content = request_body
        else:
            _content = json.dumps(request_body, cls=SdkJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_conversations_create_conversation_item_request(
            conversation_id=conversation_id,
            accept=accept,
            content_type=content_type,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_openai_models4.ItemResource, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def get_conversation_item(
        self, conversation_id: str, item_id: str, **kwargs: Any
    ) -> _openai_models4.ItemResource:
        """Retrieves a conversation item.

        get_conversation_item.

        :param conversation_id: The id of the conversation on which the item needs to tbe retrieved
         from. Required.
        :type conversation_id: str
        :param item_id: The id of the conversation item to retrieve. Required.
        :type item_id: str
        :return: ItemResource. The ItemResource is compatible with MutableMapping
        :rtype: ~openai.models.ItemResource
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        accept: Literal["application/json"] = kwargs.pop("accept", _headers.pop("accept", "application/json"))
        cls: ClsType[_openai_models4.ItemResource] = kwargs.pop("cls", None)

        _request = build_conversations_get_conversation_item_request(
            conversation_id=conversation_id,
            item_id=item_id,
            accept=accept,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_openai_models4.ItemResource, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def delete_conversation_item(
        self, conversation_id: str, item_id: str, **kwargs: Any
    ) -> _models2.DeleteConversationItemResponse:
        """Deletes a conversation.

        delete_conversation_item.

        :param conversation_id: The id of the conversation on which the item needs to tbe deleted from.
         Required.
        :type conversation_id: str
        :param item_id: The id of the conversation item to delete. Required.
        :type item_id: str
        :return: DeleteConversationItemResponse. The DeleteConversationItemResponse is compatible with
         MutableMapping
        :rtype: ~azureaiagents.models.DeleteConversationItemResponse
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        accept: Literal["application/json"] = kwargs.pop("accept", _headers.pop("accept", "application/json"))
        cls: ClsType[_models2.DeleteConversationItemResponse] = kwargs.pop("cls", None)

        _request = build_conversations_delete_conversation_item_request(
            conversation_id=conversation_id,
            item_id=item_id,
            accept=accept,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models2.DeleteConversationItemResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def list_conversation_items(
        self,
        conversation_id: str,
        *,
        item_type: Optional[Union[str, _openai_models4.ItemType]] = None,
        limit: Optional[int] = None,
        order: Optional[Literal["asc", "desc"]] = None,
        after: Optional[str] = None,
        before: Optional[str] = None,
        **kwargs: Any
    ) -> _models2.ConversationItemList:
        """Returns the list of all items in a conversation.

        list_conversation_items.

        :param conversation_id: The id of the conversation on which the items needs to be listed.
         Required.
        :type conversation_id: str
        :keyword item_type: Filter by item type. If provided, only items of the specified type will be
         returned. Known values are: "message", "file_search_call", "function_call",
         "function_call_output", "computer_call", "computer_call_output", "web_search_call",
         "reasoning", "item_reference", "image_generation_call", "code_interpreter_call",
         "local_shell_call", "local_shell_call_output", "mcp_list_tools", "mcp_approval_request",
         "mcp_approval_response", and "mcp_call". Default value is None.
        :paramtype item_type: str or ~openai.models.ItemType
        :keyword limit: A limit on the number of objects to be returned. Limit can range between 1 and
         100, and the
         default is 20. Default value is None.
        :paramtype limit: int
        :keyword order: Sort order by the ``created_at`` timestamp of the objects. ``asc`` for
         ascending order and``desc``
         for descending order. Is either a Literal["asc"] type or a Literal["desc"] type. Default value
         is None.
        :paramtype order: str or str
        :keyword after: A cursor for use in pagination. ``after`` is an object ID that defines your
         place in the list.
         For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
         subsequent call can include after=obj_foo in order to fetch the next page of the list. Default
         value is None.
        :paramtype after: str
        :keyword before: A cursor for use in pagination. ``before`` is an object ID that defines your
         place in the list.
         For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
         subsequent call can include before=obj_foo in order to fetch the previous page of the list.
         Default value is None.
        :paramtype before: str
        :return: ConversationItemList. The ConversationItemList is compatible with MutableMapping
        :rtype: ~azureaiagents.models.ConversationItemList
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        accept: Literal["application/json"] = kwargs.pop("accept", _headers.pop("accept", "application/json"))
        cls: ClsType[_models2.ConversationItemList] = kwargs.pop("cls", None)

        _request = build_conversations_list_conversation_items_request(
            conversation_id=conversation_id,
            item_type=item_type,
            limit=limit,
            order=order,
            after=after,
            before=before,
            accept=accept,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models2.ConversationItemList, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore


class AgentsOperations:
    """
    .. warning::
        **DO NOT** instantiate this class directly.

        Instead, you should access the following operations through
        :class:`~azureaiagents.aio.AzureAIAgentsClient`'s
        :attr:`agents` attribute.
    """

    def __init__(self, *args, **kwargs) -> None:
        input_args = list(args)
        self._client: AsyncPipelineClient = input_args.pop(0) if input_args else kwargs.pop("client")
        self._config: AzureAIAgentsClientConfiguration = input_args.pop(0) if input_args else kwargs.pop("config")
        self._serialize: Serializer = input_args.pop(0) if input_args else kwargs.pop("serializer")
        self._deserialize: Deserializer = input_args.pop(0) if input_args else kwargs.pop("deserializer")

    @distributed_trace_async
    async def get_agent(self, agent_name: str, **kwargs: Any) -> _models2.AgentObject:
        """Retrieves the agent.

        get_agent.

        :param agent_name: The name of the agent to retrieve. Required.
        :type agent_name: str
        :return: AgentObject. The AgentObject is compatible with MutableMapping
        :rtype: ~azureaiagents.models.AgentObject
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        accept: Literal["application/json"] = kwargs.pop("accept", _headers.pop("accept", "application/json"))
        cls: ClsType[_models2.AgentObject] = kwargs.pop("cls", None)

        _request = build_agents_get_agent_request(
            agent_name=agent_name,
            accept=accept,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _failsafe_deserialize(_models2.Error, response.json())
            raise HttpResponseError(response=response, model=error)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models2.AgentObject, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def delete_agent(self, agent_name: str, **kwargs: Any) -> _models2.DeleteAgentResponse:
        """Deletes a agent.

        delete_agent.

        :param agent_name: The name of the agent to delete. Required.
        :type agent_name: str
        :return: DeleteAgentResponse. The DeleteAgentResponse is compatible with MutableMapping
        :rtype: ~azureaiagents.models.DeleteAgentResponse
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        accept: Literal["application/json"] = kwargs.pop("accept", _headers.pop("accept", "application/json"))
        cls: ClsType[_models2.DeleteAgentResponse] = kwargs.pop("cls", None)

        _request = build_agents_delete_agent_request(
            agent_name=agent_name,
            accept=accept,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _failsafe_deserialize(_models2.Error, response.json())
            raise HttpResponseError(response=response, model=error)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models2.DeleteAgentResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def list_agents(
        self,
        *,
        kind: Optional[Union[str, _models2.AgentKind]] = None,
        limit: Optional[int] = None,
        order: Optional[Literal["asc", "desc"]] = None,
        after: Optional[str] = None,
        before: Optional[str] = None,
        **kwargs: Any
    ) -> _models2.AgentList:
        """Returns the list of all agents.

        list_agents.

        :keyword kind: Filter agents by kind. If not provided, all agents are returned. Known values
         are: "prompt_agent", "custom_agent", and "workflow". Default value is None.
        :paramtype kind: str or ~azureaiagents.models.AgentKind
        :keyword limit: A limit on the number of objects to be returned. Limit can range between 1 and
         100, and the
         default is 20. Default value is None.
        :paramtype limit: int
        :keyword order: Sort order by the ``created_at`` timestamp of the objects. ``asc`` for
         ascending order and``desc``
         for descending order. Is either a Literal["asc"] type or a Literal["desc"] type. Default value
         is None.
        :paramtype order: str or str
        :keyword after: A cursor for use in pagination. ``after`` is an object ID that defines your
         place in the list.
         For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
         subsequent call can include after=obj_foo in order to fetch the next page of the list. Default
         value is None.
        :paramtype after: str
        :keyword before: A cursor for use in pagination. ``before`` is an object ID that defines your
         place in the list.
         For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
         subsequent call can include before=obj_foo in order to fetch the previous page of the list.
         Default value is None.
        :paramtype before: str
        :return: AgentList. The AgentList is compatible with MutableMapping
        :rtype: ~azureaiagents.models.AgentList
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        accept: Literal["application/json"] = kwargs.pop("accept", _headers.pop("accept", "application/json"))
        cls: ClsType[_models2.AgentList] = kwargs.pop("cls", None)

        _request = build_agents_list_agents_request(
            kind=kind,
            limit=limit,
            order=order,
            after=after,
            before=before,
            accept=accept,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _failsafe_deserialize(_models2.Error, response.json())
            raise HttpResponseError(response=response, model=error)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models2.AgentList, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @overload
    async def create_agent_version(
        self,
        agent_name: str,
        request_body: _models2.CreateAgentVersionRequest,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models2.AgentVersionObject:
        """Create a new agent version.

        create_agent_version.

        :param agent_name: The name of the agent to create/modify. Required.
        :type agent_name: str
        :param request_body: Required.
        :type request_body: ~azureaiagents.models.CreateAgentVersionRequest
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: AgentVersionObject. The AgentVersionObject is compatible with MutableMapping
        :rtype: ~azureaiagents.models.AgentVersionObject
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    async def create_agent_version(
        self, agent_name: str, request_body: JSON, *, content_type: str = "application/json", **kwargs: Any
    ) -> _models2.AgentVersionObject:
        """Create a new agent version.

        create_agent_version.

        :param agent_name: The name of the agent to create/modify. Required.
        :type agent_name: str
        :param request_body: Required.
        :type request_body: JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: AgentVersionObject. The AgentVersionObject is compatible with MutableMapping
        :rtype: ~azureaiagents.models.AgentVersionObject
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    async def create_agent_version(
        self, agent_name: str, request_body: IO[bytes], *, content_type: str = "application/json", **kwargs: Any
    ) -> _models2.AgentVersionObject:
        """Create a new agent version.

        create_agent_version.

        :param agent_name: The name of the agent to create/modify. Required.
        :type agent_name: str
        :param request_body: Required.
        :type request_body: IO[bytes]
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: AgentVersionObject. The AgentVersionObject is compatible with MutableMapping
        :rtype: ~azureaiagents.models.AgentVersionObject
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace_async
    async def create_agent_version(
        self, agent_name: str, request_body: Union[_models2.CreateAgentVersionRequest, JSON, IO[bytes]], **kwargs: Any
    ) -> _models2.AgentVersionObject:
        """Create a new agent version.

        create_agent_version.

        :param agent_name: The name of the agent to create/modify. Required.
        :type agent_name: str
        :param request_body: Is one of the following types: CreateAgentVersionRequest, JSON, IO[bytes]
         Required.
        :type request_body: ~azureaiagents.models.CreateAgentVersionRequest or JSON or IO[bytes]
        :return: AgentVersionObject. The AgentVersionObject is compatible with MutableMapping
        :rtype: ~azureaiagents.models.AgentVersionObject
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        accept: Literal["application/json"] = kwargs.pop("accept", _headers.pop("accept", "application/json"))
        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models2.AgentVersionObject] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(request_body, (IOBase, bytes)):
            _content = request_body
        else:
            _content = json.dumps(request_body, cls=SdkJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_agents_create_agent_version_request(
            agent_name=agent_name,
            accept=accept,
            content_type=content_type,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _failsafe_deserialize(_models2.Error, response.json())
            raise HttpResponseError(response=response, model=error)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models2.AgentVersionObject, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def get_agent_version(
        self, agent_name: str, agent_version: str, **kwargs: Any
    ) -> _models2.AgentVersionObject:
        """Retrieves a specific version of a agent.

        get_agent_version.

        :param agent_name: The name of the agent to retrieve. Required.
        :type agent_name: str
        :param agent_version: The version of the agent to retrieve. Required.
        :type agent_version: str
        :return: AgentVersionObject. The AgentVersionObject is compatible with MutableMapping
        :rtype: ~azureaiagents.models.AgentVersionObject
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        accept: Literal["application/json"] = kwargs.pop("accept", _headers.pop("accept", "application/json"))
        cls: ClsType[_models2.AgentVersionObject] = kwargs.pop("cls", None)

        _request = build_agents_get_agent_version_request(
            agent_name=agent_name,
            agent_version=agent_version,
            accept=accept,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _failsafe_deserialize(_models2.Error, response.json())
            raise HttpResponseError(response=response, model=error)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models2.AgentVersionObject, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def delete_agent_version(
        self, agent_name: str, agent_version: str, **kwargs: Any
    ) -> _models2.DeleteAgentVersionResponse:
        """Deletes a specific version of a agent. Deleting an agent with user-defined labels is not
        allowed and will result in bad request.

        delete_agent_version.

        :param agent_name: The name of the agent to delete. Required.
        :type agent_name: str
        :param agent_version: The version of the agent to delete. Required.
        :type agent_version: str
        :return: DeleteAgentVersionResponse. The DeleteAgentVersionResponse is compatible with
         MutableMapping
        :rtype: ~azureaiagents.models.DeleteAgentVersionResponse
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        accept: Literal["application/json"] = kwargs.pop("accept", _headers.pop("accept", "application/json"))
        cls: ClsType[_models2.DeleteAgentVersionResponse] = kwargs.pop("cls", None)

        _request = build_agents_delete_agent_version_request(
            agent_name=agent_name,
            agent_version=agent_version,
            accept=accept,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _failsafe_deserialize(_models2.Error, response.json())
            raise HttpResponseError(response=response, model=error)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models2.DeleteAgentVersionResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def list_agent_versions(
        self,
        agent_name: str,
        *,
        limit: Optional[int] = None,
        order: Optional[Literal["asc", "desc"]] = None,
        after: Optional[str] = None,
        before: Optional[str] = None,
        **kwargs: Any
    ) -> _models2.AgentVersionList:
        """Returns the list of versions of a agent.

        list_agent_versions.

        :param agent_name: The name of the agent to retrieve versions for. Required.
        :type agent_name: str
        :keyword limit: A limit on the number of objects to be returned. Limit can range between 1 and
         100, and the
         default is 20. Default value is None.
        :paramtype limit: int
        :keyword order: Sort order by the ``created_at`` timestamp of the objects. ``asc`` for
         ascending order and``desc``
         for descending order. Is either a Literal["asc"] type or a Literal["desc"] type. Default value
         is None.
        :paramtype order: str or str
        :keyword after: A cursor for use in pagination. ``after`` is an object ID that defines your
         place in the list.
         For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
         subsequent call can include after=obj_foo in order to fetch the next page of the list. Default
         value is None.
        :paramtype after: str
        :keyword before: A cursor for use in pagination. ``before`` is an object ID that defines your
         place in the list.
         For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
         subsequent call can include before=obj_foo in order to fetch the previous page of the list.
         Default value is None.
        :paramtype before: str
        :return: AgentVersionList. The AgentVersionList is compatible with MutableMapping
        :rtype: ~azureaiagents.models.AgentVersionList
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        accept: Literal["application/json"] = kwargs.pop("accept", _headers.pop("accept", "application/json"))
        cls: ClsType[_models2.AgentVersionList] = kwargs.pop("cls", None)

        _request = build_agents_list_agent_versions_request(
            agent_name=agent_name,
            limit=limit,
            order=order,
            after=after,
            before=before,
            accept=accept,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _failsafe_deserialize(_models2.Error, response.json())
            raise HttpResponseError(response=response, model=error)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models2.AgentVersionList, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @overload
    async def upsert_agent_label(
        self,
        agent_name: str,
        label_name: str,
        request_body: _models2.UpsertAgentLabelRequest,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models2.AgentLabelObject:
        """Create/Update/Remove a label association for agent versions.

        Create/Update/Remove a label association for agent versions.

        * If the label does not exist, it will be created.
        * If version association is NOT specified, the label will be disassociated from the any agent
        version it was previously associated with.
        * If version association is specified, then it will be updated to associate with the specified
        version and any previous vesrion associations will be removed.

        System labels are reserved labels that have specific meanings and behavior:

        * `$latest`: This label is automatically assigned to the latest version of the agent. This
        label cannot be created or modified by users.
        * `$default`: The **$default** label by default always points to latest version of the agent.
        However, user can change this behaviour by explicitly seting $default label on a different
        version. If user unassigns the $default label, it will revert back to he default behaviour of
        pointing to latest version.

        :param agent_name: The name of the agent. Required.
        :type agent_name: str
        :param label_name: The name of the label to create/modify. Required.
        :type label_name: str
        :param request_body: Required.
        :type request_body: ~azureaiagents.models.UpsertAgentLabelRequest
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: AgentLabelObject. The AgentLabelObject is compatible with MutableMapping
        :rtype: ~azureaiagents.models.AgentLabelObject
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    async def upsert_agent_label(
        self,
        agent_name: str,
        label_name: str,
        request_body: JSON,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models2.AgentLabelObject:
        """Create/Update/Remove a label association for agent versions.

        Create/Update/Remove a label association for agent versions.

        * If the label does not exist, it will be created.
        * If version association is NOT specified, the label will be disassociated from the any agent
        version it was previously associated with.
        * If version association is specified, then it will be updated to associate with the specified
        version and any previous vesrion associations will be removed.

        System labels are reserved labels that have specific meanings and behavior:

        * `$latest`: This label is automatically assigned to the latest version of the agent. This
        label cannot be created or modified by users.
        * `$default`: The **$default** label by default always points to latest version of the agent.
        However, user can change this behaviour by explicitly seting $default label on a different
        version. If user unassigns the $default label, it will revert back to he default behaviour of
        pointing to latest version.

        :param agent_name: The name of the agent. Required.
        :type agent_name: str
        :param label_name: The name of the label to create/modify. Required.
        :type label_name: str
        :param request_body: Required.
        :type request_body: JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: AgentLabelObject. The AgentLabelObject is compatible with MutableMapping
        :rtype: ~azureaiagents.models.AgentLabelObject
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    async def upsert_agent_label(
        self,
        agent_name: str,
        label_name: str,
        request_body: IO[bytes],
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models2.AgentLabelObject:
        """Create/Update/Remove a label association for agent versions.

        Create/Update/Remove a label association for agent versions.

        * If the label does not exist, it will be created.
        * If version association is NOT specified, the label will be disassociated from the any agent
        version it was previously associated with.
        * If version association is specified, then it will be updated to associate with the specified
        version and any previous vesrion associations will be removed.

        System labels are reserved labels that have specific meanings and behavior:

        * `$latest`: This label is automatically assigned to the latest version of the agent. This
        label cannot be created or modified by users.
        * `$default`: The **$default** label by default always points to latest version of the agent.
        However, user can change this behaviour by explicitly seting $default label on a different
        version. If user unassigns the $default label, it will revert back to he default behaviour of
        pointing to latest version.

        :param agent_name: The name of the agent. Required.
        :type agent_name: str
        :param label_name: The name of the label to create/modify. Required.
        :type label_name: str
        :param request_body: Required.
        :type request_body: IO[bytes]
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: AgentLabelObject. The AgentLabelObject is compatible with MutableMapping
        :rtype: ~azureaiagents.models.AgentLabelObject
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace_async
    async def upsert_agent_label(
        self,
        agent_name: str,
        label_name: str,
        request_body: Union[_models2.UpsertAgentLabelRequest, JSON, IO[bytes]],
        **kwargs: Any
    ) -> _models2.AgentLabelObject:
        """Create/Update/Remove a label association for agent versions.

        Create/Update/Remove a label association for agent versions.

        * If the label does not exist, it will be created.
        * If version association is NOT specified, the label will be disassociated from the any agent
        version it was previously associated with.
        * If version association is specified, then it will be updated to associate with the specified
        version and any previous vesrion associations will be removed.

        System labels are reserved labels that have specific meanings and behavior:

        * `$latest`: This label is automatically assigned to the latest version of the agent. This
        label cannot be created or modified by users.
        * `$default`: The **$default** label by default always points to latest version of the agent.
        However, user can change this behaviour by explicitly seting $default label on a different
        version. If user unassigns the $default label, it will revert back to he default behaviour of
        pointing to latest version.

        :param agent_name: The name of the agent. Required.
        :type agent_name: str
        :param label_name: The name of the label to create/modify. Required.
        :type label_name: str
        :param request_body: Is one of the following types: UpsertAgentLabelRequest, JSON, IO[bytes]
         Required.
        :type request_body: ~azureaiagents.models.UpsertAgentLabelRequest or JSON or IO[bytes]
        :return: AgentLabelObject. The AgentLabelObject is compatible with MutableMapping
        :rtype: ~azureaiagents.models.AgentLabelObject
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        accept: Literal["application/json"] = kwargs.pop("accept", _headers.pop("accept", "application/json"))
        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models2.AgentLabelObject] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(request_body, (IOBase, bytes)):
            _content = request_body
        else:
            _content = json.dumps(request_body, cls=SdkJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_agents_upsert_agent_label_request(
            agent_name=agent_name,
            label_name=label_name,
            accept=accept,
            content_type=content_type,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _failsafe_deserialize(_models2.Error, response.json())
            raise HttpResponseError(response=response, model=error)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models2.AgentLabelObject, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def get_agent_label(self, agent_name: str, label_name: str, **kwargs: Any) -> _models2.AgentLabelObject:
        """Retrieves a specific label of an agent.

        get_agent_label.

        :param agent_name: The name of the agent. Required.
        :type agent_name: str
        :param label_name: The name of the label to retrieve. Required.
        :type label_name: str
        :return: AgentLabelObject. The AgentLabelObject is compatible with MutableMapping
        :rtype: ~azureaiagents.models.AgentLabelObject
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        accept: Literal["application/json"] = kwargs.pop("accept", _headers.pop("accept", "application/json"))
        cls: ClsType[_models2.AgentLabelObject] = kwargs.pop("cls", None)

        _request = build_agents_get_agent_label_request(
            agent_name=agent_name,
            label_name=label_name,
            accept=accept,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _failsafe_deserialize(_models2.Error, response.json())
            raise HttpResponseError(response=response, model=error)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models2.AgentLabelObject, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def get_agent_label_change_log(
        self,
        agent_name: str,
        label_name: str,
        *,
        limit: Optional[int] = None,
        order: Optional[Literal["asc", "desc"]] = None,
        after: Optional[str] = None,
        before: Optional[str] = None,
        **kwargs: Any
    ) -> _models2.AgentLabelList:
        """Retrieves the change log for a specific label of an agent.

        get_agent_label_change_log.

        :param agent_name: The name of the agent. Required.
        :type agent_name: str
        :param label_name: The name of the label to retrieve. Required.
        :type label_name: str
        :keyword limit: A limit on the number of objects to be returned. Limit can range between 1 and
         100, and the
         default is 20. Default value is None.
        :paramtype limit: int
        :keyword order: Sort order by the ``created_at`` timestamp of the objects. ``asc`` for
         ascending order and``desc``
         for descending order. Is either a Literal["asc"] type or a Literal["desc"] type. Default value
         is None.
        :paramtype order: str or str
        :keyword after: A cursor for use in pagination. ``after`` is an object ID that defines your
         place in the list.
         For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
         subsequent call can include after=obj_foo in order to fetch the next page of the list. Default
         value is None.
        :paramtype after: str
        :keyword before: A cursor for use in pagination. ``before`` is an object ID that defines your
         place in the list.
         For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
         subsequent call can include before=obj_foo in order to fetch the previous page of the list.
         Default value is None.
        :paramtype before: str
        :return: AgentLabelList. The AgentLabelList is compatible with MutableMapping
        :rtype: ~azureaiagents.models.AgentLabelList
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        accept: Literal["application/json"] = kwargs.pop("accept", _headers.pop("accept", "application/json"))
        cls: ClsType[_models2.AgentLabelList] = kwargs.pop("cls", None)

        _request = build_agents_get_agent_label_change_log_request(
            agent_name=agent_name,
            label_name=label_name,
            limit=limit,
            order=order,
            after=after,
            before=before,
            accept=accept,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _failsafe_deserialize(_models2.Error, response.json())
            raise HttpResponseError(response=response, model=error)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models2.AgentLabelList, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def list_agent_labels(
        self,
        agent_name: str,
        *,
        agent_version: Optional[str] = None,
        limit: Optional[int] = None,
        order: Optional[Literal["asc", "desc"]] = None,
        after: Optional[str] = None,
        before: Optional[str] = None,
        **kwargs: Any
    ) -> _models2.AgentLabelList:
        """Returns the list of labels of a agent.

        list_agent_labels.

        :param agent_name: The name of the agent to retrieve labels for. Required.
        :type agent_name: str
        :keyword agent_version: Filter labels by agent version. If not provided, all labels of a an
         agent are returned. Default value is None.
        :paramtype agent_version: str
        :keyword limit: A limit on the number of objects to be returned. Limit can range between 1 and
         100, and the
         default is 20. Default value is None.
        :paramtype limit: int
        :keyword order: Sort order by the ``created_at`` timestamp of the objects. ``asc`` for
         ascending order and``desc``
         for descending order. Is either a Literal["asc"] type or a Literal["desc"] type. Default value
         is None.
        :paramtype order: str or str
        :keyword after: A cursor for use in pagination. ``after`` is an object ID that defines your
         place in the list.
         For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
         subsequent call can include after=obj_foo in order to fetch the next page of the list. Default
         value is None.
        :paramtype after: str
        :keyword before: A cursor for use in pagination. ``before`` is an object ID that defines your
         place in the list.
         For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
         subsequent call can include before=obj_foo in order to fetch the previous page of the list.
         Default value is None.
        :paramtype before: str
        :return: AgentLabelList. The AgentLabelList is compatible with MutableMapping
        :rtype: ~azureaiagents.models.AgentLabelList
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        accept: Literal["application/json"] = kwargs.pop("accept", _headers.pop("accept", "application/json"))
        cls: ClsType[_models2.AgentLabelList] = kwargs.pop("cls", None)

        _request = build_agents_list_agent_labels_request(
            agent_name=agent_name,
            agent_version=agent_version,
            limit=limit,
            order=order,
            after=after,
            before=before,
            accept=accept,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _failsafe_deserialize(_models2.Error, response.json())
            raise HttpResponseError(response=response, model=error)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models2.AgentLabelList, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore


class ResponsesOperations:
    """
    .. warning::
        **DO NOT** instantiate this class directly.

        Instead, you should access the following operations through
        :class:`~azureaiagents.aio.AzureAIAgentsClient`'s
        :attr:`responses` attribute.
    """

    def __init__(self, *args, **kwargs) -> None:
        input_args = list(args)
        self._client: AsyncPipelineClient = input_args.pop(0) if input_args else kwargs.pop("client")
        self._config: AzureAIAgentsClientConfiguration = input_args.pop(0) if input_args else kwargs.pop("config")
        self._serialize: Serializer = input_args.pop(0) if input_args else kwargs.pop("serializer")
        self._deserialize: Deserializer = input_args.pop(0) if input_args else kwargs.pop("deserializer")

    @overload
    async def create_response(
        self,
        request_body: _models2.CreateResponse,
        *,
        accept: Literal["application/json", "text/event-stream"],
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _openai_models4.ResponseStreamEvent:
        """Creates a model response.

        :param request_body: Required.
        :type request_body: ~azureaiagents.models.CreateResponse
        :keyword accept: Is either a Literal["application/json"] type or a Literal["text/event-stream"]
         type. Required.
        :paramtype accept: str or str
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: ResponseStreamEvent. The ResponseStreamEvent is compatible with MutableMapping
        :rtype: ~openai.models.ResponseStreamEvent
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    async def create_response(
        self,
        request_body: JSON,
        *,
        accept: Literal["application/json", "text/event-stream"],
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _openai_models4.ResponseStreamEvent:
        """Creates a model response.

        :param request_body: Required.
        :type request_body: JSON
        :keyword accept: Is either a Literal["application/json"] type or a Literal["text/event-stream"]
         type. Required.
        :paramtype accept: str or str
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: ResponseStreamEvent. The ResponseStreamEvent is compatible with MutableMapping
        :rtype: ~openai.models.ResponseStreamEvent
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    async def create_response(
        self,
        request_body: IO[bytes],
        *,
        accept: Literal["application/json", "text/event-stream"],
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _openai_models4.ResponseStreamEvent:
        """Creates a model response.

        :param request_body: Required.
        :type request_body: IO[bytes]
        :keyword accept: Is either a Literal["application/json"] type or a Literal["text/event-stream"]
         type. Required.
        :paramtype accept: str or str
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: ResponseStreamEvent. The ResponseStreamEvent is compatible with MutableMapping
        :rtype: ~openai.models.ResponseStreamEvent
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace_async
    async def create_response(
        self,
        request_body: Union[_models2.CreateResponse, JSON, IO[bytes]],
        *,
        accept: Literal["application/json", "text/event-stream"],
        **kwargs: Any
    ) -> _openai_models4.ResponseStreamEvent:
        """Creates a model response.

        :param request_body: Is one of the following types: CreateResponse, JSON, IO[bytes] Required.
        :type request_body: ~azureaiagents.models.CreateResponse or JSON or IO[bytes]
        :keyword accept: Is either a Literal["application/json"] type or a Literal["text/event-stream"]
         type. Required.
        :paramtype accept: str or str
        :return: ResponseStreamEvent. The ResponseStreamEvent is compatible with MutableMapping
        :rtype: ~openai.models.ResponseStreamEvent
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_openai_models4.ResponseStreamEvent] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(request_body, (IOBase, bytes)):
            _content = request_body
        else:
            _content = json.dumps(request_body, cls=SdkJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_responses_create_response_request(
            accept=accept,
            content_type=content_type,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _failsafe_deserialize(_openai_models4.ResponseErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_openai_models4.ResponseStreamEvent, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def get_response(
        self,
        response_id: str,
        *,
        includables: Optional[List[Union[str, _openai_models4.Includable]]] = None,
        stream_parameter: Optional[bool] = None,
        starting_after: Optional[int] = None,
        **kwargs: Any
    ) -> _openai_models4.ResponseStreamEvent:
        """Retrieves a model response with the given ID.

        :param response_id: The ID of the response to retrieve. Required.
        :type response_id: str
        :keyword includables: Default value is None.
        :paramtype includables: list[str or ~openai.models.Includable]
        :keyword stream_parameter: If set to true, model response data will be streamed to the client
         as it is generated using server-sent events. Default value is None.
        :paramtype stream_parameter: bool
        :keyword starting_after: The sequence number of the event after which to start streaming.
         Default value is None.
        :paramtype starting_after: int
        :return: ResponseStreamEvent. The ResponseStreamEvent is compatible with MutableMapping
        :rtype: ~openai.models.ResponseStreamEvent
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_openai_models4.ResponseStreamEvent] = kwargs.pop("cls", None)

        _request = build_responses_get_response_request(
            response_id=response_id,
            includables=includables,
            stream_parameter=stream_parameter,
            starting_after=starting_after,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _failsafe_deserialize(_openai_models4.ResponseErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_openai_models4.ResponseStreamEvent, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def delete_response(self, response_id: str, **kwargs: Any) -> _models2.DeleteResponseResponse:
        """delete_response.

        :param response_id: The ID of the response to delete. Required.
        :type response_id: str
        :return: DeleteResponseResponse. The DeleteResponseResponse is compatible with MutableMapping
        :rtype: ~azureaiagents.models.DeleteResponseResponse
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models2.DeleteResponseResponse] = kwargs.pop("cls", None)

        _request = build_responses_delete_response_request(
            response_id=response_id,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _failsafe_deserialize(_openai_models4.ResponseErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models2.DeleteResponseResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def cancel_response(self, response_id: str, **kwargs: Any) -> _models2.Response:
        """cancel_response.

        :param response_id: The ID of the response to cancel. Required.
        :type response_id: str
        :return: Response. The Response is compatible with MutableMapping
        :rtype: ~azureaiagents.models.Response
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models2.Response] = kwargs.pop("cls", None)

        _request = build_responses_cancel_response_request(
            response_id=response_id,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _failsafe_deserialize(_openai_models4.ResponseErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models2.Response, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def list_input_items(
        self,
        response_id: str,
        *,
        limit: Optional[int] = None,
        order: Optional[Literal["asc", "desc"]] = None,
        after: Optional[str] = None,
        before: Optional[str] = None,
        **kwargs: Any
    ) -> _openai_models4.ResponseItemList:
        """Returns a list of input items for a given response.

        :param response_id: The ID of the response to retrieve. Required.
        :type response_id: str
        :keyword limit: A limit on the number of objects to be returned. Limit can range between 1 and
         100, and the
         default is 20. Default value is None.
        :paramtype limit: int
        :keyword order: Sort order by the ``created_at`` timestamp of the objects. ``asc`` for
         ascending order and``desc``
         for descending order. Is either a Literal["asc"] type or a Literal["desc"] type. Default value
         is None.
        :paramtype order: str or str
        :keyword after: A cursor for use in pagination. ``after`` is an object ID that defines your
         place in the list.
         For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
         subsequent call can include after=obj_foo in order to fetch the next page of the list. Default
         value is None.
        :paramtype after: str
        :keyword before: A cursor for use in pagination. ``before`` is an object ID that defines your
         place in the list.
         For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
         subsequent call can include before=obj_foo in order to fetch the previous page of the list.
         Default value is None.
        :paramtype before: str
        :return: ResponseItemList. The ResponseItemList is compatible with MutableMapping
        :rtype: ~openai.models.ResponseItemList
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_openai_models4.ResponseItemList] = kwargs.pop("cls", None)

        _request = build_responses_list_input_items_request(
            response_id=response_id,
            limit=limit,
            order=order,
            after=after,
            before=before,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _failsafe_deserialize(_openai_models4.ResponseErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_openai_models4.ResponseItemList, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def list_responses(
        self,
        *,
        agent_name: Optional[str] = None,
        agent_version: Optional[str] = None,
        conversation_id: Optional[str] = None,
        limit: Optional[int] = None,
        order: Optional[Literal["asc", "desc"]] = None,
        after: Optional[str] = None,
        before: Optional[str] = None,
        **kwargs: Any
    ) -> _openai_models4.Error:
        """Returns the list of all responses.

        list_responses.

        :keyword agent_name: Filter by agent name. If provided, only responses associated with the
         specified agent will be returned. Default value is None.
        :paramtype agent_name: str
        :keyword agent_version: Filter by agent version. If provided, only responses associated with
         the specified agent version will be returned. Default value is None.
        :paramtype agent_version: str
        :keyword conversation_id: Filter by conversation ID. If provided, only responses associated
         with the specified conversation will be returned. Default value is None.
        :paramtype conversation_id: str
        :keyword limit: A limit on the number of objects to be returned. Limit can range between 1 and
         100, and the
         default is 20. Default value is None.
        :paramtype limit: int
        :keyword order: Sort order by the ``created_at`` timestamp of the objects. ``asc`` for
         ascending order and``desc``
         for descending order. Is either a Literal["asc"] type or a Literal["desc"] type. Default value
         is None.
        :paramtype order: str or str
        :keyword after: A cursor for use in pagination. ``after`` is an object ID that defines your
         place in the list.
         For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
         subsequent call can include after=obj_foo in order to fetch the next page of the list. Default
         value is None.
        :paramtype after: str
        :keyword before: A cursor for use in pagination. ``before`` is an object ID that defines your
         place in the list.
         For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
         subsequent call can include before=obj_foo in order to fetch the previous page of the list.
         Default value is None.
        :paramtype before: str
        :return: Error. The Error is compatible with MutableMapping
        :rtype: ~openai.models.Error
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        accept: Literal["application/json"] = kwargs.pop("accept", _headers.pop("accept", "application/json"))
        cls: ClsType[_openai_models4.Error] = kwargs.pop("cls", None)

        _request = build_responses_list_responses_request(
            agent_name=agent_name,
            agent_version=agent_version,
            conversation_id=conversation_id,
            limit=limit,
            order=order,
            after=after,
            before=before,
            accept=accept,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    await response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_openai_models4.Error, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

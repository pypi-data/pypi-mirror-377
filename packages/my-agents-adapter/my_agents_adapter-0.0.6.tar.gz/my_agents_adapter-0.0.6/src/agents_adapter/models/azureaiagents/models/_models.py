# pylint: disable=line-too-long,useless-suppression,too-many-lines
# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
# pylint: disable=useless-super-delegation

import datetime
from typing import Any, Dict, List, Literal, Mapping, Optional, TYPE_CHECKING, Union, overload

from ...openai.models import ItemParam, ItemResource, Tool
from .._utils.model_base import Model as _Model, rest_discriminator, rest_field
from ._enums import AgentKind

if TYPE_CHECKING:
    from .. import models as _models
    from ...openai import models as _openai_models3


class AgentDefinition(_Model):
    """AgentDefinition.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    CustomAgentDefinition, PromptAgentDefinition, WorkflowDefinition

    :ivar kind: Required. Known values are: "prompt_agent", "custom_agent", and "workflow".
    :vartype kind: str or ~azureaiagents.models.AgentKind
    """

    __mapping__: Dict[str, _Model] = {}
    kind: str = rest_discriminator(name="kind", visibility=["read", "create", "update", "delete", "query"])
    """Required. Known values are: \"prompt_agent\", \"custom_agent\", and \"workflow\"."""

    @overload
    def __init__(
        self,
        *,
        kind: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class AgentId(_Model):
    """AgentId.

    :ivar type: Required. Default value is "agent_id".
    :vartype type: str
    :ivar name: The name of the agent. Required.
    :vartype name: str
    :ivar version: The version identifier of the agent.
    :vartype version: str
    """

    type: Literal["agent_id"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required. Default value is \"agent_id\"."""
    name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the agent. Required."""
    version: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The version identifier of the agent."""

    @overload
    def __init__(
        self,
        *,
        name: str,
        version: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type: Literal["agent_id"] = "agent_id"


class AgentLabelList(_Model):
    """AgentLabelList.

    :ivar data: A list of items used to generate this response. Required.
    :vartype data: list[~azureaiagents.models.AgentLabelObject]
    :ivar object: The object type. Always 'list'. Required. Default value is "list".
    :vartype object: str
    :ivar first_id: ID of the first item in the returned page. Required.
    :vartype first_id: str
    :ivar last_id: ID of the last item in the returned page. Required.
    :vartype last_id: str
    :ivar has_more: Whether more items are available after this page. Required.
    :vartype has_more: bool
    """

    data: List["_models.AgentLabelObject"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A list of items used to generate this response. Required."""
    object: Literal["list"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The object type. Always 'list'. Required. Default value is \"list\"."""
    first_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """ID of the first item in the returned page. Required."""
    last_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """ID of the last item in the returned page. Required."""
    has_more: bool = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether more items are available after this page. Required."""

    @overload
    def __init__(
        self,
        *,
        data: List["_models.AgentLabelObject"],
        first_id: str,
        last_id: str,
        has_more: bool,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.object: Literal["list"] = "list"


class AgentLabelObject(_Model):
    """An agent label object that shows the association between agent and a specific version of agent.
    Labels are used to mark specific versions of the agent for easy retrieval.

    :ivar object: The object type, which is always 'agent.label'. Required. Default value is
     "agent.label".
    :vartype object: str
    :ivar id: The unique identifier of the label. Every label update results in a new label ID.
     Required.
    :vartype id: str
    :ivar name: The name of the label. Required.
    :vartype name: str
    :ivar created_at: The Unix timestamp (seconds) when the label was created. Required.
    :vartype created_at: ~datetime.datetime
    :ivar agent_version: The version of the agent that this label is associated with. If not
     provided, then the label is not associated with any specific version.
    :vartype agent_version: str
    """

    object: Literal["agent.label"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The object type, which is always 'agent.label'. Required. Default value is \"agent.label\"."""
    id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique identifier of the label. Every label update results in a new label ID. Required."""
    name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the label. Required."""
    created_at: datetime.datetime = rest_field(
        visibility=["read", "create", "update", "delete", "query"], format="unix-timestamp"
    )
    """The Unix timestamp (seconds) when the label was created. Required."""
    agent_version: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The version of the agent that this label is associated with. If not provided, then the label is
     not associated with any specific version."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        name: str,
        created_at: datetime.datetime,
        agent_version: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.object: Literal["agent.label"] = "agent.label"


class AgentList(_Model):
    """AgentList.

    :ivar data: A list of items used to generate this response. Required.
    :vartype data: list[~azureaiagents.models.AgentObject]
    :ivar object: The object type. Always 'list'. Required. Default value is "list".
    :vartype object: str
    :ivar first_id: ID of the first item in the returned page. Required.
    :vartype first_id: str
    :ivar last_id: ID of the last item in the returned page. Required.
    :vartype last_id: str
    :ivar has_more: Whether more items are available after this page. Required.
    :vartype has_more: bool
    """

    data: List["_models.AgentObject"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A list of items used to generate this response. Required."""
    object: Literal["list"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The object type. Always 'list'. Required. Default value is \"list\"."""
    first_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """ID of the first item in the returned page. Required."""
    last_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """ID of the last item in the returned page. Required."""
    has_more: bool = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether more items are available after this page. Required."""

    @overload
    def __init__(
        self,
        *,
        data: List["_models.AgentObject"],
        first_id: str,
        last_id: str,
        has_more: bool,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.object: Literal["list"] = "list"


class AgentObject(_Model):
    """AgentObject.

    :ivar object: The object type, which is always 'agent'. Required. Default value is "agent".
    :vartype object: str
    :ivar id: The unique identifier of the agent. Required.
    :vartype id: str
    :ivar name: The name of the agent. Required.
    :vartype name: str
    :ivar labels: The labels and their version associations for this agent. Required.
    :vartype labels: list[~azureaiagents.models.AgentLabelObject]
    """

    object: Literal["agent"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The object type, which is always 'agent'. Required. Default value is \"agent\"."""
    id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique identifier of the agent. Required."""
    name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the agent. Required."""
    labels: List["_models.AgentLabelObject"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The labels and their version associations for this agent. Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        name: str,
        labels: List["_models.AgentLabelObject"],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.object: Literal["agent"] = "agent"


class AgentReference(_Model):
    """AgentReference.

    :ivar type: Required. Default value is "agent_reference".
    :vartype type: str
    :ivar name: The name of the agent. Required.
    :vartype name: str
    :ivar version: The version identifier of the agent.
    :vartype version: str
    :ivar label: The label that identifies the agent.
    :vartype label: str
    """

    type: Literal["agent_reference"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required. Default value is \"agent_reference\"."""
    name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the agent. Required."""
    version: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The version identifier of the agent."""
    label: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The label that identifies the agent."""

    @overload
    def __init__(
        self,
        *,
        name: str,
        version: Optional[str] = None,
        label: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type: Literal["agent_reference"] = "agent_reference"


class AgentVersionList(_Model):
    """AgentVersionList.

    :ivar data: A list of items used to generate this response. Required.
    :vartype data: list[~azureaiagents.models.AgentVersionObject]
    :ivar object: The object type. Always 'list'. Required. Default value is "list".
    :vartype object: str
    :ivar first_id: ID of the first item in the returned page. Required.
    :vartype first_id: str
    :ivar last_id: ID of the last item in the returned page. Required.
    :vartype last_id: str
    :ivar has_more: Whether more items are available after this page. Required.
    :vartype has_more: bool
    """

    data: List["_models.AgentVersionObject"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A list of items used to generate this response. Required."""
    object: Literal["list"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The object type. Always 'list'. Required. Default value is \"list\"."""
    first_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """ID of the first item in the returned page. Required."""
    last_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """ID of the last item in the returned page. Required."""
    has_more: bool = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether more items are available after this page. Required."""

    @overload
    def __init__(
        self,
        *,
        data: List["_models.AgentVersionObject"],
        first_id: str,
        last_id: str,
        has_more: bool,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.object: Literal["list"] = "list"


class AgentVersionObject(_Model):
    """AgentVersionObject.

    :ivar object: The object type, which is always 'agent.version'. Required. Default value is
     "agent.version".
    :vartype object: str
    :ivar id: The unique identifier of the agent version. Required.
    :vartype id: str
    :ivar name: The name of the agent. Name can be used to retrieve/update/delete the agent.
     Required.
    :vartype name: str
    :ivar version: The version identifier of the agent. Agents are immutable and every update
     creates a new version while keeping the name same. Required.
    :vartype version: str
    :ivar description: A human-readable description of the agent.
    :vartype description: str
    :ivar metadata: Arbitrary key-value metadata to associate with the agent.
    :vartype metadata: dict[str, str]
    :ivar created_at: The Unix timestamp (seconds) when the agent was created. Required.
    :vartype created_at: ~datetime.datetime
    :ivar labels: The labels associated with this version of the agent. Labels are used to mark
     specific versions of the agent for easy retrieval. Required.
    :vartype labels: list[str]
    :ivar status: The status of agent. Required. Is one of the following types:
     Literal["creating"], Literal["updating"], Literal["deleting"], Literal["active"]
    :vartype status: str or str or str or str
    :ivar definition: Required.
    :vartype definition: ~azureaiagents.models.AgentDefinition
    """

    object: Literal["agent.version"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The object type, which is always 'agent.version'. Required. Default value is \"agent.version\"."""
    id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique identifier of the agent version. Required."""
    name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the agent. Name can be used to retrieve/update/delete the agent. Required."""
    version: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The version identifier of the agent. Agents are immutable and every update creates a new
     version while keeping the name same. Required."""
    description: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A human-readable description of the agent."""
    metadata: Optional[Dict[str, str]] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Arbitrary key-value metadata to associate with the agent."""
    created_at: datetime.datetime = rest_field(
        visibility=["read", "create", "update", "delete", "query"], format="unix-timestamp"
    )
    """The Unix timestamp (seconds) when the agent was created. Required."""
    labels: List[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The labels associated with this version of the agent. Labels are used to mark specific versions
     of the agent for easy retrieval. Required."""
    status: Literal["creating", "updating", "deleting", "active"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The status of agent. Required. Is one of the following types: Literal[\"creating\"],
     Literal[\"updating\"], Literal[\"deleting\"], Literal[\"active\"]"""
    definition: "_models.AgentDefinition" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        name: str,
        version: str,
        created_at: datetime.datetime,
        labels: List[str],
        status: Literal["creating", "updating", "deleting", "active"],
        definition: "_models.AgentDefinition",
        description: Optional[str] = None,
        metadata: Optional[Dict[str, str]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.object: Literal["agent.version"] = "agent.version"


class CaptureSemanticEventsTool(Tool, discriminator="capture_semantic_events"):
    """CaptureSemanticEventsTool.

    :ivar type: The type of the tool. Always ``capture_semantic_events``. Required. Default value
     is "capture_semantic_events".
    :vartype type: str
    :ivar events: Set of structured events to catpure from the model. Required.
    :vartype events: dict[str, ~azureaiagents.models.SemanticEventDefinition]
    """

    type: Literal["capture_semantic_events"] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the tool. Always ``capture_semantic_events``. Required. Default value is
     \"capture_semantic_events\"."""
    events: Dict[str, "_models.SemanticEventDefinition"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Set of structured events to catpure from the model. Required."""

    @overload
    def __init__(
        self,
        *,
        events: Dict[str, "_models.SemanticEventDefinition"],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, type="capture_semantic_events", **kwargs)


class CaptureStructuredOutputsTool(Tool, discriminator="capture_structured_outputs"):
    """CaptureStructuredOutputsTool.

    :ivar type: The type of the tool. Always ``capture_structured_outputs``. Required. Default
     value is "capture_structured_outputs".
    :vartype type: str
    :ivar outputs: Set of structured outputs to capture from the model. Required.
    :vartype outputs: dict[str, ~azureaiagents.models.StructuredOutputDefinition]
    """

    type: Literal["capture_structured_outputs"] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the tool. Always ``capture_structured_outputs``. Required. Default value is
     \"capture_structured_outputs\"."""
    outputs: Dict[str, "_models.StructuredOutputDefinition"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Set of structured outputs to capture from the model. Required."""

    @overload
    def __init__(
        self,
        *,
        outputs: Dict[str, "_models.StructuredOutputDefinition"],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, type="capture_structured_outputs", **kwargs)


class ConversationItemInput(_Model):
    """ConversationItemInput.

    :ivar item: Required.
    :vartype item: ~openai.models.ItemParam
    """

    item: "_openai_models3.ItemParam" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""

    @overload
    def __init__(
        self,
        *,
        item: "_openai_models3.ItemParam",
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ConversationItemList(_Model):
    """ConversationItemList.

    :ivar data: A list of items used to generate this response. Required.
    :vartype data: list[~openai.models.ItemResource]
    :ivar object: The object type. Always 'list'. Required. Default value is "list".
    :vartype object: str
    :ivar first_id: ID of the first item in the returned page. Required.
    :vartype first_id: str
    :ivar last_id: ID of the last item in the returned page. Required.
    :vartype last_id: str
    :ivar has_more: Whether more items are available after this page. Required.
    :vartype has_more: bool
    """

    data: List["_openai_models3.ItemResource"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A list of items used to generate this response. Required."""
    object: Literal["list"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The object type. Always 'list'. Required. Default value is \"list\"."""
    first_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """ID of the first item in the returned page. Required."""
    last_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """ID of the last item in the returned page. Required."""
    has_more: bool = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether more items are available after this page. Required."""

    @overload
    def __init__(
        self,
        *,
        data: List["_openai_models3.ItemResource"],
        first_id: str,
        last_id: str,
        has_more: bool,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.object: Literal["list"] = "list"


class ConversationList(_Model):
    """ConversationList.

    :ivar data: A list of items used to generate this response. Required.
    :vartype data: list[~azureaiagents.models.ConversationObject]
    :ivar object: The object type. Always 'list'. Required. Default value is "list".
    :vartype object: str
    :ivar first_id: ID of the first item in the returned page. Required.
    :vartype first_id: str
    :ivar last_id: ID of the last item in the returned page. Required.
    :vartype last_id: str
    :ivar has_more: Whether more items are available after this page. Required.
    :vartype has_more: bool
    """

    data: List["_models.ConversationObject"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A list of items used to generate this response. Required."""
    object: Literal["list"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The object type. Always 'list'. Required. Default value is \"list\"."""
    first_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """ID of the first item in the returned page. Required."""
    last_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """ID of the last item in the returned page. Required."""
    has_more: bool = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether more items are available after this page. Required."""

    @overload
    def __init__(
        self,
        *,
        data: List["_models.ConversationObject"],
        first_id: str,
        last_id: str,
        has_more: bool,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.object: Literal["list"] = "list"


class ConversationObject(_Model):
    """ConversationObject.

    :ivar object: Required. Default value is "conversation".
    :vartype object: str
    :ivar id: Required.
    :vartype id: str
    :ivar created_at: The Unix timestamp (seconds) when the conversation was created. Required.
    :vartype created_at: ~datetime.datetime
    :ivar metadata:
    :vartype metadata: dict[str, str]
    """

    object: Literal["conversation"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required. Default value is \"conversation\"."""
    id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    created_at: datetime.datetime = rest_field(
        visibility=["read", "create", "update", "delete", "query"], format="unix-timestamp"
    )
    """The Unix timestamp (seconds) when the conversation was created. Required."""
    metadata: Optional[Dict[str, str]] = rest_field(visibility=["read", "create", "update", "delete", "query"])

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        created_at: datetime.datetime,
        metadata: Optional[Dict[str, str]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.object: Literal["conversation"] = "conversation"


class ConversationOptions(_Model):
    """ConversationOptions.

    :ivar id: The conversation ID to associate with this response.
    :vartype id: str
    :ivar commit: If true, commit the outputs of the response to the conversation if a conversation
     is specified by the user. Required.
    :vartype commit: bool
    """

    id: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The conversation ID to associate with this response."""
    commit: bool = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """If true, commit the outputs of the response to the conversation if a conversation is specified
     by the user. Required."""

    @overload
    def __init__(
        self,
        *,
        commit: bool,
        id: Optional[str] = None,  # pylint: disable=redefined-builtin
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class CreateAgentVersionRequest(_Model):
    """CreateAgentVersionRequest.

    :ivar description: A human-readable description of the agent.
    :vartype description: str
    :ivar metadata: Arbitrary key-value metadata to associate with the agent.
    :vartype metadata: dict[str, str]
    :ivar definition: The agent definition. This can be a workflow, custom agent, or a simple agent
     definition. Required.
    :vartype definition: ~azureaiagents.models.AgentDefinition
    """

    description: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A human-readable description of the agent."""
    metadata: Optional[Dict[str, str]] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Arbitrary key-value metadata to associate with the agent."""
    definition: "_models.AgentDefinition" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The agent definition. This can be a workflow, custom agent, or a simple agent definition.
     Required."""

    @overload
    def __init__(
        self,
        *,
        definition: "_models.AgentDefinition",
        description: Optional[str] = None,
        metadata: Optional[Dict[str, str]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class CreateConversationInput(_Model):
    """CreateConversationInput.

    :ivar metadata:
    :vartype metadata: dict[str, str]
    :ivar items_property:
    :vartype items_property: list[~openai.models.ItemParam]
    """

    metadata: Optional[Dict[str, str]] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    items_property: Optional[List["_openai_models3.ItemParam"]] = rest_field(
        name="items", visibility=["read", "create", "update", "delete", "query"]
    )

    @overload
    def __init__(
        self,
        *,
        metadata: Optional[Dict[str, str]] = None,
        items_property: Optional[List["_openai_models3.ItemParam"]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class CreateResponse(_Model):
    """CreateResponse.

    :ivar agent: The agent to use for generating the response. Required.
    :vartype agent: ~azureaiagents.models.AgentReference
    :ivar conversation: The conversation options to associate with this response.
    :vartype conversation: ~azureaiagents.models.ConversationOptions
    :ivar metadata: Set of 16 key-value pairs that can be attached to an object. This can be
     useful for storing additional information about the object in a structured
     format, and querying for objects via API or the dashboard.

     Keys are strings with a maximum length of 64 characters. Values are strings
     with a maximum length of 512 characters.
    :vartype metadata: dict[str, str]
    :ivar temperature: What sampling temperature to use, between 0 and 2. Higher values like 0.8
     will make the output more random, while lower values like 0.2 will make it more focused and
     deterministic.
     We generally recommend altering this or ``top_p`` but not both.
    :vartype temperature: float
    :ivar top_p: An alternative to sampling with temperature, called nucleus sampling,
     where the model considers the results of the tokens with top_p probability
     mass. So 0.1 means only the tokens comprising the top 10% probability mass
     are considered.

     We generally recommend altering this or ``temperature`` but not both.
    :vartype top_p: float
    :ivar user: A unique identifier representing your end-user, which can help OpenAI to monitor
     and detect abuse. `Learn more </docs/guides/safety-best-practices#end-user-ids>`_.
    :vartype user: str
    :ivar service_tier: Known values are: "auto", "default", "flex", "scale", and "priority".
    :vartype service_tier: str or ~openai.models.ServiceTier
    :ivar top_logprobs: An integer between 0 and 20 specifying the number of most likely tokens to
     return at each token position, each with an associated log probability.
    :vartype top_logprobs: int
    :ivar previous_response_id: The unique ID of the previous response to the model. Use this to
     create multi-turn conversations. Learn more about
     `conversation state </docs/guides/conversation-state>`_.
    :vartype previous_response_id: str
    :ivar model: Model ID used to generate the response, like ``gpt-4o`` or ``o3``. OpenAI
     offers a wide range of models with different capabilities, performance
     characteristics, and price points. Refer to the `model guide </docs/models>`_
     to browse and compare available models. Known values are: "gpt-4.1", "gpt-4.1-mini",
     "gpt-4.1-nano", "gpt-4.1-2025-04-14", "gpt-4.1-mini-2025-04-14", "gpt-4.1-nano-2025-04-14",
     "o4-mini", "o4-mini-2025-04-16", "o3", "o3-2025-04-16", "o3-mini", "o3-mini-2025-01-31", "o1",
     "o1-2024-12-17", "o1-preview", "o1-preview-2024-09-12", "o1-mini", "o1-mini-2024-09-12",
     "gpt-4o", "gpt-4o-2024-11-20", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13",
     "gpt-4o-audio-preview", "gpt-4o-audio-preview-2024-10-01", "gpt-4o-audio-preview-2024-12-17",
     "gpt-4o-audio-preview-2025-06-03", "gpt-4o-mini-audio-preview",
     "gpt-4o-mini-audio-preview-2024-12-17", "gpt-4o-search-preview", "gpt-4o-mini-search-preview",
     "gpt-4o-search-preview-2025-03-11", "gpt-4o-mini-search-preview-2025-03-11",
     "chatgpt-4o-latest", "codex-mini-latest", "gpt-4o-mini", "gpt-4o-mini-2024-07-18",
     "gpt-4-turbo", "gpt-4-turbo-2024-04-09", "gpt-4-0125-preview", "gpt-4-turbo-preview",
     "gpt-4-1106-preview", "gpt-4-vision-preview", "gpt-4", "gpt-4-0314", "gpt-4-0613", "gpt-4-32k",
     "gpt-4-32k-0314", "gpt-4-32k-0613", "gpt-3.5-turbo", "gpt-3.5-turbo-16k", "gpt-3.5-turbo-0301",
     "gpt-3.5-turbo-0613", "gpt-3.5-turbo-1106", "gpt-3.5-turbo-0125", "gpt-3.5-turbo-16k-0613",
     "o1-pro", "o1-pro-2025-03-19", "o3-pro", "o3-pro-2025-06-10", "o3-deep-research",
     "o3-deep-research-2025-06-26", "o4-mini-deep-research", "o4-mini-deep-research-2025-06-26",
     "computer-use-preview", and "computer-use-preview-2025-03-11".
    :vartype model: str or ~openai.models.ModelIdsResponses
    :ivar reasoning:
    :vartype reasoning: ~openai.models.Reasoning
    :ivar background: Whether to run the model response in the background.
     `Learn more </docs/guides/background>`_.
    :vartype background: bool
    :ivar max_output_tokens: An upper bound for the number of tokens that can be generated for a
     response, including visible output tokens and `reasoning tokens </docs/guides/reasoning>`_.
    :vartype max_output_tokens: int
    :ivar max_tool_calls: The maximum number of total calls to built-in tools that can be processed
     in a response. This maximum number applies across all built-in tool calls, not per individual
     tool. Any further attempts to call a tool by the model will be ignored.
    :vartype max_tool_calls: int
    :ivar text: Configuration options for a text response from the model. Can be plain
     text or structured JSON data. Learn more:

     * [Text inputs and outputs](/docs/guides/text)
     * [Structured Outputs](/docs/guides/structured-outputs).
    :vartype text: ~openai.models.CreateResponseText
    :ivar tools: An array of tools the model may call while generating a response. You
     can specify which tool to use by setting the ``tool_choice`` parameter.

     The two categories of tools you can provide the model are:



     * **Built-in tools**: Tools that are provided by OpenAI that extend the
     model's capabilities, like [web search](/docs/guides/tools-web-search)
     or [file search](/docs/guides/tools-file-search). Learn more about
     [built-in tools](/docs/guides/tools).
     * **Function calls (custom tools)**: Functions that are defined by you,
     enabling the model to call your own code. Learn more about
     [function calling](/docs/guides/function-calling).
    :vartype tools: list[~openai.models.Tool]
    :ivar tool_choice: How the model should select which tool (or tools) to use when generating
     a response. See the ``tools`` parameter to see how to specify which tools
     the model can call. Is either a Union[str, "_openai_models2.ToolChoiceOptions"] type or a
     ToolChoiceObject type.
    :vartype tool_choice: str or ~openai.models.ToolChoiceOptions or
     ~openai.models.ToolChoiceObject
    :ivar prompt:
    :vartype prompt: ~openai.models.Prompt
    :ivar truncation: The truncation strategy to use for the model response.

     * `auto`: If the context of this response and previous ones exceeds
     the model's context window size, the model will truncate the
     response to fit the context window by dropping input items in the
     middle of the conversation.
     * `disabled` (default): If a model response will exceed the context window
     size for a model, the request will fail with a 400 error. Is either a Literal["auto"] type or a
     Literal["disabled"] type.
    :vartype truncation: str or str
    :ivar input: Text, image, or file inputs to the model, used to generate a response.

     Learn more:

     * [Text inputs and outputs](/docs/guides/text)
     * [Image inputs](/docs/guides/images)
     * [File inputs](/docs/guides/pdf-files)
     * [Conversation state](/docs/guides/conversation-state)
     * [Function calling](/docs/guides/function-calling). Is either a str type or a
     [Union["_openai_models2.ImplicitUserMessage", "_openai_models2.ItemParam"]] type.
    :vartype input: str or list[~openai.models.ImplicitUserMessage or ~openai.models.ItemParam]
    :ivar include: Specify additional output data to include in the model response. Currently
     supported values are:

     * `code_interpreter_call.outputs`: Includes the outputs of python code execution
     in code interpreter tool call items.
     * `computer_call_output.output.image_url`: Include image urls from the computer call output.
     * `file_search_call.results`: Include the search results of
     the file search tool call.
     * `message.input_image.image_url`: Include image urls from the input message.
     * `message.output_text.logprobs`: Include logprobs with assistant messages.
     * `reasoning.encrypted_content`: Includes an encrypted version of reasoning
     tokens in reasoning item outputs. This enables reasoning items to be used in
     multi-turn conversations when using the Responses API statelessly (like
     when the `store` parameter is set to `false`, or when an organization is
     enrolled in the zero data retention program).
    :vartype include: list[str or ~openai.models.Includable]
    :ivar parallel_tool_calls: Whether to allow the model to run tool calls in parallel.
    :vartype parallel_tool_calls: bool
    :ivar store: Whether to store the generated model response for later retrieval via
     API.
    :vartype store: bool
    :ivar instructions: A system (or developer) message inserted into the model's context.

     When using along with ``previous_response_id``, the instructions from a previous
     response will not be carried over to the next response. This makes it simple
     to swap out system (or developer) messages in new responses.
    :vartype instructions: str
    :ivar stream: If set to true, the model response data will be streamed to the client
     as it is generated using `server-sent events
     <https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format>`_.
     See the `Streaming section below </docs/api-reference/responses-streaming>`_
     for more information.
    :vartype stream: bool
    """

    agent: "_models.AgentReference" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The agent to use for generating the response. Required."""
    conversation: Optional["_models.ConversationOptions"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The conversation options to associate with this response."""
    metadata: Optional[Dict[str, str]] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Set of 16 key-value pairs that can be attached to an object. This can be
     useful for storing additional information about the object in a structured
     format, and querying for objects via API or the dashboard.
     
     Keys are strings with a maximum length of 64 characters. Values are strings
     with a maximum length of 512 characters."""
    temperature: Optional[float] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output
     more random, while lower values like 0.2 will make it more focused and deterministic.
     We generally recommend altering this or ``top_p`` but not both."""
    top_p: Optional[float] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An alternative to sampling with temperature, called nucleus sampling,
     where the model considers the results of the tokens with top_p probability
     mass. So 0.1 means only the tokens comprising the top 10% probability mass
     are considered.
     
     We generally recommend altering this or ``temperature`` but not both."""
    user: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A unique identifier representing your end-user, which can help OpenAI to monitor and detect
     abuse. `Learn more </docs/guides/safety-best-practices#end-user-ids>`_."""
    service_tier: Optional[Union[str, "_openai_models3.ServiceTier"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Known values are: \"auto\", \"default\", \"flex\", \"scale\", and \"priority\"."""
    top_logprobs: Optional[int] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An integer between 0 and 20 specifying the number of most likely tokens to return at each token
     position, each with an associated log probability."""
    previous_response_id: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique ID of the previous response to the model. Use this to
     create multi-turn conversations. Learn more about
     `conversation state </docs/guides/conversation-state>`_."""
    model: Optional[Union[str, "_openai_models3.ModelIdsResponses"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Model ID used to generate the response, like ``gpt-4o`` or ``o3``. OpenAI
     offers a wide range of models with different capabilities, performance
     characteristics, and price points. Refer to the `model guide </docs/models>`_
     to browse and compare available models. Known values are: \"gpt-4.1\", \"gpt-4.1-mini\",
     \"gpt-4.1-nano\", \"gpt-4.1-2025-04-14\", \"gpt-4.1-mini-2025-04-14\",
     \"gpt-4.1-nano-2025-04-14\", \"o4-mini\", \"o4-mini-2025-04-16\", \"o3\", \"o3-2025-04-16\",
     \"o3-mini\", \"o3-mini-2025-01-31\", \"o1\", \"o1-2024-12-17\", \"o1-preview\",
     \"o1-preview-2024-09-12\", \"o1-mini\", \"o1-mini-2024-09-12\", \"gpt-4o\",
     \"gpt-4o-2024-11-20\", \"gpt-4o-2024-08-06\", \"gpt-4o-2024-05-13\", \"gpt-4o-audio-preview\",
     \"gpt-4o-audio-preview-2024-10-01\", \"gpt-4o-audio-preview-2024-12-17\",
     \"gpt-4o-audio-preview-2025-06-03\", \"gpt-4o-mini-audio-preview\",
     \"gpt-4o-mini-audio-preview-2024-12-17\", \"gpt-4o-search-preview\",
     \"gpt-4o-mini-search-preview\", \"gpt-4o-search-preview-2025-03-11\",
     \"gpt-4o-mini-search-preview-2025-03-11\", \"chatgpt-4o-latest\", \"codex-mini-latest\",
     \"gpt-4o-mini\", \"gpt-4o-mini-2024-07-18\", \"gpt-4-turbo\", \"gpt-4-turbo-2024-04-09\",
     \"gpt-4-0125-preview\", \"gpt-4-turbo-preview\", \"gpt-4-1106-preview\",
     \"gpt-4-vision-preview\", \"gpt-4\", \"gpt-4-0314\", \"gpt-4-0613\", \"gpt-4-32k\",
     \"gpt-4-32k-0314\", \"gpt-4-32k-0613\", \"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\",
     \"gpt-3.5-turbo-0301\", \"gpt-3.5-turbo-0613\", \"gpt-3.5-turbo-1106\", \"gpt-3.5-turbo-0125\",
     \"gpt-3.5-turbo-16k-0613\", \"o1-pro\", \"o1-pro-2025-03-19\", \"o3-pro\",
     \"o3-pro-2025-06-10\", \"o3-deep-research\", \"o3-deep-research-2025-06-26\",
     \"o4-mini-deep-research\", \"o4-mini-deep-research-2025-06-26\", \"computer-use-preview\", and
     \"computer-use-preview-2025-03-11\"."""
    reasoning: Optional["_openai_models3.Reasoning"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    background: Optional[bool] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether to run the model response in the background.
     `Learn more </docs/guides/background>`_."""
    max_output_tokens: Optional[int] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An upper bound for the number of tokens that can be generated for a response, including visible
     output tokens and `reasoning tokens </docs/guides/reasoning>`_."""
    max_tool_calls: Optional[int] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The maximum number of total calls to built-in tools that can be processed in a response. This
     maximum number applies across all built-in tool calls, not per individual tool. Any further
     attempts to call a tool by the model will be ignored."""
    text: Optional["_openai_models3.CreateResponseText"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Configuration options for a text response from the model. Can be plain
     text or structured JSON data. Learn more:
     
     * [Text inputs and outputs](/docs/guides/text)
     * [Structured Outputs](/docs/guides/structured-outputs)."""
    tools: Optional[List["_openai_models3.Tool"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """An array of tools the model may call while generating a response. You
     can specify which tool to use by setting the ``tool_choice`` parameter.
     
     The two categories of tools you can provide the model are:
     
     
     
     * **Built-in tools**: Tools that are provided by OpenAI that extend the
     model's capabilities, like [web search](/docs/guides/tools-web-search)
     or [file search](/docs/guides/tools-file-search). Learn more about
     [built-in tools](/docs/guides/tools).
     * **Function calls (custom tools)**: Functions that are defined by you,
     enabling the model to call your own code. Learn more about
     [function calling](/docs/guides/function-calling)."""
    tool_choice: Optional[Union[str, "_openai_models3.ToolChoiceOptions", "_openai_models3.ToolChoiceObject"]] = (
        rest_field(visibility=["read", "create", "update", "delete", "query"])
    )
    """How the model should select which tool (or tools) to use when generating
     a response. See the ``tools`` parameter to see how to specify which tools
     the model can call. Is either a Union[str, \"_openai_models2.ToolChoiceOptions\"] type or a
     ToolChoiceObject type."""
    prompt: Optional["_openai_models3.Prompt"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    truncation: Optional[Literal["auto", "disabled"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The truncation strategy to use for the model response.
     
     * `auto`: If the context of this response and previous ones exceeds
     the model's context window size, the model will truncate the
     response to fit the context window by dropping input items in the
     middle of the conversation.
     * `disabled` (default): If a model response will exceed the context window
     size for a model, the request will fail with a 400 error. Is either a Literal[\"auto\"] type or
     a Literal[\"disabled\"] type."""
    input: Optional[Union[str, List[Union["_openai_models3.ImplicitUserMessage", "_openai_models3.ItemParam"]]]] = (
        rest_field(visibility=["read", "create", "update", "delete", "query"])
    )
    """Text, image, or file inputs to the model, used to generate a response.
     
     Learn more:
     
     * [Text inputs and outputs](/docs/guides/text)
     * [Image inputs](/docs/guides/images)
     * [File inputs](/docs/guides/pdf-files)
     * [Conversation state](/docs/guides/conversation-state)
     * [Function calling](/docs/guides/function-calling). Is either a str type or a
     [Union[\"_openai_models2.ImplicitUserMessage\", \"_openai_models2.ItemParam\"]] type."""
    include: Optional[List[Union[str, "_openai_models3.Includable"]]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Specify additional output data to include in the model response. Currently
     supported values are:
     
     * `code_interpreter_call.outputs`: Includes the outputs of python code execution
     in code interpreter tool call items.
     * `computer_call_output.output.image_url`: Include image urls from the computer call output.
     * `file_search_call.results`: Include the search results of
     the file search tool call.
     * `message.input_image.image_url`: Include image urls from the input message.
     * `message.output_text.logprobs`: Include logprobs with assistant messages.
     * `reasoning.encrypted_content`: Includes an encrypted version of reasoning
     tokens in reasoning item outputs. This enables reasoning items to be used in
     multi-turn conversations when using the Responses API statelessly (like
     when the `store` parameter is set to `false`, or when an organization is
     enrolled in the zero data retention program)."""
    parallel_tool_calls: Optional[bool] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether to allow the model to run tool calls in parallel."""
    store: Optional[bool] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether to store the generated model response for later retrieval via
     API."""
    instructions: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A system (or developer) message inserted into the model's context.
     
     When using along with ``previous_response_id``, the instructions from a previous
     response will not be carried over to the next response. This makes it simple
     to swap out system (or developer) messages in new responses."""
    stream: Optional[bool] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """If set to true, the model response data will be streamed to the client
     as it is generated using `server-sent events
     <https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format>`_.
     See the `Streaming section below </docs/api-reference/responses-streaming>`_
     for more information."""

    @overload
    def __init__(  # pylint: disable=too-many-locals
        self,
        *,
        agent: "_models.AgentReference",
        conversation: Optional["_models.ConversationOptions"] = None,
        metadata: Optional[Dict[str, str]] = None,
        temperature: Optional[float] = None,
        top_p: Optional[float] = None,
        user: Optional[str] = None,
        service_tier: Optional[Union[str, "_openai_models3.ServiceTier"]] = None,
        top_logprobs: Optional[int] = None,
        previous_response_id: Optional[str] = None,
        model: Optional[Union[str, "_openai_models3.ModelIdsResponses"]] = None,
        reasoning: Optional["_openai_models3.Reasoning"] = None,
        background: Optional[bool] = None,
        max_output_tokens: Optional[int] = None,
        max_tool_calls: Optional[int] = None,
        text: Optional["_openai_models3.CreateResponseText"] = None,
        tools: Optional[List["_openai_models3.Tool"]] = None,
        tool_choice: Optional[
            Union[str, "_openai_models3.ToolChoiceOptions", "_openai_models3.ToolChoiceObject"]
        ] = None,
        prompt: Optional["_openai_models3.Prompt"] = None,
        truncation: Optional[Literal["auto", "disabled"]] = None,
        input: Optional[
            Union[str, List[Union["_openai_models3.ImplicitUserMessage", "_openai_models3.ItemParam"]]]
        ] = None,
        include: Optional[List[Union[str, "_openai_models3.Includable"]]] = None,
        parallel_tool_calls: Optional[bool] = None,
        store: Optional[bool] = None,
        instructions: Optional[str] = None,
        stream: Optional[bool] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class CustomAgentDefinition(AgentDefinition, discriminator="custom_agent"):
    """The custom agent definition.

    :ivar kind: Required.
    :vartype kind: str or ~azureaiagents.models.CUSTOM_AGENT
    """

    kind: Literal[AgentKind.CUSTOM_AGENT] = rest_discriminator(name="kind", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""

    @overload
    def __init__(
        self,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, kind=AgentKind.CUSTOM_AGENT, **kwargs)


class DeleteAgentResponse(_Model):
    """A deleted agent Object.

    :ivar object: The object type. Always 'agent.deleted'. Required. Default value is
     "agent.deleted".
    :vartype object: str
    :ivar name: The name of the agent. Required.
    :vartype name: str
    :ivar deleted: Whether the agent was successfully deleted. Required.
    :vartype deleted: bool
    """

    object: Literal["agent.deleted"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The object type. Always 'agent.deleted'. Required. Default value is \"agent.deleted\"."""
    name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the agent. Required."""
    deleted: bool = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether the agent was successfully deleted. Required."""

    @overload
    def __init__(
        self,
        *,
        name: str,
        deleted: bool,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.object: Literal["agent.deleted"] = "agent.deleted"


class DeleteAgentVersionResponse(_Model):
    """A deleted agent version Object.

    :ivar object: The object type. Always 'agent.deleted'. Required. Default value is
     "agent.version.deleted".
    :vartype object: str
    :ivar name: The name of the agent. Required.
    :vartype name: str
    :ivar version: The version identifier of the agent. Required.
    :vartype version: str
    :ivar deleted: Whether the agent was successfully deleted. Required.
    :vartype deleted: bool
    """

    object: Literal["agent.version.deleted"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The object type. Always 'agent.deleted'. Required. Default value is \"agent.version.deleted\"."""
    name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the agent. Required."""
    version: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The version identifier of the agent. Required."""
    deleted: bool = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether the agent was successfully deleted. Required."""

    @overload
    def __init__(
        self,
        *,
        name: str,
        version: str,
        deleted: bool,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.object: Literal["agent.version.deleted"] = "agent.version.deleted"


class DeleteConversationItemResponse(_Model):
    """A deleted conversation item Object.

    :ivar object: The object type. Always 'conversation.item.deleted'. Required. Default value is
     "conversation.item.deleted".
    :vartype object: str
    :ivar id: The id of the conversation item. Required.
    :vartype id: str
    :ivar deleted: Whether the conversation item was successfully deleted. Required.
    :vartype deleted: bool
    """

    object: Literal["conversation.item.deleted"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The object type. Always 'conversation.item.deleted'. Required. Default value is
     \"conversation.item.deleted\"."""
    id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The id of the conversation item. Required."""
    deleted: bool = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether the conversation item was successfully deleted. Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        deleted: bool,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.object: Literal["conversation.item.deleted"] = "conversation.item.deleted"


class DeleteConversationResponse(_Model):
    """A deleted conversation Object.

    :ivar object: The object type. Always 'conversation.deleted'. Required. Default value is
     "conversation.deleted".
    :vartype object: str
    :ivar id: The id of the conversation. Required.
    :vartype id: str
    :ivar deleted: Whether the conversation was successfully deleted. Required.
    :vartype deleted: bool
    """

    object: Literal["conversation.deleted"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The object type. Always 'conversation.deleted'. Required. Default value is
     \"conversation.deleted\"."""
    id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The id of the conversation. Required."""
    deleted: bool = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether the conversation was successfully deleted. Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        deleted: bool,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.object: Literal["conversation.deleted"] = "conversation.deleted"


class DeleteResponseResponse(_Model):
    """DeleteResponseResponse.

    :ivar id: Required.
    :vartype id: str
    :ivar object: Required. Default value is "response".
    :vartype object: str
    :ivar deleted: Required. Default value is True.
    :vartype deleted: bool
    """

    id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    object: Literal["response"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required. Default value is \"response\"."""
    deleted: Literal[True] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required. Default value is True."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.object: Literal["response"] = "response"
        self.deleted: Literal[True] = True


class Error(_Model):
    """Error.

    :ivar code: Required.
    :vartype code: str
    :ivar message: Required.
    :vartype message: str
    :ivar details:
    :vartype details: str
    :ivar errors:
    :vartype errors: dict[str, list[str]]
    """

    code: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    message: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    details: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    errors: Optional[Dict[str, List[str]]] = rest_field(visibility=["read", "create", "update", "delete", "query"])

    @overload
    def __init__(
        self,
        *,
        code: str,
        message: str,
        details: Optional[str] = None,
        errors: Optional[Dict[str, List[str]]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class WorkflowActionOutputItemResource(ItemResource, discriminator="workflow_action"):
    """WorkflowActionOutputItemResource.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    InvokeAzureAgentWorkflowActionOutputItemResource

    :ivar type: Required. Default value is "workflow_action".
    :vartype type: str
    :ivar kind: The kind of CPSDL action (e.g., 'SetVariable', 'InvokeAzureAgent'). Required.
     Default value is None.
    :vartype kind: str
    :ivar id: Unique identifier for the action. Required.
    :vartype id: str
    :ivar parent_action_id: ID of the parent action if this is a nested action.
    :vartype parent_action_id: str
    :ivar previous_action_id: ID of the previous action if this action follows another.
    :vartype previous_action_id: str
    :ivar status: Status of the action (e.g., 'in_progress', 'completed', 'failed', 'cancelled').
     Required. Is one of the following types: Literal["completed"], Literal["failed"],
     Literal["in_progress"], Literal["cancelled"]
    :vartype status: str or str or str or str
    """

    __mapping__: Dict[str, _Model] = {}
    type: Literal["workflow_action"] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required. Default value is \"workflow_action\"."""
    kind: str = rest_discriminator(name="kind", visibility=["read", "create", "update", "delete", "query"])
    """The kind of CPSDL action (e.g., 'SetVariable', 'InvokeAzureAgent'). Required. Default value is
     None."""
    parent_action_id: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """ID of the parent action if this is a nested action."""
    previous_action_id: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """ID of the previous action if this action follows another."""
    status: Literal["completed", "failed", "in_progress", "cancelled"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Status of the action (e.g., 'in_progress', 'completed', 'failed', 'cancelled'). Required. Is
     one of the following types: Literal[\"completed\"], Literal[\"failed\"],
     Literal[\"in_progress\"], Literal[\"cancelled\"]"""

    @overload
    def __init__(
        self,
        *,
        kind: str,
        id: str,  # pylint: disable=redefined-builtin
        status: Literal["completed", "failed", "in_progress", "cancelled"],
        parent_action_id: Optional[str] = None,
        previous_action_id: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, type="workflow_action", **kwargs)


class InvokeAzureAgentWorkflowActionOutputItemResource(
    WorkflowActionOutputItemResource, discriminator="InvokeAzureAgent"
):  # pylint: disable=name-too-long
    """Details about an agent invocation as part of a workflow action.

    :ivar type: Required. Default value is "workflow_action".
    :vartype type: str
    :ivar id: Unique identifier for the action. Required.
    :vartype id: str
    :ivar parent_action_id: ID of the parent action if this is a nested action.
    :vartype parent_action_id: str
    :ivar previous_action_id: ID of the previous action if this action follows another.
    :vartype previous_action_id: str
    :ivar status: Status of the action (e.g., 'in_progress', 'completed', 'failed', 'cancelled').
     Required. Is one of the following types: Literal["completed"], Literal["failed"],
     Literal["in_progress"], Literal["cancelled"]
    :vartype status: str or str or str or str
    :ivar kind: Required. Default value is "InvokeAzureAgent".
    :vartype kind: str
    :ivar agent: Agent id. Required.
    :vartype agent: ~azureaiagents.models.AgentId
    :ivar conversation_id: ID of the conversation for the agent invocation.
    :vartype conversation_id: str
    :ivar response_id: The response id for the agent invocation. Required.
    :vartype response_id: str
    """

    __mapping__: Dict[str, _Model] = {}
    kind: Literal["InvokeAzureAgent"] = rest_discriminator(name="kind", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required. Default value is \"InvokeAzureAgent\"."""
    agent: "_models.AgentId" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Agent id. Required."""
    conversation_id: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """ID of the conversation for the agent invocation."""
    response_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The response id for the agent invocation. Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        status: Literal["completed", "failed", "in_progress", "cancelled"],
        agent: "_models.AgentId",
        response_id: str,
        parent_action_id: Optional[str] = None,
        previous_action_id: Optional[str] = None,
        conversation_id: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, kind="InvokeAzureAgent", **kwargs)


class PromptAgentDefinition(AgentDefinition, discriminator="prompt_agent"):
    """The prompt agent definition.

    :ivar kind: Required.
    :vartype kind: str or ~azureaiagents.models.PROMPT_AGENT
    :ivar model: Model ID used to generate the response, like ``gpt-4o`` or ``o3``. OpenAI
     offers a wide range of models with different capabilities, performance
     characteristics, and price points. Refer to the `model guide </docs/models>`_
     to browse and compare available models. Known values are: "gpt-4.1", "gpt-4.1-mini",
     "gpt-4.1-nano", "gpt-4.1-2025-04-14", "gpt-4.1-mini-2025-04-14", "gpt-4.1-nano-2025-04-14",
     "o4-mini", "o4-mini-2025-04-16", "o3", "o3-2025-04-16", "o3-mini", "o3-mini-2025-01-31", "o1",
     "o1-2024-12-17", "o1-preview", "o1-preview-2024-09-12", "o1-mini", "o1-mini-2024-09-12",
     "gpt-4o", "gpt-4o-2024-11-20", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13",
     "gpt-4o-audio-preview", "gpt-4o-audio-preview-2024-10-01", "gpt-4o-audio-preview-2024-12-17",
     "gpt-4o-audio-preview-2025-06-03", "gpt-4o-mini-audio-preview",
     "gpt-4o-mini-audio-preview-2024-12-17", "gpt-4o-search-preview", "gpt-4o-mini-search-preview",
     "gpt-4o-search-preview-2025-03-11", "gpt-4o-mini-search-preview-2025-03-11",
     "chatgpt-4o-latest", "codex-mini-latest", "gpt-4o-mini", "gpt-4o-mini-2024-07-18",
     "gpt-4-turbo", "gpt-4-turbo-2024-04-09", "gpt-4-0125-preview", "gpt-4-turbo-preview",
     "gpt-4-1106-preview", "gpt-4-vision-preview", "gpt-4", "gpt-4-0314", "gpt-4-0613", "gpt-4-32k",
     "gpt-4-32k-0314", "gpt-4-32k-0613", "gpt-3.5-turbo", "gpt-3.5-turbo-16k", "gpt-3.5-turbo-0301",
     "gpt-3.5-turbo-0613", "gpt-3.5-turbo-1106", "gpt-3.5-turbo-0125", "gpt-3.5-turbo-16k-0613",
     "o1-pro", "o1-pro-2025-03-19", "o3-pro", "o3-pro-2025-06-10", "o3-deep-research",
     "o3-deep-research-2025-06-26", "o4-mini-deep-research", "o4-mini-deep-research-2025-06-26",
     "computer-use-preview", and "computer-use-preview-2025-03-11".
    :vartype model: str or ~openai.models.ModelIdsResponses
    :ivar instructions: A system (or developer) message inserted into the model's context.
    :vartype instructions: str
    :ivar temperature: What sampling temperature to use, between 0 and 2. Higher values like 0.8
     will make the output more random, while lower values like 0.2 will make it more focused and
     deterministic.
     We generally recommend altering this or ``top_p`` but not both.
    :vartype temperature: float
    :ivar top_p: An alternative to sampling with temperature, called nucleus sampling,
     where the model considers the results of the tokens with top_p probability
     mass. So 0.1 means only the tokens comprising the top 10% probability mass
     are considered.

     We generally recommend altering this or ``temperature`` but not both.
    :vartype top_p: float
    :ivar reasoning:
    :vartype reasoning: ~openai.models.Reasoning
    :ivar tools: An array of tools the model may call while generating a response. You
     can specify which tool to use by setting the ``tool_choice`` parameter.
    :vartype tools: list[~openai.models.Tool]
    :ivar text: Configuration options for a text response from the model. Can be plain text or
     structured JSON data.
    :vartype text: ~azureaiagents.models.PromptAgentDefinitionText
    :ivar structured_inputs: Set of structured inputs that can participate in prompt template
     substitution or tool argument bindings.
    :vartype structured_inputs: dict[str, ~azureaiagents.models.StructuredInputDefinition]
    """

    kind: Literal[AgentKind.PROMPT_AGENT] = rest_discriminator(name="kind", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    model: Optional[Union[str, "_openai_models3.ModelIdsResponses"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Model ID used to generate the response, like ``gpt-4o`` or ``o3``. OpenAI
     offers a wide range of models with different capabilities, performance
     characteristics, and price points. Refer to the `model guide </docs/models>`_
     to browse and compare available models. Known values are: \"gpt-4.1\", \"gpt-4.1-mini\",
     \"gpt-4.1-nano\", \"gpt-4.1-2025-04-14\", \"gpt-4.1-mini-2025-04-14\",
     \"gpt-4.1-nano-2025-04-14\", \"o4-mini\", \"o4-mini-2025-04-16\", \"o3\", \"o3-2025-04-16\",
     \"o3-mini\", \"o3-mini-2025-01-31\", \"o1\", \"o1-2024-12-17\", \"o1-preview\",
     \"o1-preview-2024-09-12\", \"o1-mini\", \"o1-mini-2024-09-12\", \"gpt-4o\",
     \"gpt-4o-2024-11-20\", \"gpt-4o-2024-08-06\", \"gpt-4o-2024-05-13\", \"gpt-4o-audio-preview\",
     \"gpt-4o-audio-preview-2024-10-01\", \"gpt-4o-audio-preview-2024-12-17\",
     \"gpt-4o-audio-preview-2025-06-03\", \"gpt-4o-mini-audio-preview\",
     \"gpt-4o-mini-audio-preview-2024-12-17\", \"gpt-4o-search-preview\",
     \"gpt-4o-mini-search-preview\", \"gpt-4o-search-preview-2025-03-11\",
     \"gpt-4o-mini-search-preview-2025-03-11\", \"chatgpt-4o-latest\", \"codex-mini-latest\",
     \"gpt-4o-mini\", \"gpt-4o-mini-2024-07-18\", \"gpt-4-turbo\", \"gpt-4-turbo-2024-04-09\",
     \"gpt-4-0125-preview\", \"gpt-4-turbo-preview\", \"gpt-4-1106-preview\",
     \"gpt-4-vision-preview\", \"gpt-4\", \"gpt-4-0314\", \"gpt-4-0613\", \"gpt-4-32k\",
     \"gpt-4-32k-0314\", \"gpt-4-32k-0613\", \"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\",
     \"gpt-3.5-turbo-0301\", \"gpt-3.5-turbo-0613\", \"gpt-3.5-turbo-1106\", \"gpt-3.5-turbo-0125\",
     \"gpt-3.5-turbo-16k-0613\", \"o1-pro\", \"o1-pro-2025-03-19\", \"o3-pro\",
     \"o3-pro-2025-06-10\", \"o3-deep-research\", \"o3-deep-research-2025-06-26\",
     \"o4-mini-deep-research\", \"o4-mini-deep-research-2025-06-26\", \"computer-use-preview\", and
     \"computer-use-preview-2025-03-11\"."""
    instructions: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A system (or developer) message inserted into the model's context."""
    temperature: Optional[float] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output
     more random, while lower values like 0.2 will make it more focused and deterministic.
     We generally recommend altering this or ``top_p`` but not both."""
    top_p: Optional[float] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An alternative to sampling with temperature, called nucleus sampling,
     where the model considers the results of the tokens with top_p probability
     mass. So 0.1 means only the tokens comprising the top 10% probability mass
     are considered.
     
     We generally recommend altering this or ``temperature`` but not both."""
    reasoning: Optional["_openai_models3.Reasoning"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    tools: Optional[List["_openai_models3.Tool"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """An array of tools the model may call while generating a response. You
     can specify which tool to use by setting the ``tool_choice`` parameter."""
    text: Optional["_models.PromptAgentDefinitionText"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Configuration options for a text response from the model. Can be plain text or structured JSON
     data."""
    structured_inputs: Optional[Dict[str, "_models.StructuredInputDefinition"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Set of structured inputs that can participate in prompt template substitution or tool argument
     bindings."""

    @overload
    def __init__(
        self,
        *,
        model: Optional[Union[str, "_openai_models3.ModelIdsResponses"]] = None,
        instructions: Optional[str] = None,
        temperature: Optional[float] = None,
        top_p: Optional[float] = None,
        reasoning: Optional["_openai_models3.Reasoning"] = None,
        tools: Optional[List["_openai_models3.Tool"]] = None,
        text: Optional["_models.PromptAgentDefinitionText"] = None,
        structured_inputs: Optional[Dict[str, "_models.StructuredInputDefinition"]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, kind=AgentKind.PROMPT_AGENT, **kwargs)


class PromptAgentDefinitionText(_Model):
    """PromptAgentDefinitionText.

    :ivar format:
    :vartype format: ~openai.models.ResponseTextFormatConfiguration
    """

    format: Optional["_openai_models3.ResponseTextFormatConfiguration"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )

    @overload
    def __init__(
        self,
        *,
        format: Optional["_openai_models3.ResponseTextFormatConfiguration"] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class Response(_Model):
    """Response.

    :ivar agent: The agent used for this response. Required.
    :vartype agent: ~azureaiagents.models.AgentId
    :ivar conversation_id: The id of the conversation used for this response.
    :vartype conversation_id: str
    :ivar metadata: Set of 16 key-value pairs that can be attached to an object. This can be
     useful for storing additional information about the object in a structured
     format, and querying for objects via API or the dashboard.

     Keys are strings with a maximum length of 64 characters. Values are strings
     with a maximum length of 512 characters. Required.
    :vartype metadata: dict[str, str]
    :ivar temperature: What sampling temperature to use, between 0 and 2. Higher values like 0.8
     will make the output more random, while lower values like 0.2 will make it more focused and
     deterministic.
     We generally recommend altering this or ``top_p`` but not both. Required.
    :vartype temperature: float
    :ivar top_p: An alternative to sampling with temperature, called nucleus sampling,
     where the model considers the results of the tokens with top_p probability
     mass. So 0.1 means only the tokens comprising the top 10% probability mass
     are considered.

     We generally recommend altering this or ``temperature`` but not both. Required.
    :vartype top_p: float
    :ivar user: A unique identifier representing your end-user, which can help OpenAI to monitor
     and detect abuse. `Learn more </docs/guides/safety-best-practices#end-user-ids>`_. Required.
    :vartype user: str
    :ivar service_tier: Known values are: "auto", "default", "flex", "scale", and "priority".
    :vartype service_tier: str or ~openai.models.ServiceTier
    :ivar top_logprobs: An integer between 0 and 20 specifying the number of most likely tokens to
     return at each token position, each with an associated log probability.
    :vartype top_logprobs: int
    :ivar previous_response_id: The unique ID of the previous response to the model. Use this to
     create multi-turn conversations. Learn more about
     `conversation state </docs/guides/conversation-state>`_.
    :vartype previous_response_id: str
    :ivar model: Model ID used to generate the response, like ``gpt-4o`` or ``o3``. OpenAI
     offers a wide range of models with different capabilities, performance
     characteristics, and price points. Refer to the `model guide </docs/models>`_
     to browse and compare available models. Known values are: "gpt-4.1", "gpt-4.1-mini",
     "gpt-4.1-nano", "gpt-4.1-2025-04-14", "gpt-4.1-mini-2025-04-14", "gpt-4.1-nano-2025-04-14",
     "o4-mini", "o4-mini-2025-04-16", "o3", "o3-2025-04-16", "o3-mini", "o3-mini-2025-01-31", "o1",
     "o1-2024-12-17", "o1-preview", "o1-preview-2024-09-12", "o1-mini", "o1-mini-2024-09-12",
     "gpt-4o", "gpt-4o-2024-11-20", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13",
     "gpt-4o-audio-preview", "gpt-4o-audio-preview-2024-10-01", "gpt-4o-audio-preview-2024-12-17",
     "gpt-4o-audio-preview-2025-06-03", "gpt-4o-mini-audio-preview",
     "gpt-4o-mini-audio-preview-2024-12-17", "gpt-4o-search-preview", "gpt-4o-mini-search-preview",
     "gpt-4o-search-preview-2025-03-11", "gpt-4o-mini-search-preview-2025-03-11",
     "chatgpt-4o-latest", "codex-mini-latest", "gpt-4o-mini", "gpt-4o-mini-2024-07-18",
     "gpt-4-turbo", "gpt-4-turbo-2024-04-09", "gpt-4-0125-preview", "gpt-4-turbo-preview",
     "gpt-4-1106-preview", "gpt-4-vision-preview", "gpt-4", "gpt-4-0314", "gpt-4-0613", "gpt-4-32k",
     "gpt-4-32k-0314", "gpt-4-32k-0613", "gpt-3.5-turbo", "gpt-3.5-turbo-16k", "gpt-3.5-turbo-0301",
     "gpt-3.5-turbo-0613", "gpt-3.5-turbo-1106", "gpt-3.5-turbo-0125", "gpt-3.5-turbo-16k-0613",
     "o1-pro", "o1-pro-2025-03-19", "o3-pro", "o3-pro-2025-06-10", "o3-deep-research",
     "o3-deep-research-2025-06-26", "o4-mini-deep-research", "o4-mini-deep-research-2025-06-26",
     "computer-use-preview", and "computer-use-preview-2025-03-11".
    :vartype model: str or ~openai.models.ModelIdsResponses
    :ivar reasoning:
    :vartype reasoning: ~openai.models.Reasoning
    :ivar background: Whether to run the model response in the background.
     `Learn more </docs/guides/background>`_.
    :vartype background: bool
    :ivar max_output_tokens: An upper bound for the number of tokens that can be generated for a
     response, including visible output tokens and `reasoning tokens </docs/guides/reasoning>`_.
    :vartype max_output_tokens: int
    :ivar max_tool_calls: The maximum number of total calls to built-in tools that can be processed
     in a response. This maximum number applies across all built-in tool calls, not per individual
     tool. Any further attempts to call a tool by the model will be ignored.
    :vartype max_tool_calls: int
    :ivar text: Configuration options for a text response from the model. Can be plain
     text or structured JSON data. Learn more:

     * [Text inputs and outputs](/docs/guides/text)
     * [Structured Outputs](/docs/guides/structured-outputs).
    :vartype text: ~openai.models.CreateResponseText
    :ivar tools: An array of tools the model may call while generating a response. You
     can specify which tool to use by setting the ``tool_choice`` parameter.

     The two categories of tools you can provide the model are:



     * **Built-in tools**: Tools that are provided by OpenAI that extend the
     model's capabilities, like [web search](/docs/guides/tools-web-search)
     or [file search](/docs/guides/tools-file-search). Learn more about
     [built-in tools](/docs/guides/tools).
     * **Function calls (custom tools)**: Functions that are defined by you,
     enabling the model to call your own code. Learn more about
     [function calling](/docs/guides/function-calling).
    :vartype tools: list[~openai.models.Tool]
    :ivar tool_choice: How the model should select which tool (or tools) to use when generating
     a response. See the ``tools`` parameter to see how to specify which tools
     the model can call. Is either a Union[str, "_openai_models2.ToolChoiceOptions"] type or a
     ToolChoiceObject type.
    :vartype tool_choice: str or ~openai.models.ToolChoiceOptions or
     ~openai.models.ToolChoiceObject
    :ivar prompt:
    :vartype prompt: ~openai.models.Prompt
    :ivar truncation: The truncation strategy to use for the model response.

     * `auto`: If the context of this response and previous ones exceeds
     the model's context window size, the model will truncate the
     response to fit the context window by dropping input items in the
     middle of the conversation.
     * `disabled` (default): If a model response will exceed the context window
     size for a model, the request will fail with a 400 error. Is either a Literal["auto"] type or a
     Literal["disabled"] type.
    :vartype truncation: str or str
    :ivar id: Unique identifier for this Response. Required.
    :vartype id: str
    :ivar object: The object type of this resource - always set to ``response``. Required. Default
     value is "response".
    :vartype object: str
    :ivar status: The status of the response generation. One of ``completed``, ``failed``,
     ``in_progress``, ``cancelled``, ``queued``, or ``incomplete``. Is one of the following types:
     Literal["completed"], Literal["failed"], Literal["in_progress"], Literal["cancelled"],
     Literal["queued"], Literal["incomplete"]
    :vartype status: str or str or str or str or str or str
    :ivar created_at: Unix timestamp (in seconds) of when this Response was created. Required.
    :vartype created_at: ~datetime.datetime
    :ivar error: Required.
    :vartype error: ~openai.models.ResponseError
    :ivar incomplete_details: Details about why the response is incomplete. Required.
    :vartype incomplete_details: ~openai.models.ResponseIncompleteDetails1
    :ivar output: An array of content items generated by the model.



     * The length and order of items in the `output` array is dependent
     on the model's response.
     * Rather than accessing the first item in the `output` array and
     assuming it's an `assistant` message with the content generated by
     the model, you might consider using the `output_text` property where
     supported in SDKs. Required.
    :vartype output: list[~openai.models.ItemResource]
    :ivar instructions: A system (or developer) message inserted into the model's context.

     When using along with ``previous_response_id``, the instructions from a previous
     response will not be carried over to the next response. This makes it simple
     to swap out system (or developer) messages in new responses. Required. Is either a str type or
     a [ItemParam] type.
    :vartype instructions: str or list[~openai.models.ItemParam]
    :ivar output_text: SDK-only convenience property that contains the aggregated text output
     from all ``output_text`` items in the ``output`` array, if any are present.
     Supported in the Python and JavaScript SDKs.
    :vartype output_text: str
    :ivar usage:
    :vartype usage: ~openai.models.ResponseUsage
    :ivar parallel_tool_calls: Whether to allow the model to run tool calls in parallel. Required.
    :vartype parallel_tool_calls: bool
    """

    agent: "_models.AgentId" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The agent used for this response. Required."""
    conversation_id: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The id of the conversation used for this response."""
    metadata: Dict[str, str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Set of 16 key-value pairs that can be attached to an object. This can be
     useful for storing additional information about the object in a structured
     format, and querying for objects via API or the dashboard.
     
     Keys are strings with a maximum length of 64 characters. Values are strings
     with a maximum length of 512 characters. Required."""
    temperature: float = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output
     more random, while lower values like 0.2 will make it more focused and deterministic.
     We generally recommend altering this or ``top_p`` but not both. Required."""
    top_p: float = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An alternative to sampling with temperature, called nucleus sampling,
     where the model considers the results of the tokens with top_p probability
     mass. So 0.1 means only the tokens comprising the top 10% probability mass
     are considered.
     
     We generally recommend altering this or ``temperature`` but not both. Required."""
    user: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A unique identifier representing your end-user, which can help OpenAI to monitor and detect
     abuse. `Learn more </docs/guides/safety-best-practices#end-user-ids>`_. Required."""
    service_tier: Optional[Union[str, "_openai_models3.ServiceTier"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Known values are: \"auto\", \"default\", \"flex\", \"scale\", and \"priority\"."""
    top_logprobs: Optional[int] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An integer between 0 and 20 specifying the number of most likely tokens to return at each token
     position, each with an associated log probability."""
    previous_response_id: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique ID of the previous response to the model. Use this to
     create multi-turn conversations. Learn more about
     `conversation state </docs/guides/conversation-state>`_."""
    model: Optional[Union[str, "_openai_models3.ModelIdsResponses"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Model ID used to generate the response, like ``gpt-4o`` or ``o3``. OpenAI
     offers a wide range of models with different capabilities, performance
     characteristics, and price points. Refer to the `model guide </docs/models>`_
     to browse and compare available models. Known values are: \"gpt-4.1\", \"gpt-4.1-mini\",
     \"gpt-4.1-nano\", \"gpt-4.1-2025-04-14\", \"gpt-4.1-mini-2025-04-14\",
     \"gpt-4.1-nano-2025-04-14\", \"o4-mini\", \"o4-mini-2025-04-16\", \"o3\", \"o3-2025-04-16\",
     \"o3-mini\", \"o3-mini-2025-01-31\", \"o1\", \"o1-2024-12-17\", \"o1-preview\",
     \"o1-preview-2024-09-12\", \"o1-mini\", \"o1-mini-2024-09-12\", \"gpt-4o\",
     \"gpt-4o-2024-11-20\", \"gpt-4o-2024-08-06\", \"gpt-4o-2024-05-13\", \"gpt-4o-audio-preview\",
     \"gpt-4o-audio-preview-2024-10-01\", \"gpt-4o-audio-preview-2024-12-17\",
     \"gpt-4o-audio-preview-2025-06-03\", \"gpt-4o-mini-audio-preview\",
     \"gpt-4o-mini-audio-preview-2024-12-17\", \"gpt-4o-search-preview\",
     \"gpt-4o-mini-search-preview\", \"gpt-4o-search-preview-2025-03-11\",
     \"gpt-4o-mini-search-preview-2025-03-11\", \"chatgpt-4o-latest\", \"codex-mini-latest\",
     \"gpt-4o-mini\", \"gpt-4o-mini-2024-07-18\", \"gpt-4-turbo\", \"gpt-4-turbo-2024-04-09\",
     \"gpt-4-0125-preview\", \"gpt-4-turbo-preview\", \"gpt-4-1106-preview\",
     \"gpt-4-vision-preview\", \"gpt-4\", \"gpt-4-0314\", \"gpt-4-0613\", \"gpt-4-32k\",
     \"gpt-4-32k-0314\", \"gpt-4-32k-0613\", \"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\",
     \"gpt-3.5-turbo-0301\", \"gpt-3.5-turbo-0613\", \"gpt-3.5-turbo-1106\", \"gpt-3.5-turbo-0125\",
     \"gpt-3.5-turbo-16k-0613\", \"o1-pro\", \"o1-pro-2025-03-19\", \"o3-pro\",
     \"o3-pro-2025-06-10\", \"o3-deep-research\", \"o3-deep-research-2025-06-26\",
     \"o4-mini-deep-research\", \"o4-mini-deep-research-2025-06-26\", \"computer-use-preview\", and
     \"computer-use-preview-2025-03-11\"."""
    reasoning: Optional["_openai_models3.Reasoning"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    background: Optional[bool] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether to run the model response in the background.
     `Learn more </docs/guides/background>`_."""
    max_output_tokens: Optional[int] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An upper bound for the number of tokens that can be generated for a response, including visible
     output tokens and `reasoning tokens </docs/guides/reasoning>`_."""
    max_tool_calls: Optional[int] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The maximum number of total calls to built-in tools that can be processed in a response. This
     maximum number applies across all built-in tool calls, not per individual tool. Any further
     attempts to call a tool by the model will be ignored."""
    text: Optional["_openai_models3.CreateResponseText"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Configuration options for a text response from the model. Can be plain
     text or structured JSON data. Learn more:
     
     * [Text inputs and outputs](/docs/guides/text)
     * [Structured Outputs](/docs/guides/structured-outputs)."""
    tools: Optional[List["_openai_models3.Tool"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """An array of tools the model may call while generating a response. You
     can specify which tool to use by setting the ``tool_choice`` parameter.
     
     The two categories of tools you can provide the model are:
     
     
     
     * **Built-in tools**: Tools that are provided by OpenAI that extend the
     model's capabilities, like [web search](/docs/guides/tools-web-search)
     or [file search](/docs/guides/tools-file-search). Learn more about
     [built-in tools](/docs/guides/tools).
     * **Function calls (custom tools)**: Functions that are defined by you,
     enabling the model to call your own code. Learn more about
     [function calling](/docs/guides/function-calling)."""
    tool_choice: Optional[Union[str, "_openai_models3.ToolChoiceOptions", "_openai_models3.ToolChoiceObject"]] = (
        rest_field(visibility=["read", "create", "update", "delete", "query"])
    )
    """How the model should select which tool (or tools) to use when generating
     a response. See the ``tools`` parameter to see how to specify which tools
     the model can call. Is either a Union[str, \"_openai_models2.ToolChoiceOptions\"] type or a
     ToolChoiceObject type."""
    prompt: Optional["_openai_models3.Prompt"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    truncation: Optional[Literal["auto", "disabled"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The truncation strategy to use for the model response.
     
     * `auto`: If the context of this response and previous ones exceeds
     the model's context window size, the model will truncate the
     response to fit the context window by dropping input items in the
     middle of the conversation.
     * `disabled` (default): If a model response will exceed the context window
     size for a model, the request will fail with a 400 error. Is either a Literal[\"auto\"] type or
     a Literal[\"disabled\"] type."""
    id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Unique identifier for this Response. Required."""
    object: Literal["response"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The object type of this resource - always set to ``response``. Required. Default value is
     \"response\"."""
    status: Optional[Literal["completed", "failed", "in_progress", "cancelled", "queued", "incomplete"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The status of the response generation. One of ``completed``, ``failed``,
     ``in_progress``, ``cancelled``, ``queued``, or ``incomplete``. Is one of the following types:
     Literal[\"completed\"], Literal[\"failed\"], Literal[\"in_progress\"], Literal[\"cancelled\"],
     Literal[\"queued\"], Literal[\"incomplete\"]"""
    created_at: datetime.datetime = rest_field(
        visibility=["read", "create", "update", "delete", "query"], format="unix-timestamp"
    )
    """Unix timestamp (in seconds) of when this Response was created. Required."""
    error: "_openai_models3.ResponseError" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    incomplete_details: "_openai_models3.ResponseIncompleteDetails1" = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Details about why the response is incomplete. Required."""
    output: List["_openai_models3.ItemResource"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """An array of content items generated by the model.
     
     
     
     * The length and order of items in the `output` array is dependent
     on the model's response.
     * Rather than accessing the first item in the `output` array and
     assuming it's an `assistant` message with the content generated by
     the model, you might consider using the `output_text` property where
     supported in SDKs. Required."""
    instructions: Union[str, List["_openai_models3.ItemParam"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """A system (or developer) message inserted into the model's context.
     
     When using along with ``previous_response_id``, the instructions from a previous
     response will not be carried over to the next response. This makes it simple
     to swap out system (or developer) messages in new responses. Required. Is either a str type or
     a [ItemParam] type."""
    output_text: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """SDK-only convenience property that contains the aggregated text output
     from all ``output_text`` items in the ``output`` array, if any are present.
     Supported in the Python and JavaScript SDKs."""
    usage: Optional["_openai_models3.ResponseUsage"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    parallel_tool_calls: bool = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether to allow the model to run tool calls in parallel. Required."""

    @overload
    def __init__(  # pylint: disable=too-many-locals
        self,
        *,
        agent: "_models.AgentId",
        metadata: Dict[str, str],
        temperature: float,
        top_p: float,
        user: str,
        id: str,  # pylint: disable=redefined-builtin
        created_at: datetime.datetime,
        error: "_openai_models3.ResponseError",
        incomplete_details: "_openai_models3.ResponseIncompleteDetails1",
        output: List["_openai_models3.ItemResource"],
        instructions: Union[str, List["_openai_models3.ItemParam"]],
        parallel_tool_calls: bool,
        conversation_id: Optional[str] = None,
        service_tier: Optional[Union[str, "_openai_models3.ServiceTier"]] = None,
        top_logprobs: Optional[int] = None,
        previous_response_id: Optional[str] = None,
        model: Optional[Union[str, "_openai_models3.ModelIdsResponses"]] = None,
        reasoning: Optional["_openai_models3.Reasoning"] = None,
        background: Optional[bool] = None,
        max_output_tokens: Optional[int] = None,
        max_tool_calls: Optional[int] = None,
        text: Optional["_openai_models3.CreateResponseText"] = None,
        tools: Optional[List["_openai_models3.Tool"]] = None,
        tool_choice: Optional[
            Union[str, "_openai_models3.ToolChoiceOptions", "_openai_models3.ToolChoiceObject"]
        ] = None,
        prompt: Optional["_openai_models3.Prompt"] = None,
        truncation: Optional[Literal["auto", "disabled"]] = None,
        status: Optional[Literal["completed", "failed", "in_progress", "cancelled", "queued", "incomplete"]] = None,
        output_text: Optional[str] = None,
        usage: Optional["_openai_models3.ResponseUsage"] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.object: Literal["response"] = "response"


class ResponseList(_Model):
    """ResponseList.

    :ivar object: The type of object returned, must be ``list``. Required. Default value is "list".
    :vartype object: str
    :ivar data: A list of items used to generate this response. Required.
    :vartype data: list[~openai.models.Response]
    :ivar has_more: Whether there are more items available. Required.
    :vartype has_more: bool
    :ivar first_id: The ID of the first item in the list. Required.
    :vartype first_id: str
    :ivar last_id: The ID of the last item in the list. Required.
    :vartype last_id: str
    """

    object: Literal["list"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The type of object returned, must be ``list``. Required. Default value is \"list\"."""
    data: List["_openai_models3.Response"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A list of items used to generate this response. Required."""
    has_more: bool = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether there are more items available. Required."""
    first_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the first item in the list. Required."""
    last_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the last item in the list. Required."""

    @overload
    def __init__(
        self,
        *,
        data: List["_openai_models3.Response"],
        has_more: bool,
        first_id: str,
        last_id: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.object: Literal["list"] = "list"


class SemanticEventDefinition(_Model):
    """An event that can be raised by the agent based on a semantic condition.

    :ivar condition: A condition that specifies when the event must be raised. Used by the model to
     determine when to raise the event. Required.
    :vartype condition: str
    """

    condition: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A condition that specifies when the event must be raised. Used by the model to determine when
     to raise the event. Required."""

    @overload
    def __init__(
        self,
        *,
        condition: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class SemanticEventsOutputItemResource(ItemResource, discriminator="semantic_event"):
    """SemanticEventsOutputItemResource.

    :ivar id: Required.
    :vartype id: str
    :ivar type: Required. Default value is "semantic_event".
    :vartype type: str
    :ivar name: The name of the semantic event. Required.
    :vartype name: str
    """

    type: Literal["semantic_event"] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required. Default value is \"semantic_event\"."""
    name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the semantic event. Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        name: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, type="semantic_event", **kwargs)


class StructuredInputDefinition(_Model):
    """An structured input that can participate in prompt template substitutions and tool argument
    binding.

    :ivar description: A human-readable description of the input.
    :vartype description: str
    :ivar default_value: The default value for the input if no run-time value is provided.
    :vartype default_value: any
    :ivar tool_argument_bindings: When provided, the input value is binded to the specified tool
     arguments.
    :vartype tool_argument_bindings: list[~azureaiagents.models.ToolArgumentBinding]
    :ivar schema: The JSON schema for the structured input (optional).
    :vartype schema: any
    :ivar required: Whether the input property is required when the agent is invoked.
    :vartype required: bool
    """

    description: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A human-readable description of the input."""
    default_value: Optional[Any] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The default value for the input if no run-time value is provided."""
    tool_argument_bindings: Optional[List["_models.ToolArgumentBinding"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """When provided, the input value is binded to the specified tool arguments."""
    schema: Optional[Any] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The JSON schema for the structured input (optional)."""
    required: Optional[bool] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether the input property is required when the agent is invoked."""

    @overload
    def __init__(
        self,
        *,
        description: Optional[str] = None,
        default_value: Optional[Any] = None,
        tool_argument_bindings: Optional[List["_models.ToolArgumentBinding"]] = None,
        schema: Optional[Any] = None,
        required: Optional[bool] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class StructuredInputsItemParam(ItemParam, discriminator="structured_inputs"):
    """StructuredInputsItemParam.

    :ivar type: Required. Default value is "structured_inputs".
    :vartype type: str
    :ivar inputs: The structured inputs to the response.
    :vartype inputs: dict[str, any]
    """

    type: Literal["structured_inputs"] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required. Default value is \"structured_inputs\"."""
    inputs: Optional[Dict[str, Any]] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The structured inputs to the response."""

    @overload
    def __init__(
        self,
        *,
        inputs: Optional[Dict[str, Any]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, type="structured_inputs", **kwargs)


class StructuredInputsItemResource(ItemResource, discriminator="structured_inputs"):
    """StructuredInputsItemResource.

    :ivar id: Required.
    :vartype id: str
    :ivar type: Required. Default value is "structured_inputs".
    :vartype type: str
    :ivar inputs: The structured inputs provided to the response.
    :vartype inputs: dict[str, any]
    """

    type: Literal["structured_inputs"] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required. Default value is \"structured_inputs\"."""
    inputs: Optional[Dict[str, Any]] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The structured inputs provided to the response."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        inputs: Optional[Dict[str, Any]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, type="structured_inputs", **kwargs)


class StructuredOutputDefinition(_Model):
    """A structeud output that can be produced by the agent.

    :ivar description: A descriptopn of the output to emit. Used by the model to determine when to
     emit the output.
    :vartype description: str
    :ivar schema: The JSON schema for the structured output. Required.
    :vartype schema: dict[str, any]
    """

    description: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A descriptopn of the output to emit. Used by the model to determine when to emit the output."""
    schema: Dict[str, Any] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The JSON schema for the structured output. Required."""

    @overload
    def __init__(
        self,
        *,
        schema: Dict[str, Any],
        description: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class StructuredOutputsItemResource(ItemResource, discriminator="structured_outputs"):
    """StructuredOutputsItemResource.

    :ivar id: Required.
    :vartype id: str
    :ivar type: Required. Default value is "structured_outputs".
    :vartype type: str
    :ivar outputs: The structured outputs captured during the response.
    :vartype outputs: dict[str, any]
    """

    type: Literal["structured_outputs"] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required. Default value is \"structured_outputs\"."""
    outputs: Optional[Dict[str, Any]] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The structured outputs captured during the response."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        outputs: Optional[Dict[str, Any]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, type="structured_outputs", **kwargs)


class ToolArgumentBinding(_Model):
    """ToolArgumentBinding.

    :ivar tool_name: The name of the tool to participate in the argument binding. If not provided,
     then all tools with matching arguments will participate in binding.
    :vartype tool_name: str
    :ivar argument_name: The name of the argument within the tool. Required.
    :vartype argument_name: str
    """

    tool_name: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the tool to participate in the argument binding. If not provided, then all tools
     with matching arguments will participate in binding."""
    argument_name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the argument within the tool. Required."""

    @overload
    def __init__(
        self,
        *,
        argument_name: str,
        tool_name: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class UpsertAgentLabelRequest(_Model):
    """UpsertAgentLabelRequest.

    :ivar associated_version: The version of the agent that this label is associated with. If not
     provided, then the label is not associated with any specific version.
    :vartype associated_version: str
    """

    associated_version: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The version of the agent that this label is associated with. If not provided, then the label is
     not associated with any specific version."""

    @overload
    def __init__(
        self,
        *,
        associated_version: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class WorkflowDefinition(AgentDefinition, discriminator="workflow"):
    """The workflow specification in CPSDL format.

    :ivar kind: Required.
    :vartype kind: str or ~azureaiagents.models.WORKFLOW
    :ivar actions: The workflow actions in CPSDL format. Required.
    :vartype actions: list[any]
    """

    kind: Literal[AgentKind.WORKFLOW] = rest_discriminator(name="kind", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    actions: List[Any] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The workflow actions in CPSDL format. Required."""

    @overload
    def __init__(
        self,
        *,
        actions: List[Any],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, kind=AgentKind.WORKFLOW, **kwargs)

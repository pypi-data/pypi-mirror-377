{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to org:  Plan-B\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from openweights import OpenWeights # type: ignore\n",
    "from dotenv import load_dotenv # type: ignore\n",
    "import random\n",
    "load_dotenv()\n",
    "ow = OpenWeights()\n",
    "\n",
    "import openweights.jobs.vllm\n",
    "\n",
    "from dataclasses import dataclass, asdict\n",
    "import time\n",
    "import json\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "import os\n",
    "\n",
    "@dataclass \n",
    "class RequestResult:\n",
    "    \"\"\"Results for a single request\"\"\"\n",
    "    completion_time: float\n",
    "    total_tokens: int\n",
    "    prompt_tokens: int\n",
    "    completion_tokens: int\n",
    "\n",
    "@dataclass\n",
    "class LoadTestResult:\n",
    "    \"\"\"Class to save all API and client args together with load test results\"\"\"\n",
    "    name: str\n",
    "    model: str\n",
    "    request_timeout: float \n",
    "    per_token_timeout: float\n",
    "    max_num_seqs: int\n",
    "    dataset_size: int\n",
    "    n_gpus: int\n",
    "    total_time: float\n",
    "    total_tokens: int\n",
    "    total_requests: int\n",
    "    throughput_requests: float  # requests per second\n",
    "    throughput_tokens: float    # tokens per second\n",
    "    avg_latency: float         # seconds per request\n",
    "    per_request_results: List[Dict]  # List of RequestResult as dicts\n",
    "    \n",
    "    def to_json(self, filename):\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(asdict(self), f, indent=2)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_json(cls, filename):\n",
    "        with open(filename) as f:\n",
    "            data = json.load(f)\n",
    "        return cls(**data)\n",
    "\n",
    "def plot_results(results):\n",
    "    \"\"\"Create interactive plots of results\"\"\"\n",
    "    # Latency vs Throughput scatter plot\n",
    "    df = pd.DataFrame([asdict(r) for r in results])\n",
    "    fig1 = px.scatter(\n",
    "        df,\n",
    "        x=\"throughput_requests\",\n",
    "        y=\"avg_latency\",\n",
    "        hover_data=[\"name\", \"model\", \"max_num_seqs\", \"n_gpus\"],\n",
    "        title=\"Load Test Results - Latency vs Throughput\"\n",
    "    )\n",
    "    fig1.show()\n",
    "    \n",
    "    # Distribution of completion times\n",
    "    for result in results:\n",
    "        df_requests = pd.DataFrame(result.per_request_results)\n",
    "        fig2 = ff.create_distplot(\n",
    "            [df_requests['completion_time']], \n",
    "            [result.name],\n",
    "            bin_size=0.1\n",
    "        )\n",
    "        fig2.update_layout(\n",
    "            title=f\"Distribution of Completion Times - {result.name}\",\n",
    "            xaxis_title=\"Completion Time (s)\",\n",
    "            yaxis_title=\"Density\"\n",
    "        )\n",
    "        fig2.show()\n",
    "\n",
    "def get_dataset(size):\n",
    "    \"\"\"Generate test dataset\"\"\"\n",
    "    return [\n",
    "        [{\"role\": \"user\", \"content\": \"Please explain in great detail the history of China. Start with a general history, then add chaopter that explain in detail the history of every major city, and then add chapters that explain the history of every major dynasty. Be very detailed and resemble the style of wikipedia.\"}]\n",
    "        for _ in range(size)\n",
    "    ]\n",
    "\n",
    "async def load_test(\n",
    "    name: str,\n",
    "    model = \"unsloth/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "    request_timeout: float = 5,\n",
    "    per_token_timeout: float = 1,\n",
    "    max_num_seqs: int = 100,\n",
    "    dataset_size: int = 1000,\n",
    "    n_gpus: int = 1,\n",
    "    n_tokens=[600]\n",
    "):\n",
    "    \"\"\"Deploy a model with the given vllm/client args and test the performance\"\"\"\n",
    "    deploy_kwargs = dict(\n",
    "        max_num_seqs=max_num_seqs,\n",
    "        requires_vram_gb = n_gpus * 65,\n",
    "    )\n",
    "    dataset = get_dataset(dataset_size)\n",
    "    sem = asyncio.Semaphore(max_num_seqs)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    async with ow.api.deploy(model, **deploy_kwargs):\n",
    "        ow.chat.request_timeout = request_timeout\n",
    "        ow.chat.per_token_timeout = per_token_timeout\n",
    "\n",
    "        async def timed_request(messages):\n",
    "            async with sem:\n",
    "                req_start = time.time()\n",
    "                n_tokens_choice = random.choice(n_tokens)\n",
    "                response = await ow.async_chat.completions.create(model=model, messages=messages, max_tokens=n_tokens_choice)\n",
    "                print(f\"Completion time: {time.time() - req_start:.2f}s\")\n",
    "                return RequestResult(\n",
    "                    completion_time=time.time() - req_start,\n",
    "                    total_tokens=response.usage.total_tokens,\n",
    "                    prompt_tokens=response.usage.prompt_tokens,\n",
    "                    completion_tokens=response.usage.completion_tokens\n",
    "                )\n",
    "\n",
    "        responses = await asyncio.gather(\n",
    "            *[timed_request(messages) for messages in dataset]\n",
    "        )\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    total_tokens = sum(r.total_tokens for r in responses)\n",
    "    total_requests = len(responses)\n",
    "    \n",
    "    result = LoadTestResult(\n",
    "        name=name,\n",
    "        model=model,\n",
    "        request_timeout=request_timeout,\n",
    "        per_token_timeout=per_token_timeout,\n",
    "        max_num_seqs=max_num_seqs,\n",
    "        dataset_size=dataset_size,\n",
    "        n_gpus=n_gpus,\n",
    "        total_time=total_time,\n",
    "        total_tokens=total_tokens,\n",
    "        total_requests=total_requests,\n",
    "        throughput_requests=total_requests/total_time,\n",
    "        throughput_tokens=total_tokens/total_time,\n",
    "        avg_latency=total_time/total_requests,\n",
    "        per_request_results=[asdict(r) for r in responses]\n",
    "    )\n",
    "    \n",
    "    result.to_json(f\"results/{name}.json\")\n",
    "    return result\n",
    "\n",
    "\n",
    "async def eval_max_num_seqs(**_load_test_kwargs):\n",
    "    \"\"\"Evaluate the impact of max_num_seqs on throughput\"\"\"\n",
    "    results = []\n",
    "    for max_num_seqs in [1, 10, 100]:\n",
    "        name = f\"max_num_seqs_{max_num_seqs}\"\n",
    "        results.append(await load_test(name, max_num_seqs=max_num_seqs, **_load_test_kwargs))\n",
    "    plot_results(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OpenWeights' object has no attribute 'deploy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m eval_max_num_seqs(n_tokens\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m600\u001b[39m], request_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 160\u001b[0m, in \u001b[0;36meval_max_num_seqs\u001b[0;34m(**_load_test_kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m max_num_seqs \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m]:\n\u001b[1;32m    159\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_num_seqs_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_num_seqs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 160\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mawait\u001b[39;00m load_test(name, max_num_seqs\u001b[38;5;241m=\u001b[39mmax_num_seqs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_load_test_kwargs))\n\u001b[1;32m    161\u001b[0m plot_results(results)\n",
      "Cell \u001b[0;32mIn[1], line 109\u001b[0m, in \u001b[0;36mload_test\u001b[0;34m(name, model, request_timeout, per_token_timeout, max_num_seqs, dataset_size, n_gpus, n_tokens)\u001b[0m\n\u001b[1;32m    106\u001b[0m sem \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mSemaphore(max_num_seqs)\n\u001b[1;32m    108\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m(model, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdeploy_kwargs):\n\u001b[1;32m    110\u001b[0m     ow\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mrequest_timeout \u001b[38;5;241m=\u001b[39m request_timeout\n\u001b[1;32m    111\u001b[0m     ow\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mper_token_timeout \u001b[38;5;241m=\u001b[39m per_token_timeout\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OpenWeights' object has no attribute 'deploy'"
     ]
    }
   ],
   "source": [
    "await eval_max_num_seqs(n_tokens=[600], request_timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await eval_max_num_seqs(max_tokens=[1000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kva",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

import json,logging,glob

#this script will load all the sample json and generate the load options 
#load options are used in Dataflow (also called KM options) 
#Load options differ by load strategy, Append or Incremental update


import os
from logging import Logger

#funciton that scan all the sample files (*sample.json and return full path)
def scan_sample_files():
    script_dir=os.path.dirname(os.path.realpath(__file__))
    logging.debug(msg="Scanning {script_dir} for sample json files".format_map(locals()))

    files = glob.glob(os.path.join(script_dir,"load_option_samples","*sample.json"))
    logging.debug("Total {file_count} sample json files found ".format(file_count=len(files)))
    return files

def parse_json(sample_file):
    try:
        logging.debug("Parsing file {sample_file}".format_map(locals()))
        sample_json_file = open(sample_file,"r")
        json_doc = json.loads(sample_json_file.read())
        #logging.debug(json_doc)
        #KM Options must have only one entry in the array.
        if (not isinstance(json_doc, list)) or "kmName" not in json_doc[0]:
            raise Exception("Unknown sample JSON, No kmName entry found in the array")
        return True,json_doc
    except Exception as e:
        logging.error("Failed Parsing file {sample_file}".format_map(locals()))
        print(e)
        raise e
    finally:
        sample_json_file.close()

def generate_options2dict_method(class_name):
    braces="{}"
    options_method="""
	def options():
		dict2={class_name}.__dict__
		options={braces}
		for key in dict2:
			if key.startswith('__'):
				pass
			elif callable(getattr({class_name},key)):
				pass
			elif type(dict2[key]) == bool:
				options[key] = "true" if dict2[key] == True else "false"
			else:
				options[key]=dict2[key]
		return options
""".format_map(locals())
    
    return options_method

def generate_options_code(jsondoc):
    options_entry=jsondoc[0]
    strip_list=["kmName","IKM","LKM"," "]
    class_name=options_entry["kmName"]
    for item in strip_list:
        class_name=class_name.replace(item,"")
    
    import_fragment=""
    class_fragment="class {class_name}:\n".format_map(locals())
    
    options = options_entry["kmOptions"]
    member_fragment= "" if len(options)!=0 else "\tpass\n"
    inner_classes =""
    for option in options:
        optionName=option["optionName"]
        optionType=option["optionType"]
        defaultValue=option["defaultValue"]

        value="\"\""
        if optionType=="CHECKBOX":
            value=defaultValue.capitalize()
        elif optionType=="LONG_TEXT":
            value="\"{defaultValue}\"".format(defaultValue=defaultValue)
        elif optionType=="CHOICE":
            choice_enum_comment="#possible values for {optionName}".format_map(locals())
            choice_enum_class_name="{optionName}_ENUM".format_map(locals())
            choice_enum_class="\tclass {choice_enum_class_name}(Enum):\n".format_map(locals())
            enum_fragment=""
            choiceValues=option["choiceValues"]
            for choiceValue in choiceValues:
                choiceValue_name=choiceValue.replace(" ","_")
                choiceValue_name="NONE" if choiceValue_name=="None" else choiceValue_name

                enum_fragment+="\t\t{choiceValue_name}=\"{choiceValue}\"\n".format_map(locals())
            choice_enum_class=choice_enum_class+enum_fragment+"\n"
            inner_classes+=choice_enum_class
            defaultValue_name=option["defaultValue"]
            defaultValue_name="NONE" if defaultValue_name=="None" else defaultValue_name
            
            value="{choice_enum_class_name}.{defaultValue_name}.value".format_map(locals())
        else:
            value="\"UNKOWN\""
        
        member_fragment+="\t{optionName}={value}\n".format_map(locals())

    options_method_fragment=generate_options2dict_method(class_name)
#DONT CHANGE FORMAT of this line, python code indentation 
    final_code="""{import_fragment}
{class_fragment}
{inner_classes}
{member_fragment}
{options_method_fragment}
""".format_map(locals())
    return final_code

def generate_integration_type_code():
    load_strategy_fragment="""
class DataFlowIntegrationType:
    def append():
        return {"integrationType":"CONTROL_APPEND"}
    
    def incremental_update():
        return {"integrationType":"INCREMENTAL_UPDATE"}
"""
    return load_strategy_fragment


logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(levelname)s - %(message)s')
logging.debug("Loading JSON files for geneators")

files=scan_sample_files()
logging.debug("Preparing python script")
global_fragment="""## Copyright - Oracle Data Transforms
##Generated Load options from JSON Metadata
##DO NOT EDIT THIS FILE. CHANGES WILL BE LOST, AS THIS FILE IS GENERATED FROM METADATA.
from enum import Enum
{code_fragment}
{load_strategy_fragment}
"""
code_fragment=""
for file in files:
    result,jsondoc= parse_json(file)
    if result:
        logging.debug("Preparing load options for " + file)
        code_fragment += generate_options_code(jsondoc)
    else:
        logging.error("Skipped {file} from options generation".format_map(locals()))
        code_fragment+="###IGNORED Options Generation for {file}".format_map(locals())

load_strategy_fragment=generate_integration_type_code()

script_file_name=os.path.join(os.path.dirname(os.path.realpath(__file__)),"dataflow_load_options.py")
script_file=open(script_file_name,"w")
script_file.write(global_fragment.format_map(locals()))
script_file.close()

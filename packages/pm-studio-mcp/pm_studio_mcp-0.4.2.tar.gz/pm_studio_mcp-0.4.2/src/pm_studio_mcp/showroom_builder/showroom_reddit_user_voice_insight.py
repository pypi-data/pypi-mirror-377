# -*- coding: utf-8 -*-
"""
Showroom Reddit User Voice Insight Workflow
This module provides workflow for Reddit user voice analysis and insights.
"""


def get_showroom_reddit_user_voice_insight_workflow(product_name: str = None, template_name: str = "basic") -> str:
    """
    Get the Reddit User Voice Insight workflow content.
    
    Args:
        product_name (str, optional): The product name to analyze (e.g., "Perplexity", "ChatGPT", "Gemini")
        template_name (str, optional): Template name for workflows (deprecated, only "basic" is supported)
    """
    # ‚ö†Ô∏è CRITICAL: Always validate product_name parameter first
    if not product_name or product_name.strip() == "":
        return """---
mode: 'agent'
---
# Missing Parameter: Product Name

## Parameter Required
This workflow requires a specific product name to analyze.

**Examples:**
- "Perplexity" ‚Äî AI search product analysis
- "ChatGPT" ‚Äî AI conversation product analysis  
- "Gemini" ‚Äî Google AI product analysis
- "Microsoft Edge" ‚Äî Browser product analysis
- "Claude" ‚Äî Anthropic AI analysis

### How to restart:
```
get_showroom_guide("your_name", "showroom_reddit_user_voice_insight", "PRODUCT_NAME")
```

**Please provide a product name to continue.**
"""
    
    # Validate and clean product name
    cleaned_product_name = product_name.strip()
    if len(cleaned_product_name) < 2:
        return """# Invalid Product Name

The provided product name is too short or invalid. Please provide a meaningful product name (at least 2 characters).

Re-run with a valid product name:
```
get_showroom_guide("your_name", "showroom_reddit_user_voice_insight", "VALID_PRODUCT_NAME")
```
"""
    
    return f"""---
mode: 'agent'
name: 'User Voice Insight Agent'
description: 'Mine user voices from Reddit communities for the target product, discover user needs and scenarios, and generate structured reports for PMs.'
---

# Role
You are a senior product manager specializing in user feedback analysis, including voice-of-customer classification, insight summarization, and report generation.

# Task Confirmation
Before execution, present complete task plan:

"Task Plan - Reddit User Voice Insight for: {cleaned_product_name}

1. Environment setup + isolated workspace creation
2. Reddit data collection using fetch_product_insights
3. Data cleaning and filtering for quality
4. Comprehensive user voice analysis (5+5+5 framework)
5. Generate HTML report using integrated template

Expected outputs: Raw CSV + Cleaned CSV + HTML report

Confirm to proceed? (yes/no)"

Wait for explicit confirmation.

# Workflow

## Step 0: Environment Setup
```
1. Locate project root directory using AI reasoning:
   - Find the directory containing pyproject.toml, .venv, and working_dir
   - Navigate to that directory using run_in_terminal "cd [calculated_path]"
   - This should be the pm-studio-mcp project root directory
2. Verify project root location: run_in_terminal "dir pyproject.toml .venv working_dir"
3. Generate timestamp via AI reasoning (format: YYYYMMDD_HHMMSS)
4. Create isolated workspace using exact mkdir command:
   run_in_terminal "mkdir working_dir\<timestamp>_reddit_voice"
5. Set RUN_DIR = working_dir\<timestamp>_reddit_voice

Virtual environment requirement:
- All Python execution: .venv\Scripts\python.exe
- Never use plain "python" command

Time handling via AI reasoning only:
- Parse time periods to concrete start_date/end_date (YYYY-MM-DD)
- Apply 3-day buffer for recent periods
- NO command line date calculations
```

## Step 1: Reddit Data Collection
```
Use fetch_product_insights tool with parameters:
- Product: {cleaned_product_name}
- Target platforms: ["reddit"]
- Parameters: post_limit=2000, time_filter="last 6 months"
- Filter: high engagement posts (upvotes ‚â•50 or comments ‚â•10)

IMPORTANT: fetch_product_insights saves to working_dir by default.
After data collection:
1. Locate the generated CSV file in working_dir
2. Copy ONLY the raw data file to RUN_DIR using exact copy command:
   run_in_terminal "copy working_dir\[filename].csv working_dir\<timestamp>_reddit_voice\reddit_all_<timestamp>_raw.csv"
3. Verify file exists in RUN_DIR: run_in_terminal "dir working_dir\<timestamp>_reddit_voice\*.csv"

Target filename in RUN_DIR: reddit_all_{{{{YYYYMMDDHHMM}}}}_raw.csv
Default subreddits: r/Google, r/Gemini, r/perplexity_ai, r/Productivity, r/GenAI, r/AIsearch, r/AItools, r/AImode, r/Search, r/AIVideo, r/AIImage
```

## Step 2: Data Cleaning

üö´ **ABSOLUTE PROHIBITION: NO scripts, NO command-line tools, NO external processing whatsoever** üö´

**MANDATORY: Direct AI text analysis approach ONLY**

Input file: RUN_DIR/reddit_all_{{{{YYYYMMDDHHMM}}}}_raw.csv (from Step 1)

‚úÖ **Required AI-only process:**

1. **Read CSV content as text from RUN_DIR:**
   - Use read_file tool: working_dir\<timestamp>_reddit_voice\reddit_all_<timestamp>_raw.csv
   - AI can directly read and understand CSV format

2. **Apply filtering using ONLY AI reasoning:**
   - Analyze each row using AI text comprehension
   - Apply filtering criteria through AI judgment
   - No external tools needed - AI can process CSV text directly

3. **Create cleaned CSV using AI text generation:**
   - Generate new CSV content with same structure as input
   - Output file: RUN_DIR/clean_reddit_all_{{{{YYYYMMDDHHMM}}}}.csv
   - Use create_file tool to save cleaned content

**Keep criteria (must meet at least 2 of the following):**
- Contains specific {cleaned_product_name} usage scenarios or experiences
- Describes concrete problems, benefits, or detailed feedback
- Has meaningful engagement (upvotes ‚â•3 OR comments ‚â•2)
- Includes first-person experience language ("I used", "my experience", "I tried", etc.)
- Content length ‚â•50 characters with substantial information
- Mentions specific features, versions, or use cases

**Exclude criteria (any one triggers exclusion):**
- Memes, jokes, or pure entertainment content
- News reposts without personal commentary
- Promotional/advertising language or spam
- Generic complaints without specific details (e.g., "it sucks", "terrible")
- Off-topic discussions unrelated to {cleaned_product_name}
- Deleted or removed posts with [deleted]/[removed] content

**Output:**
- File: RUN_DIR/clean_reddit_all_{{{{YYYYMMDDHHMM}}}}.csv
- Report: "Data cleaning completed: X posts kept out of Y total posts"

üö´ **FORBIDDEN ACTIONS:**
- Using PowerShell, cmd, or any command-line tools for data processing
- Creating scripts of any kind (.py, .ps1, .bat, etc.)
- Using external CSV processing tools
- Attempting to execute any commands for data processing
- Re-checking environment or file locations (already set in Step 0)

‚úÖ **AI IS FULLY CAPABLE** of reading, analyzing, and filtering CSV text content directly through read_file and create_file tools.

## Step 3: User Voice Analysis

Input file: RUN_DIR/clean_reddit_all_{{{{YYYYMMDDHHMM}}}}.csv (from Step 2)

üéØ **CRITICAL: Perform analysis INTERNALLY - DO NOT display 5+5+5 content in chat**

Analysis Framework: Professional market analyst reviewing discussions about {cleaned_product_name}

‚ö†Ô∏è **OUTPUT STRATEGY:**
- Perform complete 5+5+5 analysis internally using the cleaned CSV file
- Store analysis results in memory for Step 4
- Only report completion status in chat: "Analysis completed: [X] posts analyzed, [5] needs, [5] pains, [5] highlights, [3+] opportunities identified"
- DO NOT display the detailed analysis content (saves massive tokens)
- Save analysis content directly for HTML generation in Step 4

**Mandatory analysis structure (process internally):**

1. User voice overview (200+ words)
   - How users interact with product (when/where/how)
   - Sentiment distribution (positive/negative/neutral)
   - Discussion topics (top 3‚Äì5 recurring categories)
   - Include: total posts analyzed, sentiment percentages, topic frequencies

2. User needs and pains (exactly 5 needs + 5 pains)
   
   2.1 Key user needs (exactly 5 required)
   Each need must include:
   ‚úì Concrete user scenario (‚â•30 words)
   ‚úì Direct user quote from real post (‚â•20 words)
   ‚úì Expected solution description
   ‚úì Reddit URL and engagement metrics (upvotes/comments)
   ‚úì Frequency stats (how many similar posts)
   
   2.2 Key pain points (exactly 5 required)
   Each pain must include:
   ‚úì Detailed pain scenario (‚â•40 words)
   ‚úì Direct quote showing frustration (‚â•25 words)
   ‚úì Emotional context analysis
   ‚úì Suggested solution path
   ‚úì Reddit URL and engagement metrics
   ‚úì Severity (High/Medium based on frequency + engagement)

3. Positive highlights (exactly 5 required)
   Each highlight must include:
   ‚úì Specific praised feature/experience
   ‚úì Direct positive user quote (‚â•20 words)
   ‚úì Scenario where it excels
   ‚úì Reddit URL and engagement metrics
   ‚úì Competitive advantage analysis

4. Product opportunities (at least 3)
   Categories:
   - High impact + low effort (quick wins ‚Äî at least 2)
   - High impact + high effort (strategic investments ‚Äî at least 1)
   
   Each opportunity must include:
   ‚úì Unmet need description
   ‚úì Supporting evidence (quotes + number of posts)
   ‚úì Implementation difficulty
   ‚úì Expected business impact
   ‚úì Source of insight (specific user feedback/need)
   ‚úì Detailed proposed solution (‚â•50 words)
   ‚úì Expected user impact
   ‚úì Priority (P0/P1/P2)
   ‚úì Success metrics to track

Quality requirements:
- No generic phrases (e.g., "Users generally feel")
- Every claim needs concrete quote + URL + numbers
- Complete all 5+5+5 items without exception
- Enforce minimum word counts

## Step 4: Generate HTML Report

üö´ **ABSOLUTE PROHIBITION: NO Python scripts, NO command execution for HTML generation** üö´

**MANDATORY AI-only HTML generation process:**

1. **Read template using read_file tool:**
   - File: "src/pm_studio_mcp/showroom_builder/showroom_reddit_user_voice_insight_template.html"
   - Use read_file tool to get complete template content

2. **Process template using ONLY AI text processing:**
   - Replace [PRODUCT_NAME] with: {cleaned_product_name}
   - Replace [X], [Y] placeholders with analysis content from Step 3 (stored internally)
   - Use the 5+5+5 analysis results performed in Step 3 (no need to re-analyze)
   - Keep ALL CSS classes, HTML structure, JavaScript code intact
   - Use AI reasoning to substitute all placeholders with the internal analysis

3. **Create HTML file using create_file tool:**
   - Output path: RUN_DIR/reddit_{cleaned_product_name}_insight_{{{{YYYYMMDD}}}}.html
   - Content: Complete processed HTML with all 5+5+5 analysis content embedded
   - Use create_file tool with full HTML content

4. **MANDATORY verification:**
   - Read back the created file using read_file tool (first 500 characters only)
   - Verify file size > 8000 characters (substantial content with 5+5+5 analysis)
   - Report actual file size and brief content preview
   - Confirm analysis content is properly embedded (not just placeholders)

**File naming requirements:**
- Raw CSV: RUN_DIR/reddit_all_{{{{YYYYMMDDHHMM}}}}_raw.csv (from Step 1)
- Cleaned CSV: RUN_DIR/clean_reddit_all_{{{{YYYYMMDDHHMM}}}}.csv (from Step 2)
- HTML report: RUN_DIR/reddit_{cleaned_product_name}_insight_{{{{YYYYMMDD}}}}.html

**Template compliance:**
- Use template as-is, no modifications to structure
- Replace only [placeholders] with actual analysis content from Step 3
- Preserve all JavaScript code exactly
- All files saved to RUN_DIR (working_dir\<timestamp>_reddit_voice\)
- No hardcoded absolute paths

**Completion requirement:**
- Report: "HTML report generated successfully: [filename] ([file_size] characters)"
- Show brief content preview (first 200 characters) as proof
- Verify substantial content is embedded from 5+5+5 analysis

üö´ **FORBIDDEN ACTIONS:**
- Creating .py files for HTML generation
- Using run_in_terminal for HTML processing
- Writing any scripts whatsoever
- Using external tools for template processing
- Re-displaying the 5+5+5 analysis content in chat (use internal results directly)

## Completion Protocol
```
Final verification: run_in_terminal "dir RUN_DIR"

Success criteria:
- Raw CSV file
- Cleaned CSV file
- HTML report with analysis
- All files isolated in RUN_DIR

Report completion with file locations.
```

---
Save all files in RUN_DIR directory
"""

    return """# Reddit User Voice Insight Workflow

## Parameters
Please specify the product name to analyze, for example:
- "Perplexity" ‚Äî AI search product
- "ChatGPT" ‚Äî AI conversation product
- "Gemini" ‚Äî Google AI product
- Or any other product you care about

## Workflow features
- 6-step process: data collection ‚Üí cleaning & filtering ‚Üí 5+5+5 structured analysis ‚Üí Apple-style professional report
- Modern design: polished HTML report output
- Structured analysis: user voice overview, needs & pains, product opportunities

---
How to use: please provide a product name to start the analysis.

---
**Usage**: Please provide a product name to start the analysis workflow.
"""

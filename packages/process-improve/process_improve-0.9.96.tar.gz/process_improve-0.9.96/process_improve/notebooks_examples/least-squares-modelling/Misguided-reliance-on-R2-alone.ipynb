{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Why-do-we-build-linear-regression-models?\" data-toc-modified-id=\"Why-do-we-build-linear-regression-models?-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Why do we build linear regression models?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Learning-more-about-the-relationships\" data-toc-modified-id=\"Learning-more-about-the-relationships-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Learning more about the relationships</a></span></li><li><span><a href=\"#Use-the-model-in-the-backwards-direction\" data-toc-modified-id=\"Use-the-model-in-the-backwards-direction-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Use the model in the backwards direction</a></span></li><li><span><a href=\"#Using-the-model's-predictions\" data-toc-modified-id=\"Using-the-model's-predictions-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Using the model's predictions</a></span></li></ul></li><li><span><a href=\"#What-does-$ùëÖ^2$-measure?\" data-toc-modified-id=\"What-does-$ùëÖ^2$-measure?-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>What does $ùëÖ^2$ measure?</a></span><ul class=\"toc-item\"><li><span><a href=\"#One-interpretation-of-$R^2$\" data-toc-modified-id=\"One-interpretation-of-$R^2$-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>One interpretation of $R^2$</a></span></li><li><span><a href=\"#Another-interpretation-of-$R^2$\" data-toc-modified-id=\"Another-interpretation-of-$R^2$-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Another interpretation of $R^2$</a></span></li><li><span><a href=\"#Yet-another-interpretation\" data-toc-modified-id=\"Yet-another-interpretation-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Yet another interpretation</a></span></li><li><span><a href=\"#Summary-so-far\" data-toc-modified-id=\"Summary-so-far-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Summary so far</a></span></li></ul></li><li><span><a href=\"#Why-$R^2$-is-not-sufficient-to-judge-a-model's-regression-performance\" data-toc-modified-id=\"Why-$R^2$-is-not-sufficient-to-judge-a-model's-regression-performance-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Why $R^2$ is not sufficient to judge a model's regression performance</a></span><ul class=\"toc-item\"><li><span><a href=\"#Switching-$x$-and-$y$-around\" data-toc-modified-id=\"Switching-$x$-and-$y$-around-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Switching $x$ and $y$ around</a></span></li><li><span><a href=\"#Able-to-calculate-$R^2$-before-even-fitting-the-model\" data-toc-modified-id=\"Able-to-calculate-$R^2$-before-even-fitting-the-model-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Able to calculate $R^2$ before even fitting the model</a></span></li></ul></li><li><span><a href=\"#OK,-I've-been-convinced.-But-which-metrics-should-be-used-instead?\" data-toc-modified-id=\"OK,-I've-been-convinced.-But-which-metrics-should-be-used-instead?-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>OK, I've been convinced. But which metrics should be used instead?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Learning-more-about-the-relationships\" data-toc-modified-id=\"Learning-more-about-the-relationships-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Learning more about the relationships</a></span></li><li><span><a href=\"#Predictions-from-the-model\" data-toc-modified-id=\"Predictions-from-the-model-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Predictions from the model</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoid $R^2$ to judge regression model performance\n",
    "\n",
    "This note shows why relying on $R^2$ to judge a regression model's performance is misguided and misleading\n",
    "\n",
    "**Summary**\n",
    "\n",
    "* A very high $R^2$ value for a linear regression model is no guarantee that it is \"fit-for-purpose\".\n",
    "* A low $R^2$ value can, in many cases, still be valuable.\n",
    "* The intention of your regression model is the important determinant for choosing an appropriate metric, and a suitable metric is probably not $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we build linear regression models?\n",
    "\n",
    "Historical data is collected and a relationship between the input $x$ and the output $y$ is calculated. This relationship is often a linear regression model, written as $y = b_0 + b_1x$, where the intercept is $b_0$ and the slope is $b_1$.\n",
    "\n",
    "The purpose is most often to use that calculated relationship and based on it, is then to make a prediction of some future output, $\\hat{y}$, given a new input: $\\hat{y} = b_0 + b_1 x_\\text{new}$\n",
    "\n",
    "As said, this is the most comment reason for building that linear regression model. So here are some ways a linear regression model is commonly used: \n",
    "\n",
    "1. to learn more about what this relationship between input and output is\n",
    "2. to later turn the model around, and find the input, in order to get a desired output (i.e. using the model in the backwards direction)\n",
    "3. and by far the most common usage: to get predictions of the output, based on the inputs (i.e. use the model in the forwards direction).\n",
    "\n",
    "Let's look at each of these in turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning more about the relationships\n",
    "\n",
    "The coefficient, $b_1$ of the linear regression $y = b_0 + b_1 x$, shows the average effect on the output, $y$, for a one unit increase in the input $x$. This is called \"learning about our system\".\n",
    "\n",
    "If you built a regression model between $x = $ temperature measured in Celsius of your system (input) and the $y=$ pH (output) you might get a regression model of $$ y=4.5 + 0.12 x$$\n",
    "from which you learn two things:\n",
    "* that every 1 degree increase in temperature, leads, on average, to an increase of pH by 0.12 units\n",
    "* that the expected pH when using a temperature of $x = 0$ degrees Celsius, leads to an output pH of 4.5 units.\n",
    "\n",
    "But consider two cases: what if I told you the $R^2$ of this model was 0.2, or it was 0.94. How does this change your learnings? We will come to this in the next section, where we understand a bit more what $R^2$ is measuring.\n",
    "\n",
    "### Use the model in the backwards direction\n",
    "\n",
    "To continue the above example, at what temperature do we operate the system to reach a pH of $y=5.7$? Provided we keep things constant at the same conditions as when we acquired the historical data to build the model [that is far-reaching requirement], we can turn the model around, and calculate that $$x = \\dfrac{y - 4.5}{0.12}$$\n",
    "\n",
    "Again, consider two cases of a low and high $R^2$: how reliable is this usage of the regression model under those 2 scenarios?\n",
    "\n",
    "### Using the model's predictions \n",
    "\n",
    "This scenario is the one most people are familiar with. Continuing the above, it is asking what the expected (or predicted) pH would be for a given new input value of temperature, $x$. For example, at a new temperature that we have never operated at before of 13¬∞C, we expect an output pH of $4.5 + 0.12 \\times 13 = 6.06$ pH units.\n",
    "\n",
    "And again, what value do we have from a model with an $R^2$ which is around 0.2, or a model with $R^2$ of 0.94?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does $ùëÖ^2$ measure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $R^2$ value has multiple interpretations. Here are two.\n",
    "\n",
    "### One interpretation of $R^2$\n",
    "\n",
    "In its simplest form, it is nothing more than a measure of how strongly two variables are correlated. It is the square root of the correlation coefficient between $x$ and $y$.\n",
    "\n",
    "$$\\sqrt{R^2} = r(x, y) = \\dfrac{\\mathcal{E}\\left\\{ (x - \\overline{x}) (y - \\overline{y})\\right\\}}{\\sqrt{\\mathcal{V}\\left\\{x\\right\\}\\mathcal{V}\\left\\{y\\right\\}}} = \\dfrac{\\text{Cov}\\left\\{x, y\\right\\}}{\\sqrt{\\mathcal{V}\\left\\{x\\right\\}\\mathcal{V}\\left\\{y\\right\\}}}$$\n",
    "\n",
    "where \n",
    "* $\\mathcal{E}$ is the \"expected value of\", \n",
    "* $\\mathcal{V}$ is the \"variance of\", and\n",
    "* $\\text{Cov}\\left\\{x, y\\right\\}$ is the \"covariance of\" operation; and\n",
    "* the lines above $x$ and $y$ means to calculate the average value of those data. In other words, $\\overline{y}$ is the average value of all the training $y$ values.\n",
    "\n",
    "### Another interpretation of $R^2$\n",
    "\n",
    "A further interpretation is that $R^2$ is the ratio of the Regression Sum of Squares (RegSS) to the Total Sum of Squares (TSS). \n",
    "\n",
    "$$R^2 = \\dfrac{\\text{RegSS}}{\\text{TSS}} = \\dfrac{\\sum_i{ \\left(\\hat{y}_i - \\overline{y}\\right)^2}}{\\sum_i{ \\left(y_i - \\overline{y}\\right)^2}}$$\n",
    "\n",
    "showing that a $R^2$ value of 1.0 means the predictions, $\\hat{y}_i$, are identically equally to the original values, $y_i$. Conversely to make $R^2$ have a value of 0.0, the predictions are simply equal to a flat line, $\\overline{y}$, the average value of $y$, no matter what the input value of $x$. This is the worst model you can have: it says the best prediction you can make for $y$ is just to return the average value of the training $y$ values.\n",
    "\n",
    "It is from this equation where the common interpretation of $R^2$ comes from: that it is the percentage variation explained. The denominator is proportional to the total variation, and the numerator is the amount explained, leading to a fraction (percentage) between 0 and 1.\n",
    "\n",
    "You can read more in this book: https://learnche.org/pid/least-squares-modelling/least-squares-model-analysis\n",
    "\n",
    "### Yet another interpretation\n",
    "\n",
    "Related to the prior interpretation, so it isn't really new, is that $$R^2 = 1-\\dfrac{\\text{RSS}}{\\text{TSS}}$$\n",
    "\n",
    "coming from that fact that for a simple regression model we have TSS = RegSS + RSS. The RSS is the Residual Sum of Squares (RSS), or mathematically RSS = $\\sum_i{ \\left(y_i - \\hat{y}_i\\right)^2}$.\n",
    "\n",
    "This also shows nicely that to get an $R^2$ of 1.0 you must have no residuals; or an $R^2$ of 0.0 means that your TSS = RSS, in other words, your residuals are as big as the raw data themselves.\n",
    "\n",
    "### Summary so far\n",
    "\n",
    "It is very fruitful to understand the above formulas and try to interpret them yourself, in plain language. It is not easy at first, but it pays off understanding how you can make each part of the equations bigger and smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why $R^2$ is not sufficient to judge a model's regression performance\n",
    "\n",
    "From the above, here are two very simple reasons why $R^2$ is not the correct metric to judge how well you can predict a new output, $y$, from a new input $x$:\n",
    "\n",
    "1. If you switch the historical data around, and make $y$ the $x$ and let $x$ become $y$, then you get ***exactly the same*** $R^2$ value. That does not make sense. A metric of a model's prediction ability **must** depend on what is the input and the output.\n",
    "\n",
    "2. What if I told you that I can tell you what the $R^2$ value will be, before even calculating the model's slope and intercept? Again, that does not make sense. How can a good metric of prediction performance be calculated before even fitting the prediction model? \n",
    "\n",
    "The above would be the equivalent of calculating the prediction ability of a neural network before even fitting it; or flipping the input and outputs around and getting the same performance metric.\n",
    "\n",
    "How can we make these two very strong statements that show $R^2$ is not useful? Look back at the first formula for $R^2$:\n",
    "$$\\sqrt{R^2} = r(x, y) = \\dfrac{\\mathcal{E}\\left\\{ (x - \\overline{x}) (y - \\overline{y})\\right\\}}{\\sqrt{\\mathcal{V}\\left\\{x\\right\\}\\mathcal{V}\\left\\{y\\right\\}}} $$\n",
    "\n",
    "\n",
    "### Switching $x$ and $y$ around\n",
    "\n",
    "The numerator is symmetrical. If you switch the roles of $x$ and $y$ you get the same numerator value. This also holds for the denominator. Please confirm this for yourself in Python, Excel, R, MATLAB, or whatever tool you use for linear regression. Here is some R code::\n",
    "\n",
    "    x = c(10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5)\n",
    "    y = c( 8, 7,  8, 9,  8, 10, 7, 4, 11, 5, 6)\n",
    "    summary(lm(y ~ x))  # R^2 = 0.657 \n",
    "    summary(lm(x ~ y))  # R^2 = 0.657\n",
    "    \n",
    "\n",
    "### Able to calculate $R^2$ before even fitting the model\n",
    "\n",
    "Again, take a second look at the above formula. Does it depend on:\n",
    "\n",
    "* the model's residuals? ***No***\n",
    "* any of the model's coefficients, such as the slope or intercept? ***No***\n",
    "\n",
    "So it is possible to calculate $R^2$ without even fitting a model. The formula depends only on the raw data. This is not some mathematical trick because things cancel out or simplify in some special way. It is simply a fact of what $R^2$ is designed to measure: the degree of correlation between two sequences, $x$ and $y$.\n",
    "\n",
    "So quite simply, that last sentence indicates when $R^2$ should be calculated, and for when it should actually be used (and by extension for when it should not be used).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OK, I've been convinced. But which metrics should be used¬†instead?\n",
    "\n",
    "Let's look back at the two use cases, and also add a third one:\n",
    "\n",
    "1. learning from the model\n",
    "2. predictions from the model\n",
    "3. comparing various models\n",
    "\n",
    "### Learning more about the relationships\n",
    "\n",
    "If your goal is to interpret the slope or intercept, then use a metric related to that, and not $R^2$. In this case the confidence intervals for these two coefficients are very informative. The confidence interval gives you two numbers, a **range** therefore, within which you can expect with a degree of confidence, that it contains the true value of the parameter. Let's return to our temperature and pH example, and only consider the slope. The story is the same for the intercept.\n",
    "\n",
    "Remember that $y = 4.5 + 0.12x$, meaning that every 1 degree increase in temperature, leads, on average, to an increase of pH by 0.12 units. A 95% confidence interval for the true (but unknown) slope might have been [0.09; 0.15], meaning that we have 95% probability that the range contains the true slope. Note, ***it is not***  the probability that the true slope is within this range; a subtle, but important distinction.\n",
    "\n",
    "**Why use confidence intervals?** The main reason is that the value is in the units that you care about, and not an abstract ratio of two variances, such as $R^2$. Secondly, the wider the range, the poorer the model:\n",
    "\n",
    "* confidence interval for the slope: [0.09; 0.15]\n",
    "* confidence interval for the slope: [0.03; 0.21]; which would you rather have?\n",
    "\n",
    "Yes, there is a direct relationship between the range of the intervals and the value of $R^2$, but this connection is non-linear, and different for different models. \n",
    "\n",
    "EXAMPLE CODE FOR R and Python for the CI\n",
    "\n",
    "\n",
    "### Predictions from the model\n",
    "\n",
    "If you want to judge model prediction's, use the linear model's prediction interval! The prediction interval is like the confidence interval, but it is for a new prediction. In the example, we might have had:\n",
    "* a new temperature measurement, $x=10$ degrees Celsius\n",
    "* leading to a predicted pH of $5.7 \\, \\pm \\, 0.4$,\n",
    "* in other words, the predicted pH lies in a bound from [5.3 to 6.1] with 95% confidence,\n",
    "* since the interval calculation requires you specify your degree of confidence.\n",
    "\n",
    "This is extremely informative; right away we get an range, in the units we care about, namely the units of the output variable, $y$.\n",
    "\n",
    "As before, the higher the value of $R^2$, the smaller the bounds, proving intuitively that a higher $R^2$ is better, but you cannot derive any cut-off limit, ahead of time, of what is \"a good $R^2$\", since it depends on the data measured.\n",
    "\n",
    "EXAMPLE CODE FOR R and Python for the PI\n",
    "\n",
    "It is a hacky way, but you can get a reasonable estimate for the prediction interval from the model's standard error. The standard error is the variance of the output\n",
    "\n",
    "\n",
    "* prediction: use PIs and SE to judge model\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "445.2174072265625px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

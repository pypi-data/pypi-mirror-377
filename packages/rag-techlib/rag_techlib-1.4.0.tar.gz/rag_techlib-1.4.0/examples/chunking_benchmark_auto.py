#!/usr/bin/env python3
"""
Auto-generated Chunking Benchmark Script

This script was automatically generated by the RAGLib documentation updater.
It benchmarks all 8 available chunking techniques.

Generated on: 2025-09-17 22:09:34
"""

import json
import sys
import time
from pathlib import Path

# Add raglib to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from raglib.techniques import (
        ContentAwareChunker, DocumentSpecificChunker, FixedSizeChunker, ParentDocumentChunker, PropositionalChunker, RecursiveChunker, SemanticChunker, SentenceWindowChunker
    )
    from raglib.schemas import Document
    from raglib.registry import TechniqueRegistry
except ImportError as e:
    print(f"Failed to import raglib: {e}")
    sys.exit(1)


def main():
    """Run comprehensive benchmark on all chunking techniques."""
    print("üî¨ Auto-Generated Chunking Benchmark")
    print("=" * 50)
    
    # Get all chunking techniques
    techniques = TechniqueRegistry.find_by_category("chunking")
    print(f"üìä Testing {len(techniques)} chunking techniques")
    
    # Test document
    test_doc = Document(
        id="test_document",
        text="""
# Introduction

This is a test document with various structures. It contains multiple paragraphs,
different section headings, and various text patterns to test chunking strategies.

## Section 1

Here we have some content that spans multiple sentences. The goal is to see
how different chunking techniques handle document structure and boundaries.

### Subsection 1.1

More detailed content with technical information. This section contains
specific details that should ideally stay together for context preservation.

## Section 2

Different content with various formatting. Lists, code blocks, and other
structural elements challenge chunking algorithms differently.

- Item 1: First list item
- Item 2: Second list item  
- Item 3: Third list item

### Code Example

```python
def example_function():
    return "Hello, World!"
```

## Conclusion

This document provides a comprehensive test case for evaluating chunking
strategies across different text structures and patterns.
        """,
        meta={"type": "test", "structure": "hierarchical"}
    )
    
    results = {}
    
    for name, technique_class in techniques.items():
        print(f"\nüîç Testing: {name}")
        
        try:
            # Initialize with default parameters
            technique = technique_class()
            
            start_time = time.time()
            result = technique.apply(test_doc)
            end_time = time.time()
            
            if result.success:
                # Handle different result formats
                if name == "parent_document_chunker":
                    payload = result.payload
                    child_chunks = payload.get("child_chunks", [])
                    parent_chunks = payload.get("parent_chunks", [])
                    
                    results[name] = {
                        "success": True,
                        "child_chunks": len(child_chunks),
                        "parent_chunks": len(parent_chunks),
                        "processing_time": end_time - start_time,
                        "technique_class": technique_class.__name__
                    }
                    
                    print(f"   ‚úÖ {len(child_chunks)} child chunks, {len(parent_chunks)} parent chunks")
                else:
                    chunks = result.payload.get("chunks", [])
                    avg_length = sum(len(c.text) for c in chunks) / len(chunks) if chunks else 0
                    
                    results[name] = {
                        "success": True,
                        "num_chunks": len(chunks),
                        "avg_chunk_length": avg_length,
                        "processing_time": end_time - start_time,
                        "technique_class": technique_class.__name__
                    }
                    
                    print(f"   ‚úÖ {len(chunks)} chunks, avg length: {avg_length:.0f} chars")
            else:
                results[name] = {
                    "success": False,
                    "error": result.error,
                    "processing_time": end_time - start_time
                }
                print(f"   ‚ùå Failed: {result.error}")
                
        except Exception as e:
            results[name] = {
                "success": False,
                "error": str(e),
                "processing_time": 0
            }
            print(f"   üí• Exception: {e}")
    
    # Save results
    output_file = Path(__file__).parent / "chunking_benchmark_results_auto.json"
    with open(output_file, 'w') as f:
        json.dump({
            "timestamp": time.strftime('%Y-%m-%d %H:%M:%S'),
            "total_techniques": len(techniques),
            "results": results
        }, f, indent=2)
    
    print(f"\nüíæ Results saved to: {output_file}")
    
    # Summary
    successful = sum(1 for r in results.values() if r.get("success", False))
    print(f"\nüìä Summary: {successful}/{len(results)} techniques successful")


if __name__ == "__main__":
    main()

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f494d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install numpy scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dae7165",
   "metadata": {},
   "source": [
    "# Load toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7691cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 42\n",
    "X = load_diabetes(as_frame=True).frame\n",
    "discrete_features = [\"sex\"]\n",
    "target_column = \"target\"\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=seed)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6495635",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install synthyverse[arf]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be08df19",
   "metadata": {},
   "source": [
    "# Import and train synthetic data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a716f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthyverse.generators import ARFGenerator\n",
    "\n",
    "generator = ARFGenerator(num_trees=20, random_state=0)\n",
    "generator.fit(X_train, discrete_features=[\"target\"])\n",
    "\n",
    "syn = generator.generate(len(X))\n",
    "syn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d7c783",
   "metadata": {},
   "source": [
    "Each generator also takes parameters related to preprocessing: \n",
    "- how to handle missing values\n",
    "- whether to enforce any constraints\n",
    "- how to handle mixed numerical-discrete features\n",
    "- whether to normalize numerical features through quantile transformation\n",
    "\n",
    "The last two can be especially important for synthetic data generators which rely on continuous numerical input distributions, such as deep generative models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69701d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install synthyverse[ctgan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25c1785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthyverse.generators import CTGANGenerator\n",
    "import numpy as np\n",
    "\n",
    "# add some missing values to the first few columns\n",
    "for i in range(25):\n",
    "    X_train.iloc[i, np.random.randint(0, X_train.shape[1] - 5)] = np.nan\n",
    "\n",
    "generator = CTGANGenerator(\n",
    "    constraints=[\"s1>=s2+s3\"],  # enforce a constraint on the synthetic data\n",
    "    missing_imputation_method=\"random\",  # random imputation of missing values\n",
    "    retain_missingness=True,  # retain missing values in the synthetic data\n",
    "    encode_mixed_numerical_features=True,\n",
    "    quantile_transform_numericals=True,\n",
    "    random_state=0,\n",
    ")\n",
    "generator.fit(X_train, discrete_features=[\"target\"])\n",
    "\n",
    "syn = generator.generate(len(X))\n",
    "syn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc3ffb",
   "metadata": {},
   "source": [
    "# Evaluate synthetic data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1283b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthyverse.evaluation import TabularMetricEvaluator\n",
    "\n",
    "metrics = [\"mle\", \"dcr\", \"similarity\"]\n",
    "metrics = {\n",
    "    \"mle-trts\": {\"train_set\": \"real\"},\n",
    "    \"mle-tstr\": {\"train_set\": \"synthetic\"},\n",
    "    \"dcr\": {\"estimates\": [\"mean\", 0.01, 0.05]},\n",
    "    \"similarity\": {},\n",
    "}\n",
    "evaluator = TabularMetricEvaluator(metrics, discrete_features, target_column, seed)\n",
    "results = evaluator.evaluate(X_train, X_test, syn)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d556b3",
   "metadata": {},
   "source": [
    "# Unified pipeline for synthetic data generation and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322dae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthyverse.benchmark import TabularBenchmark\n",
    "\n",
    "benchmark = TabularBenchmark(\n",
    "    generator_name=\"arf\",\n",
    "    generator_params={},\n",
    "    n_random_splits=1,\n",
    "    n_inits=1,\n",
    "    n_generated_datasets=1,\n",
    "    metrics=[\"mle\", \"similarity\", \"classifier_test\"],\n",
    "    test_size=0.2,\n",
    "    val_size=0.1,\n",
    "    missing_imputation_method=\"drop\",\n",
    "    retain_missingness=False,\n",
    "    encode_mixed_numerical_features=False,\n",
    "    quantile_transform_numericals=False,\n",
    "    constraints=[],\n",
    ")\n",
    "results = benchmark.run(\n",
    "    X, target_column=target_column, discrete_columns=discrete_features\n",
    ")\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

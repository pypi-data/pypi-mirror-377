from tamil_utils import normalize, tokens, remove_stopwords, graphemes

def test_tokens_and_stopwords():
    s = "à®‡à®¤à¯ à®’à®°à¯ à®šà¯‹à®¤à®©à¯ˆ"
    t = tokens(s)
    assert "à®šà¯‹à®¤à®©à¯ˆ" in t
    assert "à®’à®°à¯" in t
    assert remove_stopwords(t) == ["à®šà¯‹à®¤à®©à¯ˆ"]

def test_graphemes_emoji():
    g = graphemes("ğŸ‘©ğŸ½â€ğŸ’»")
    assert isinstance(g, list)
    assert "".join(g) == "ğŸ‘©ğŸ½â€ğŸ’»"

def test_normalize_keeps_meaning():
    s = "à®•à®¾\u200Dn"   # insert ZWJ noise
    assert normalize(s) == "à®•à®¾à®©à¯".replace("à®©à¯","à®©à¯") or isinstance(normalize(s), str)

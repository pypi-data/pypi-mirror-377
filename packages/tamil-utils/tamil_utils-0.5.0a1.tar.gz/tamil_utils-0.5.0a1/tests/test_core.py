from tamil_utils import (
    normalize, tokens, remove_stopwords, graphemes,
    sents, to_arabic_numerals, to_tamil_numerals, stopwords_preset,
    transliterate_iso15919, script_of, token_scripts,
    # v0.2
    ngrams, bigrams, trigrams, word_counts, syllables, sort_tamil
)

# --- existing coverage ---

def test_tokens_and_stopwords():
    s = "роЗродрпБ роТро░рпБ роЪрпЛродройрпИ"
    t = tokens(s)
    assert "роЪрпЛродройрпИ" in t and "роТро░рпБ" in t
    assert remove_stopwords(t, preset="ta") == ["роЪрпЛродройрпИ"]

def test_graphemes_emoji():
    g = graphemes("ЁЯСйЁЯП╜тАНЁЯТ╗")
    assert isinstance(g, list)
    assert "".join(g) == "ЁЯСйЁЯП╜тАНЁЯТ╗"

def test_sents_basic():
    text = "роЗродрпБ роТро░рпБ ро╡ро╛роХрпНроХро┐ропроорпН. роЗродрпБ роЗро░рогрпНроЯро╛роорпН? роЪро░ро┐!"
    out = sents(text)
    assert len(out) == 3
    assert out[0].endswith(".") and out[1].endswith("?") and out[2].endswith("!")

def test_numerals_roundtrip():
    assert to_arabic_numerals("рпзрпирпй") == "123"
    assert to_tamil_numerals("2025") == "рпирпжрпирпл"

def test_preset_exposed():
    sw = stopwords_preset("ta")
    assert "роТро░рпБ" in sw and "роЗродрпБ" in sw

def test_transliterate_basic():
    assert transliterate_iso15919("родрооро┐ро┤рпН")[:4] == "tami"  # loose check
    assert transliterate_iso15919("роЖродро┐") == "─Бdi"        # род softened between vowels

def test_script_detection():
    ts = token_scripts(["родрооро┐ро┤рпН", "hello", "AI", "роХрпЛроЯрпН123"])
    assert ts[0][1] == "Tamil"
    assert ts[1][1] == "Latin"
    # Tamil + digits => Mixed
    assert any(tok == "роХрпЛроЯрпН123" and tag == "Mixed" for tok, tag in ts)

# --- v0.2 coverage ---

def test_ngrams_and_helpers():
    t = tokens("роЕродрпБ роЗродрпБ роЕродрпБ")
    assert t == ["роЕродрпБ", "роЗродрпБ", "роЕродрпБ"]
    bi = bigrams(t)
    tri = trigrams(t)
    assert bi == [("роЕродрпБ","роЗродрпБ"), ("роЗродрпБ","роЕродрпБ")]
    assert tri == [("роЕродрпБ","роЗродрпБ","роЕродрпБ")]
    # generic n=2 matches bigrams
    from_generic = [tuple(x.split()) for x in [" ".join(b) for b in bigrams(t)]]
    assert from_generic == bi

def test_word_counts_unigram_rmstop():
    s = "роЗродрпБ роТро░рпБ роЪрпЛродройрпИ роЗродрпБ роТро░рпБ роЪрпЛродройрпИ"
    freq = dict(word_counts(s, rmstop=True, preset="ta", n=1))
    # 'роЗродрпБ' and 'роТро░рпБ' removed by stopwords; 'роЪрпЛродройрпИ' remains with count 2
    assert freq.get("роЪрпЛродройрпИ") == 2
    assert "роЗродрпБ" not in freq and "роТро░рпБ" not in freq

def test_word_counts_bigrams_top():
    s = "родрооро┐ро┤рпН NLP родрооро┐ро┤рпН рокропройрпНрокро╛роЯрпБ родрооро┐ро┤рпН NLP"
    # tokens ~ ["родрооро┐ро┤рпН","NLP","родрооро┐ро┤рпН","рокропройрпНрокро╛роЯрпБ","родрооро┐ро┤рпН","NLP"]
    pairs = word_counts(s, n=2, top=1)
    assert pairs[0][0] in {"родрооро┐ро┤рпН NLP", "NLP родрооро┐ро┤рпН"}  # depending on spacing-tokenization
    assert pairs[0][1] >= 1

def test_syllables_returns_tamil_graphemes():
    s = "родрооро┐ро┤рпНЁЯЩВ test 123"
    syl = syllables(s)
    # Should include only Tamil grapheme clusters (no Latin/digits/emoji)
    assert all(any("\p{Tamil}" in c for c in [g]) for g in syl) or all(any(ord(ch) >= 2944 and ord(ch) <= 3066 for ch in g) for g in syl)
    assert len(syl) >= 2  # at least a couple of Tamil clusters from "родрооро┐ро┤рпН"

def test_sort_tamil_order():
    words = ["роЗро▓роЩрпНроХрпИ", "роЖродро┐", "роЕроЯро┐"]
    sorted_words = sort_tamil(words)
    # ISO key order: a* < ─Б* < i*  => "роЕроЯро┐", "роЖродро┐", "роЗро▓роЩрпНроХрпИ"
    assert sorted_words == ["роЕроЯро┐", "роЖродро┐", "роЗро▓роЩрпНроХрпИ"]

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earth System Model Monitoring and Analytics with Tellus\n",
    "\n",
    "## User Story: Real-time Climate Model Monitoring and Performance Analytics\n",
    "\n",
    "**Scenario**: Dr. James Thompson leads the model development team at NOAA GFDL. His team runs continuous integration testing of their Earth System Model, monitors performance across different configurations, tracks model improvements over development cycles, and provides real-time analytics for ongoing long-term climate simulations.\n",
    "\n",
    "**Goals**:\n",
    "- Implement real-time monitoring of running climate simulations\n",
    "- Track model performance metrics and computational efficiency\n",
    "- Detect and alert on simulation anomalies and failures\n",
    "- Analyze model behavior and output quality trends over time\n",
    "- Generate automated reports and dashboards for stakeholders\n",
    "\n",
    "**Key Features Demonstrated**:\n",
    "- Real-time simulation monitoring and alerting\n",
    "- Performance analytics and trend analysis\n",
    "- Automated quality assessment and anomaly detection\n",
    "- Comprehensive dashboards and reporting\n",
    "- Integration with CI/CD pipelines for model development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Monitoring Infrastructure Setup\n",
    "\n",
    "Configure Tellus for comprehensive Earth System Model monitoring and analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from tellus.application.container import ServiceContainer\n",
    "from tellus.application.dtos import (\n",
    "    CreateLocationDto, CreateSimulationDto, CreateArchiveDto,\n",
    "    CreateProgressTrackingDto, UpdateProgressDto\n",
    ")\n",
    "from tellus.domain.entities.location import LocationKind\n",
    "from tellus.domain.entities.progress_tracking import OperationType\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize service container for model monitoring\n",
    "container = ServiceContainer()\n",
    "location_service = container.get_location_service()\n",
    "simulation_service = container.get_simulation_service()\n",
    "archive_service = container.get_archive_service()\n",
    "transfer_service = container.get_file_transfer_service()\n",
    "progress_service = container.get_progress_tracking_service()\n",
    "\n",
    "print(\"ðŸ“Š Earth System Model Monitoring System Initialized\")\n",
    "print(f\"Institution: NOAA Geophysical Fluid Dynamics Laboratory (GFDL)\")\n",
    "print(f\"Team Lead: Dr. James Thompson\")\n",
    "print(f\"Mission: ESM Development, Monitoring, and Performance Analytics\")\n",
    "print(f\"Scope: Multi-scale model monitoring from development to production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Monitoring Infrastructure Configuration\n",
    "\n",
    "Set up dedicated monitoring infrastructure for real-time model analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model development and testing infrastructure\n",
    "dev_cluster_dto = CreateLocationDto(\n",
    "    name=\"gfdl-dev-cluster\",\n",
    "    kinds=[LocationKind.COMPUTE, LocationKind.FILESERVER],\n",
    "    protocol=\"ssh\",\n",
    "    host=\"dev-cluster.gfdl.noaa.gov\",\n",
    "    username=\"jthompson\",\n",
    "    path=\"/home/jthompson/model-development\",\n",
    "    description=\"GFDL development cluster for model testing and CI/CD\",\n",
    "    metadata={\n",
    "        \"purpose\": \"model_development_testing\",\n",
    "        \"compute_nodes\": 32,\n",
    "        \"cores_per_node\": 48,\n",
    "        \"total_cores\": 1536,\n",
    "        \"memory_per_node_gb\": 256,\n",
    "        \"storage_capacity_tb\": 50,\n",
    "        \"job_scheduler\": \"slurm\",\n",
    "        \"ci_cd_integration\": True,\n",
    "        \"monitoring_agents\": [\"prometheus\", \"node_exporter\", \"slurm_exporter\"],\n",
    "        \"test_suite_runtime_hours\": 4,\n",
    "        \"supported_models\": [\"AM4\", \"OM4\", \"LM4\", \"CM4\"]\n",
    "    }\n",
    ")\n",
    "dev_result = location_service.create_location(dev_cluster_dto)\n",
    "print(f\"âœ“ Configured development cluster: {dev_result.name}\")\n",
    "\n",
    "# Configure production climate simulation infrastructure\n",
    "prod_hpc_dto = CreateLocationDto(\n",
    "    name=\"gfdl-production-hpc\",\n",
    "    kinds=[LocationKind.COMPUTE],\n",
    "    protocol=\"ssh\",\n",
    "    host=\"gaea.ncrc.gov\",\n",
    "    username=\"james.thompson\",\n",
    "    path=\"/lustre/f2/pdata/gfdl/james.thompson\",\n",
    "    description=\"NCRC Gaea supercomputer for production climate simulations\",\n",
    "    metadata={\n",
    "        \"purpose\": \"production_climate_simulations\",\n",
    "        \"compute_nodes\": 4920,\n",
    "        \"cores_per_node\": 40,\n",
    "        \"total_cores\": 196800,\n",
    "        \"memory_per_node_gb\": 128,\n",
    "        \"peak_performance_pflops\": 3.76,\n",
    "        \"filesystem_type\": \"lustre\",\n",
    "        \"storage_capacity_pb\": 35,\n",
    "        \"job_scheduler\": \"pbs_professional\",\n",
    "        \"monitoring_systems\": [\"xalt\", \"tacc_stats\", \"hpc_toolkit\"],\n",
    "        \"typical_job_walltime_hours\": 48,\n",
    "        \"queue_types\": [\"debug\", \"urgent\", \"batch\", \"windfall\"]\n",
    "    }\n",
    ")\n",
    "prod_result = location_service.create_location(prod_hpc_dto)\n",
    "print(f\"âœ“ Configured production HPC: {prod_result.name}\")\n",
    "\n",
    "# Configure monitoring and analytics infrastructure\n",
    "monitoring_dto = CreateLocationDto(\n",
    "    name=\"gfdl-monitoring-hub\",\n",
    "    kinds=[LocationKind.FILESERVER, LocationKind.COMPUTE],\n",
    "    protocol=\"ssh\",\n",
    "    host=\"monitoring.gfdl.noaa.gov\",\n",
    "    username=\"monitor\",\n",
    "    path=\"/data/monitoring\",\n",
    "    description=\"Dedicated monitoring and analytics infrastructure\",\n",
    "    metadata={\n",
    "        \"purpose\": \"real_time_monitoring_analytics\",\n",
    "        \"monitoring_tools\": [\n",
    "            \"prometheus\", \"grafana\", \"elasticsearch\", \"kibana\",\n",
    "            \"influxdb\", \"telegraf\", \"alertmanager\"\n",
    "        ],\n",
    "        \"analytics_tools\": [\n",
    "            \"jupyter\", \"python\", \"r\", \"matlab\", \"ncl\",\n",
    "            \"cdo\", \"nco\", \"xarray\", \"iris\", \"dask\"\n",
    "        ],\n",
    "        \"data_retention_days\": 365,\n",
    "        \"alert_channels\": [\"email\", \"slack\", \"pagerduty\", \"sms\"],\n",
    "        \"dashboard_users\": 50,\n",
    "        \"api_endpoints\": \"rest_and_graphql\",\n",
    "        \"update_frequency_seconds\": 30,\n",
    "        \"storage_capacity_tb\": 100\n",
    "    }\n",
    ")\n",
    "monitoring_result = location_service.create_location(monitoring_dto)\n",
    "print(f\"âœ“ Configured monitoring hub: {monitoring_result.name}\")\n",
    "\n",
    "# Configure data analytics and visualization cluster\n",
    "analytics_dto = CreateLocationDto(\n",
    "    name=\"gfdl-analytics-cluster\",\n",
    "    kinds=[LocationKind.COMPUTE, LocationKind.FILESERVER],\n",
    "    protocol=\"ssh\",\n",
    "    host=\"analytics.gfdl.noaa.gov\",\n",
    "    username=\"analytics\",\n",
    "    path=\"/shared/analytics\",\n",
    "    description=\"High-performance analytics cluster for model data analysis\",\n",
    "    metadata={\n",
    "        \"purpose\": \"model_data_analytics_visualization\",\n",
    "        \"compute_nodes\": 16,\n",
    "        \"cores_per_node\": 64,\n",
    "        \"total_cores\": 1024,\n",
    "        \"memory_per_node_gb\": 512,\n",
    "        \"gpu_nodes\": 4,\n",
    "        \"gpu_per_node\": 4,\n",
    "        \"total_gpus\": 16,\n",
    "        \"gpu_memory_gb\": 32,\n",
    "        \"storage_capacity_tb\": 200,\n",
    "        \"specialized_software\": [\n",
    "            \"tensorflow\", \"pytorch\", \"rapids\", \"dask-cuda\",\n",
    "            \"paraview\", \"visit\", \"matplotlib\", \"plotly\"\n",
    "        ],\n",
    "        \"ml_frameworks\": [\"scikit_learn\", \"xgboost\", \"keras\"],\n",
    "        \"notebook_servers\": \"jupyterhub_with_gpu_support\"\n",
    "    }\n",
    ")\n",
    "analytics_result = location_service.create_location(analytics_dto)\n",
    "print(f\"âœ“ Configured analytics cluster: {analytics_result.name}\")\n",
    "\n",
    "# Configure long-term storage for monitoring data\n",
    "archive_dto = CreateLocationDto(\n",
    "    name=\"gfdl-monitoring-archive\",\n",
    "    kinds=[LocationKind.TAPE, LocationKind.FILESERVER],\n",
    "    protocol=\"hsi\",\n",
    "    host=\"hpss.gfdl.noaa.gov\",\n",
    "    path=\"/archive/gfdl/monitoring\",\n",
    "    description=\"Long-term archive for monitoring data and historical analytics\",\n",
    "    metadata={\n",
    "        \"purpose\": \"monitoring_data_preservation\",\n",
    "        \"storage_type\": \"hierarchical_storage\",\n",
    "        \"capacity_tb\": 1000,\n",
    "        \"retention_policy\": \"10_years\",\n",
    "        \"data_categories\": [\n",
    "            \"performance_metrics\", \"simulation_logs\", \"quality_reports\",\n",
    "            \"trend_analysis\", \"benchmark_results\", \"configuration_history\"\n",
    "        ],\n",
    "        \"retrieval_sla_hours\": 2,\n",
    "        \"compression_enabled\": True,\n",
    "        \"backup_copies\": 2\n",
    "    }\n",
    ")\n",
    "archive_result = location_service.create_location(archive_dto)\n",
    "print(f\"âœ“ Configured monitoring archive: {archive_result.name}\")\n",
    "\n",
    "print(\"\\nðŸ—ï¸  Model Monitoring Infrastructure Overview:\")\n",
    "print(\"  ðŸ”¬ Development â†’ Testing â†’ Production â†’ Analytics â†’ Archive\")\n",
    "print(f\"  ðŸ’» Total Compute: {1536 + 196800 + 1024} cores across 3 systems\")\n",
    "print(f\"  ðŸ“Š Monitoring Coverage: Real-time metrics, alerts, and analytics\")\n",
    "print(f\"  ðŸŽ¯ Integration: CI/CD, HPC schedulers, and visualization tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Development and Testing Simulations\n",
    "\n",
    "Create a suite of development and testing simulations for continuous monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GFDL model development test suite\n",
    "test_configurations = {\n",
    "    \"unit_tests\": {\n",
    "        \"description\": \"Individual component unit tests\",\n",
    "        \"duration_hours\": 0.5,\n",
    "        \"frequency\": \"every_commit\",\n",
    "        \"components\": [\"AM4\", \"OM4\", \"LM4\", \"sea_ice\"],\n",
    "        \"priority\": \"critical\"\n",
    "    },\n",
    "    \"integration_tests\": {\n",
    "        \"description\": \"Multi-component integration testing\",\n",
    "        \"duration_hours\": 2,\n",
    "        \"frequency\": \"daily\",\n",
    "        \"components\": [\"coupled_am4_om4\", \"am4_lm4\", \"full_cm4\"],\n",
    "        \"priority\": \"high\"\n",
    "    },\n",
    "    \"regression_tests\": {\n",
    "        \"description\": \"Regression testing against benchmarks\",\n",
    "        \"duration_hours\": 6,\n",
    "        \"frequency\": \"weekly\",\n",
    "        \"benchmarks\": [\"aquaplanet\", \"held_suarez\", \"idealized_hurricane\"],\n",
    "        \"priority\": \"medium\"\n",
    "    },\n",
    "    \"performance_tests\": {\n",
    "        \"description\": \"Performance and scaling benchmarks\",\n",
    "        \"duration_hours\": 4,\n",
    "        \"frequency\": \"weekly\",\n",
    "        \"metrics\": [\"throughput\", \"scaling\", \"memory_usage\", \"io_performance\"],\n",
    "        \"priority\": \"medium\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create development test simulations\n",
    "test_simulations = []\n",
    "print(\"ðŸ§ª Creating Model Development Test Suite\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "for test_type, config in test_configurations.items():\n",
    "    for i in range(3):  # Create 3 instances of each test type\n",
    "        sim_id = f\"gfdl-{test_type}-{i+1:02d}\"\n",
    "        \n",
    "        sim_dto = CreateSimulationDto(\n",
    "            simulation_id=sim_id,\n",
    "            model_id=\"GFDL-ESM4\",\n",
    "            attrs={\n",
    "                # Test configuration\n",
    "                \"test_type\": test_type,\n",
    "                \"test_description\": config[\"description\"],\n",
    "                \"test_duration_hours\": config[\"duration_hours\"],\n",
    "                \"test_frequency\": config[\"frequency\"],\n",
    "                \"test_priority\": config[\"priority\"],\n",
    "                \n",
    "                # Model configuration\n",
    "                \"model_components\": config.get(\"components\", [\"full_model\"]),\n",
    "                \"resolution\": \"C96\" if \"performance\" in test_type else \"C48\",\n",
    "                \"time_step_seconds\": 1800,\n",
    "                \"simulation_length\": \"5_days\" if test_type == \"unit_tests\" else \"30_days\",\n",
    "                \n",
    "                # Monitoring configuration\n",
    "                \"monitoring_enabled\": True,\n",
    "                \"real_time_metrics\": True,\n",
    "                \"alert_on_failure\": True,\n",
    "                \"performance_tracking\": True,\n",
    "                \"quality_checks\": True,\n",
    "                \n",
    "                # CI/CD integration\n",
    "                \"ci_cd_enabled\": True,\n",
    "                \"git_branch\": \"develop\" if test_type == \"unit_tests\" else \"main\",\n",
    "                \"automated_deployment\": True,\n",
    "                \"test_automation\": True,\n",
    "                \n",
    "                # Expected outcomes\n",
    "                \"expected_completion_rate\": 0.95,\n",
    "                \"performance_baseline_sypd\": 8.5 if \"performance\" in test_type else None,\n",
    "                \"quality_thresholds\": {\n",
    "                    \"energy_conservation_error\": 1e-6,\n",
    "                    \"mass_conservation_error\": 1e-8,\n",
    "                    \"temperature_drift_k_per_century\": 0.1\n",
    "                },\n",
    "                \n",
    "                # Metadata\n",
    "                \"contact\": \"james.thompson@noaa.gov\",\n",
    "                \"institution\": \"GFDL\",\n",
    "                \"project\": \"esm_development_testing\",\n",
    "                \"created_date\": \"2024-06-15\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        sim_result = simulation_service.create_simulation(sim_dto)\n",
    "        test_simulations.append(sim_result)\n",
    "        \n",
    "        # Only print details for first instance of each test type\n",
    "        if i == 0:\n",
    "            print(f\"\\nðŸ”¬ {test_type.upper().replace('_', ' ')}\")\n",
    "            print(f\"   Description: {config['description']}\")\n",
    "            print(f\"   Duration: {config['duration_hours']} hours\")\n",
    "            print(f\"   Frequency: {config['frequency']}\")\n",
    "            print(f\"   Priority: {config['priority']}\")\n",
    "            print(f\"   Components: {', '.join(config.get('components', ['full_model'])[:2])}\")\n",
    "            if len(config.get('components', [])) > 2:\n",
    "                print(f\"                {', '.join(config['components'][2:])}\")\n",
    "            print(f\"   Simulation ID: {sim_result.simulation_id}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Test Suite Summary:\")\n",
    "print(f\"  Total test simulations: {len(test_simulations)}\")\n",
    "print(f\"  Test categories: {len(test_configurations)}\")\n",
    "print(f\"  Instances per category: 3\")\n",
    "print(f\"  Total test duration: {sum(config['duration_hours'] for config in test_configurations.values())*3:.1f} hours\")\n",
    "print(f\"  Automated CI/CD: 100%\")\n",
    "print(f\"  Real-time monitoring: 100%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Real-Time Monitoring and Metrics Collection\n",
    "\n",
    "Implement comprehensive real-time monitoring system for Earth System Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define comprehensive monitoring metrics\n",
    "def create_monitoring_metrics_system():\n",
    "    \"\"\"Create comprehensive monitoring metrics for Earth System Models.\"\"\"\n",
    "    \n",
    "    monitoring_metrics = {\n",
    "        \"computational_performance\": {\n",
    "            \"category\": \"Performance\",\n",
    "            \"update_frequency_seconds\": 30,\n",
    "            \"metrics\": {\n",
    "                \"simulation_years_per_day\": {\n",
    "                    \"description\": \"Model throughput (SYPD)\",\n",
    "                    \"unit\": \"years/day\",\n",
    "                    \"target_range\": [6.0, 12.0],\n",
    "                    \"alert_threshold_low\": 4.0,\n",
    "                    \"data_source\": \"job_scheduler_logs\"\n",
    "                },\n",
    "                \"cpu_efficiency_percent\": {\n",
    "                    \"description\": \"CPU utilization efficiency\",\n",
    "                    \"unit\": \"percent\",\n",
    "                    \"target_range\": [85.0, 95.0],\n",
    "                    \"alert_threshold_low\": 70.0,\n",
    "                    \"data_source\": \"system_monitoring\"\n",
    "                },\n",
    "                \"memory_usage_gb\": {\n",
    "                    \"description\": \"Peak memory consumption\",\n",
    "                    \"unit\": \"GB\",\n",
    "                    \"target_range\": [50.0, 120.0],\n",
    "                    \"alert_threshold_high\": 150.0,\n",
    "                    \"data_source\": \"system_monitoring\"\n",
    "                },\n",
    "                \"io_throughput_gb_per_sec\": {\n",
    "                    \"description\": \"I/O throughput rate\",\n",
    "                    \"unit\": \"GB/s\",\n",
    "                    \"target_range\": [2.0, 8.0],\n",
    "                    \"alert_threshold_low\": 1.0,\n",
    "                    \"data_source\": \"filesystem_monitoring\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"model_physics_quality\": {\n",
    "            \"category\": \"Scientific Quality\",\n",
    "            \"update_frequency_seconds\": 300,\n",
    "            \"metrics\": {\n",
    "                \"global_mean_temperature_k\": {\n",
    "                    \"description\": \"Global mean surface temperature\",\n",
    "                    \"unit\": \"Kelvin\",\n",
    "                    \"target_range\": [287.0, 289.0],\n",
    "                    \"alert_threshold_low\": 285.0,\n",
    "                    \"alert_threshold_high\": 291.0,\n",
    "                    \"data_source\": \"model_diagnostics\"\n",
    "                },\n",
    "                \"energy_imbalance_w_per_m2\": {\n",
    "                    \"description\": \"Top-of-atmosphere energy imbalance\",\n",
    "                    \"unit\": \"W/mÂ²\",\n",
    "                    \"target_range\": [-2.0, 2.0],\n",
    "                    \"alert_threshold_high\": 5.0,\n",
    "                    \"data_source\": \"radiation_diagnostics\"\n",
    "                },\n",
    "                \"global_precipitation_mm_per_day\": {\n",
    "                    \"description\": \"Global mean precipitation rate\",\n",
    "                    \"unit\": \"mm/day\",\n",
    "                    \"target_range\": [2.5, 3.5],\n",
    "                    \"alert_threshold_low\": 2.0,\n",
    "                    \"alert_threshold_high\": 4.0,\n",
    "                    \"data_source\": \"hydrological_diagnostics\"\n",
    "                },\n",
    "                \"sea_ice_extent_million_km2\": {\n",
    "                    \"description\": \"Arctic sea ice extent\",\n",
    "                    \"unit\": \"10^6 kmÂ²\",\n",
    "                    \"target_range\": [12.0, 16.0],\n",
    "                    \"seasonal_variation\": True,\n",
    "                    \"data_source\": \"sea_ice_diagnostics\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"system_health\": {\n",
    "            \"category\": \"System Health\",\n",
    "            \"update_frequency_seconds\": 60,\n",
    "            \"metrics\": {\n",
    "                \"job_queue_depth\": {\n",
    "                    \"description\": \"Number of queued jobs\",\n",
    "                    \"unit\": \"count\",\n",
    "                    \"target_range\": [0, 10],\n",
    "                    \"alert_threshold_high\": 25,\n",
    "                    \"data_source\": \"job_scheduler\"\n",
    "                },\n",
    "                \"failed_jobs_24h\": {\n",
    "                    \"description\": \"Failed jobs in last 24 hours\",\n",
    "                    \"unit\": \"count\",\n",
    "                    \"target_range\": [0, 2],\n",
    "                    \"alert_threshold_high\": 5,\n",
    "                    \"data_source\": \"job_scheduler\"\n",
    "                },\n",
    "                \"storage_usage_percent\": {\n",
    "                    \"description\": \"Scratch storage utilization\",\n",
    "                    \"unit\": \"percent\",\n",
    "                    \"target_range\": [20.0, 80.0],\n",
    "                    \"alert_threshold_high\": 90.0,\n",
    "                    \"data_source\": \"filesystem_monitoring\"\n",
    "                },\n",
    "                \"network_latency_ms\": {\n",
    "                    \"description\": \"Inter-node network latency\",\n",
    "                    \"unit\": \"milliseconds\",\n",
    "                    \"target_range\": [1.0, 5.0],\n",
    "                    \"alert_threshold_high\": 10.0,\n",
    "                    \"data_source\": \"network_monitoring\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"data_quality\": {\n",
    "            \"category\": \"Data Quality\",\n",
    "            \"update_frequency_seconds\": 600,\n",
    "            \"metrics\": {\n",
    "                \"missing_data_percent\": {\n",
    "                    \"description\": \"Percentage of missing data values\",\n",
    "                    \"unit\": \"percent\",\n",
    "                    \"target_range\": [0.0, 1.0],\n",
    "                    \"alert_threshold_high\": 5.0,\n",
    "                    \"data_source\": \"data_validation\"\n",
    "                },\n",
    "                \"out_of_bounds_values_count\": {\n",
    "                    \"description\": \"Variables exceeding physical bounds\",\n",
    "                    \"unit\": \"count\",\n",
    "                    \"target_range\": [0, 100],\n",
    "                    \"alert_threshold_high\": 1000,\n",
    "                    \"data_source\": \"data_validation\"\n",
    "                },\n",
    "                \"file_integrity_checks_passed\": {\n",
    "                    \"description\": \"Files passing integrity checks\",\n",
    "                    \"unit\": \"percent\",\n",
    "                    \"target_range\": [99.5, 100.0],\n",
    "                    \"alert_threshold_low\": 95.0,\n",
    "                    \"data_source\": \"file_validation\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return monitoring_metrics\n",
    "\n",
    "# Create monitoring system\n",
    "monitoring_system = create_monitoring_metrics_system()\n",
    "print(\"ðŸ“Š Real-Time Model Monitoring System\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "total_metrics = 0\n",
    "for category_id, category_info in monitoring_system.items():\n",
    "    category_name = category_info['category']\n",
    "    update_freq = category_info['update_frequency_seconds']\n",
    "    metrics_count = len(category_info['metrics'])\n",
    "    total_metrics += metrics_count\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ {category_name.upper()}\")\n",
    "    print(f\"   Update Frequency: {update_freq} seconds\")\n",
    "    print(f\"   Metrics Count: {metrics_count}\")\n",
    "    \n",
    "    # Show first 2 metrics\n",
    "    for i, (metric_id, metric_info) in enumerate(list(category_info['metrics'].items())[:2]):\n",
    "        print(f\"   {i+1}. {metric_info['description']}\")\n",
    "        print(f\"      Unit: {metric_info['unit']}\")\n",
    "        print(f\"      Target: {metric_info['target_range'][0]}-{metric_info['target_range'][1]} {metric_info['unit']}\")\n",
    "        if 'alert_threshold_low' in metric_info:\n",
    "            print(f\"      Alert: < {metric_info['alert_threshold_low']} {metric_info['unit']}\")\n",
    "        if 'alert_threshold_high' in metric_info:\n",
    "            print(f\"      Alert: > {metric_info['alert_threshold_high']} {metric_info['unit']}\")\n",
    "    \n",
    "    if metrics_count > 2:\n",
    "        print(f\"   ... and {metrics_count - 2} more metrics\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ Monitoring System Summary:\")\n",
    "print(f\"  Total metrics categories: {len(monitoring_system)}\")\n",
    "print(f\"  Total metrics tracked: {total_metrics}\")\n",
    "print(f\"  Fastest update frequency: 30 seconds\")\n",
    "print(f\"  Data sources: Job schedulers, system monitoring, model diagnostics\")\n",
    "print(f\"  Alert systems: Threshold-based with custom ranges per metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate real-time monitoring data collection\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def generate_monitoring_data(simulation_id, metrics_system):\n",
    "    \"\"\"Generate realistic monitoring data for a simulation.\"\"\"\n",
    "    \n",
    "    current_time = datetime.now()\n",
    "    monitoring_data = {\n",
    "        \"simulation_id\": simulation_id,\n",
    "        \"timestamp\": current_time.isoformat(),\n",
    "        \"monitoring_status\": \"active\",\n",
    "        \"data_points\": {}\n",
    "    }\n",
    "    \n",
    "    for category_id, category_info in metrics_system.items():\n",
    "        monitoring_data[\"data_points\"][category_id] = {}\n",
    "        \n",
    "        for metric_id, metric_info in category_info['metrics'].items():\n",
    "            target_range = metric_info['target_range']\n",
    "            target_mid = (target_range[0] + target_range[1]) / 2\n",
    "            target_range_width = target_range[1] - target_range[0]\n",
    "            \n",
    "            # Generate realistic values with some variation\n",
    "            # Most values should be in target range, some outliers\n",
    "            if random.random() < 0.9:  # 90% in target range\n",
    "                value = np.random.normal(target_mid, target_range_width * 0.2)\n",
    "                value = max(target_range[0], min(target_range[1], value))\n",
    "                status = \"normal\"\n",
    "            else:  # 10% outside target range\n",
    "                if random.random() < 0.5:\n",
    "                    value = target_range[0] - abs(np.random.normal(0, target_range_width * 0.3))\n",
    "                else:\n",
    "                    value = target_range[1] + abs(np.random.normal(0, target_range_width * 0.3))\n",
    "                status = \"warning\" if metric_id != \"energy_imbalance_w_per_m2\" else \"alert\"\n",
    "            \n",
    "            # Special handling for specific metrics\n",
    "            if \"percent\" in metric_info['unit']:\n",
    "                value = max(0, min(100, value))\n",
    "            elif \"count\" in metric_info['unit']:\n",
    "                value = max(0, int(value))\n",
    "            \n",
    "            monitoring_data[\"data_points\"][category_id][metric_id] = {\n",
    "                \"value\": round(value, 2),\n",
    "                \"unit\": metric_info['unit'],\n",
    "                \"status\": status,\n",
    "                \"target_range\": target_range,\n",
    "                \"timestamp\": current_time.isoformat()\n",
    "            }\n",
    "    \n",
    "    return monitoring_data\n",
    "\n",
    "# Generate monitoring data for a sample simulation\n",
    "sample_sim = test_simulations[0]  # Use first test simulation\n",
    "monitoring_data = generate_monitoring_data(sample_sim.simulation_id, monitoring_system)\n",
    "\n",
    "print(f\"ðŸ“Š Real-Time Monitoring Data for {monitoring_data['simulation_id']}\")\n",
    "print(f\"Timestamp: {monitoring_data['timestamp']}\")\n",
    "print(f\"Status: {monitoring_data['monitoring_status']}\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "for category_id, category_data in monitoring_data['data_points'].items():\n",
    "    category_name = monitoring_system[category_id]['category']\n",
    "    print(f\"\\nðŸ“ˆ {category_name.upper()}:\")\n",
    "    \n",
    "    for metric_id, metric_data in list(category_data.items())[:2]:  # Show first 2 metrics per category\n",
    "        value = metric_data['value']\n",
    "        unit = metric_data['unit']\n",
    "        status = metric_data['status']\n",
    "        target_range = metric_data['target_range']\n",
    "        \n",
    "        status_icon = {\n",
    "            \"normal\": \"âœ…\",\n",
    "            \"warning\": \"âš ï¸\",\n",
    "            \"alert\": \"ðŸš¨\"\n",
    "        }.get(status, \"â“\")\n",
    "        \n",
    "        metric_name = monitoring_system[category_id]['metrics'][metric_id]['description']\n",
    "        print(f\"  {status_icon} {metric_name}: {value} {unit}\")\n",
    "        print(f\"     Target: {target_range[0]}-{target_range[1]} {unit} | Status: {status.upper()}\")\n",
    "    \n",
    "    if len(category_data) > 2:\n",
    "        remaining = len(category_data) - 2\n",
    "        print(f\"  ... and {remaining} more metrics\")\n",
    "\n",
    "# Count status distribution\n",
    "status_counts = {\"normal\": 0, \"warning\": 0, \"alert\": 0}\n",
    "for category_data in monitoring_data['data_points'].values():\n",
    "    for metric_data in category_data.values():\n",
    "        status_counts[metric_data['status']] += 1\n",
    "\n",
    "print(f\"\\nðŸ“‹ Overall System Health:\")\n",
    "print(f\"  âœ… Normal: {status_counts['normal']} metrics\")\n",
    "print(f\"  âš ï¸  Warning: {status_counts['warning']} metrics\")\n",
    "print(f\"  ðŸš¨ Alert: {status_counts['alert']} metrics\")\n",
    "health_score = (status_counts['normal'] / sum(status_counts.values())) * 100\n",
    "print(f\"  ðŸŽ¯ Health Score: {health_score:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Automated Anomaly Detection and Alerting\n",
    "\n",
    "Implement intelligent anomaly detection and alert management system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create anomaly detection and alerting system\n",
    "def create_anomaly_detection_system():\n",
    "    \"\"\"Create comprehensive anomaly detection and alerting system.\"\"\"\n",
    "    \n",
    "    anomaly_detection = {\n",
    "        \"detection_methods\": {\n",
    "            \"threshold_based\": {\n",
    "                \"description\": \"Static threshold alerts for critical metrics\",\n",
    "                \"algorithms\": [\"min_max_bounds\", \"percentile_bounds\"],\n",
    "                \"response_time_seconds\": 30,\n",
    "                \"accuracy_percent\": 95,\n",
    "                \"false_positive_rate\": 0.02,\n",
    "                \"applicable_metrics\": [\n",
    "                    \"cpu_efficiency_percent\", \"memory_usage_gb\",\n",
    "                    \"storage_usage_percent\", \"job_queue_depth\"\n",
    "                ]\n",
    "            },\n",
    "            \"statistical_anomaly\": {\n",
    "                \"description\": \"Statistical methods for time series anomalies\",\n",
    "                \"algorithms\": [\"z_score\", \"isolation_forest\", \"local_outlier_factor\"],\n",
    "                \"lookback_window_hours\": 24,\n",
    "                \"sensitivity_level\": \"medium\",\n",
    "                \"response_time_seconds\": 300,\n",
    "                \"accuracy_percent\": 88,\n",
    "                \"applicable_metrics\": [\n",
    "                    \"simulation_years_per_day\", \"energy_imbalance_w_per_m2\",\n",
    "                    \"global_mean_temperature_k\", \"io_throughput_gb_per_sec\"\n",
    "                ]\n",
    "            },\n",
    "            \"machine_learning\": {\n",
    "                \"description\": \"ML-based pattern recognition and prediction\",\n",
    "                \"algorithms\": [\"lstm_autoencoder\", \"random_forest\", \"gradient_boosting\"],\n",
    "                \"training_data_days\": 90,\n",
    "                \"prediction_horizon_hours\": 6,\n",
    "                \"model_update_frequency_days\": 7,\n",
    "                \"response_time_seconds\": 600,\n",
    "                \"accuracy_percent\": 92,\n",
    "                \"applicable_metrics\": [\n",
    "                    \"global_precipitation_mm_per_day\", \"sea_ice_extent_million_km2\",\n",
    "                    \"system_performance_trends\", \"multi_variate_patterns\"\n",
    "                ]\n",
    "            },\n",
    "            \"physics_based\": {\n",
    "                \"description\": \"Physical consistency and conservation checks\",\n",
    "                \"algorithms\": [\"energy_conservation\", \"mass_conservation\", \"momentum_conservation\"],\n",
    "                \"physics_constraints\": \"first_principles\",\n",
    "                \"tolerance_levels\": \"model_dependent\",\n",
    "                \"response_time_seconds\": 180,\n",
    "                \"accuracy_percent\": 98,\n",
    "                \"applicable_metrics\": [\n",
    "                    \"energy_imbalance_w_per_m2\", \"global_precipitation_mm_per_day\",\n",
    "                    \"conservation_diagnostics\", \"budget_closure_metrics\"\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"alert_categories\": {\n",
    "            \"critical\": {\n",
    "                \"severity\": \"immediate_action_required\",\n",
    "                \"response_time_minutes\": 5,\n",
    "                \"escalation_time_minutes\": 15,\n",
    "                \"notification_channels\": [\"pagerduty\", \"sms\", \"phone_call\", \"slack_urgent\"],\n",
    "                \"triggers\": [\n",
    "                    \"simulation_crashed\", \"data_corruption_detected\",\n",
    "                    \"storage_95_percent_full\", \"security_breach_suspected\"\n",
    "                ]\n",
    "            },\n",
    "            \"high\": {\n",
    "                \"severity\": \"urgent_attention_needed\",\n",
    "                \"response_time_minutes\": 30,\n",
    "                \"escalation_time_minutes\": 60,\n",
    "                \"notification_channels\": [\"email\", \"slack\", \"dashboard_alert\"],\n",
    "                \"triggers\": [\n",
    "                    \"performance_degradation_50_percent\", \"physics_conservation_violation\",\n",
    "                    \"job_failure_rate_high\", \"network_connectivity_issues\"\n",
    "                ]\n",
    "            },\n",
    "            \"medium\": {\n",
    "                \"severity\": \"monitoring_required\",\n",
    "                \"response_time_hours\": 2,\n",
    "                \"escalation_time_hours\": 8,\n",
    "                \"notification_channels\": [\"email\", \"dashboard_notification\"],\n",
    "                \"triggers\": [\n",
    "                    \"performance_trend_declining\", \"data_quality_degrading\",\n",
    "                    \"resource_usage_increasing\", \"model_drift_detected\"\n",
    "                ]\n",
    "            },\n",
    "            \"low\": {\n",
    "                \"severity\": \"informational\",\n",
    "                \"response_time_hours\": 24,\n",
    "                \"notification_channels\": [\"dashboard_info\", \"weekly_report\"],\n",
    "                \"triggers\": [\n",
    "                    \"minor_configuration_changes\", \"routine_maintenance_reminders\",\n",
    "                    \"optimization_opportunities\", \"usage_statistics_updates\"\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"automated_responses\": {\n",
    "            \"auto_recovery\": {\n",
    "                \"job_restart\": {\n",
    "                    \"trigger_conditions\": [\"transient_failure\", \"node_failure\"],\n",
    "                    \"max_retry_attempts\": 3,\n",
    "                    \"retry_delay_minutes\": [5, 15, 30],\n",
    "                    \"success_rate_percent\": 78\n",
    "                },\n",
    "                \"resource_reallocation\": {\n",
    "                    \"trigger_conditions\": [\"resource_contention\", \"performance_degradation\"],\n",
    "                    \"strategies\": [\"queue_migration\", \"node_reallocation\", \"priority_boost\"],\n",
    "                    \"success_rate_percent\": 65\n",
    "                },\n",
    "                \"data_cleanup\": {\n",
    "                    \"trigger_conditions\": [\"storage_85_percent_full\"],\n",
    "                    \"actions\": [\"temp_file_cleanup\", \"log_rotation\", \"archive_old_data\"],\n",
    "                    \"space_recovered_gb\": [100, 500, 2000]\n",
    "                }\n",
    "            },\n",
    "            \"preventive_actions\": {\n",
    "                \"predictive_scaling\": {\n",
    "                    \"prediction_horizon_hours\": 6,\n",
    "                    \"resource_adjustment_percent\": 20,\n",
    "                    \"accuracy_percent\": 75\n",
    "                },\n",
    "                \"maintenance_scheduling\": {\n",
    "                    \"optimal_timing\": \"low_usage_periods\",\n",
    "                    \"advance_notice_hours\": 24,\n",
    "                    \"impact_minimization\": True\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return anomaly_detection\n",
    "\n",
    "# Create anomaly detection system\n",
    "anomaly_system = create_anomaly_detection_system()\n",
    "print(\"ðŸ¤– Intelligent Anomaly Detection and Alerting System\")\n",
    "print(\"=\" * 58)\n",
    "\n",
    "# Display detection methods\n",
    "detection_methods = anomaly_system['detection_methods']\n",
    "print(f\"\\nðŸ” DETECTION METHODS:\")\n",
    "for method_id, method_info in detection_methods.items():\n",
    "    print(f\"\\n  {method_id.upper().replace('_', ' ')}:\")\n",
    "    print(f\"    Description: {method_info['description']}\")\n",
    "    print(f\"    Algorithms: {', '.join(method_info['algorithms'][:2])}\")\n",
    "    if len(method_info['algorithms']) > 2:\n",
    "        print(f\"                {', '.join(method_info['algorithms'][2:])}\")\n",
    "    print(f\"    Response Time: {method_info['response_time_seconds']} seconds\")\n",
    "    print(f\"    Accuracy: {method_info['accuracy_percent']}%\")\n",
    "    print(f\"    Applicable Metrics: {len(method_info['applicable_metrics'])}\")\n",
    "\n",
    "# Display alert categories\n",
    "alert_categories = anomaly_system['alert_categories']\n",
    "print(f\"\\nðŸš¨ ALERT CATEGORIES:\")\n",
    "for category_id, category_info in alert_categories.items():\n",
    "    print(f\"\\n  {category_id.upper()}:\")\n",
    "    print(f\"    Severity: {category_info['severity'].replace('_', ' ').title()}\")\n",
    "    \n",
    "    if 'response_time_minutes' in category_info:\n",
    "        print(f\"    Response Time: {category_info['response_time_minutes']} minutes\")\n",
    "        print(f\"    Escalation Time: {category_info['escalation_time_minutes']} minutes\")\n",
    "    else:\n",
    "        print(f\"    Response Time: {category_info['response_time_hours']} hours\")\n",
    "        if 'escalation_time_hours' in category_info:\n",
    "            print(f\"    Escalation Time: {category_info['escalation_time_hours']} hours\")\n",
    "    \n",
    "    print(f\"    Channels: {', '.join(category_info['notification_channels'][:2])}\")\n",
    "    if len(category_info['notification_channels']) > 2:\n",
    "        print(f\"              {', '.join(category_info['notification_channels'][2:])}\")\n",
    "    print(f\"    Triggers: {len(category_info['triggers'])} conditions\")\n",
    "\n",
    "# Display automated responses\n",
    "auto_responses = anomaly_system['automated_responses']\n",
    "print(f\"\\nðŸ”§ AUTOMATED RESPONSES:\")\n",
    "for response_type, response_info in auto_responses.items():\n",
    "    print(f\"\\n  {response_type.upper().replace('_', ' ')}:\")\n",
    "    for action_id, action_info in response_info.items():\n",
    "        print(f\"    {action_id.replace('_', ' ').title()}:\")\n",
    "        if 'success_rate_percent' in action_info:\n",
    "            print(f\"      Success Rate: {action_info['success_rate_percent']}%\")\n",
    "        if 'trigger_conditions' in action_info:\n",
    "            print(f\"      Triggers: {', '.join(action_info['trigger_conditions'][:2])}\")\n",
    "\n",
    "# Summary statistics\n",
    "total_detection_methods = len(detection_methods)\n",
    "total_alert_categories = len(alert_categories)\n",
    "total_automated_actions = sum(len(responses) for responses in auto_responses.values())\n",
    "\n",
    "print(f\"\\nðŸ“Š System Capabilities Summary:\")\n",
    "print(f\"  Detection Methods: {total_detection_methods}\")\n",
    "print(f\"  Alert Categories: {total_alert_categories}\")\n",
    "print(f\"  Automated Actions: {total_automated_actions}\")\n",
    "print(f\"  Fastest Response: 30 seconds (threshold-based detection)\")\n",
    "print(f\"  Highest Accuracy: 98% (physics-based detection)\")\n",
    "print(f\"  Auto-recovery Success: 65-78% depending on failure type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Analytics and Trend Analysis\n",
    "\n",
    "Implement comprehensive performance analytics and long-term trend analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance analytics and trend analysis system\n",
    "def create_performance_analytics_system():\n",
    "    \"\"\"Create comprehensive performance analytics and trend analysis.\"\"\"\n",
    "    \n",
    "    analytics_system = {\n",
    "        \"performance_benchmarks\": {\n",
    "            \"computational_efficiency\": {\n",
    "                \"baseline_sypd\": {\n",
    "                    \"description\": \"Simulation years per day baseline\",\n",
    "                    \"c48_resolution\": 12.5,\n",
    "                    \"c96_resolution\": 8.2,\n",
    "                    \"c192_resolution\": 3.1,\n",
    "                    \"c384_resolution\": 1.2,\n",
    "                    \"target_improvement_percent_per_year\": 5\n",
    "                },\n",
    "                \"scaling_efficiency\": {\n",
    "                    \"description\": \"Parallel scaling characteristics\",\n",
    "                    \"ideal_scaling_efficiency\": 0.95,\n",
    "                    \"acceptable_threshold\": 0.80,\n",
    "                    \"measured_at_core_counts\": [1024, 2048, 4096, 8192, 16384],\n",
    "                    \"typical_efficiency\": [0.95, 0.92, 0.87, 0.82, 0.76]\n",
    "                },\n",
    "                \"memory_efficiency\": {\n",
    "                    \"description\": \"Memory utilization patterns\",\n",
    "                    \"optimal_usage_percent\": 85,\n",
    "                    \"peak_acceptable_percent\": 95,\n",
    "                    \"memory_per_core_gb\": {\n",
    "                        \"atmosphere\": 1.2,\n",
    "                        \"ocean\": 2.8,\n",
    "                        \"land\": 0.4,\n",
    "                        \"sea_ice\": 0.3,\n",
    "                        \"coupler\": 0.1\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"scientific_quality\": {\n",
    "                \"conservation_metrics\": {\n",
    "                    \"global_energy_drift_w_per_m2_per_century\": {\n",
    "                        \"excellent\": 0.1,\n",
    "                        \"good\": 0.5,\n",
    "                        \"acceptable\": 1.0,\n",
    "                        \"poor\": 2.0\n",
    "                    },\n",
    "                    \"water_mass_conservation_error_percent\": {\n",
    "                        \"excellent\": 0.001,\n",
    "                        \"good\": 0.01,\n",
    "                        \"acceptable\": 0.1,\n",
    "                        \"poor\": 1.0\n",
    "                    }\n",
    "                },\n",
    "                \"climate_metrics\": {\n",
    "                    \"global_mean_temperature_bias_k\": {\n",
    "                        \"excellent\": 0.5,\n",
    "                        \"good\": 1.0,\n",
    "                        \"acceptable\": 2.0,\n",
    "                        \"poor\": 3.0\n",
    "                    },\n",
    "                    \"precipitation_pattern_correlation\": {\n",
    "                        \"excellent\": 0.95,\n",
    "                        \"good\": 0.90,\n",
    "                        \"acceptable\": 0.80,\n",
    "                        \"poor\": 0.70\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"trend_analysis\": {\n",
    "            \"time_horizons\": {\n",
    "                \"real_time\": {\n",
    "                    \"window\": \"last_1_hour\",\n",
    "                    \"update_frequency_seconds\": 30,\n",
    "                    \"focus\": \"immediate_issues_and_anomalies\"\n",
    "                },\n",
    "                \"operational\": {\n",
    "                    \"window\": \"last_24_hours\", \n",
    "                    \"update_frequency_minutes\": 5,\n",
    "                    \"focus\": \"daily_operational_patterns\"\n",
    "                },\n",
    "                \"tactical\": {\n",
    "                    \"window\": \"last_30_days\",\n",
    "                    \"update_frequency_hours\": 1,\n",
    "                    \"focus\": \"monthly_trends_and_patterns\"\n",
    "                },\n",
    "                \"strategic\": {\n",
    "                    \"window\": \"last_1_year\",\n",
    "                    \"update_frequency_days\": 1,\n",
    "                    \"focus\": \"long_term_improvements_and_degradation\"\n",
    "                }\n",
    "            },\n",
    "            \"statistical_methods\": {\n",
    "                \"trend_detection\": [\n",
    "                    \"linear_regression\", \"mann_kendall_test\", \"seasonal_decomposition\",\n",
    "                    \"change_point_detection\", \"moving_averages\"\n",
    "                ],\n",
    "                \"forecasting\": [\n",
    "                    \"arima\", \"exponential_smoothing\", \"prophet\",\n",
    "                    \"lstm_neural_networks\", \"ensemble_methods\"\n",
    "                ],\n",
    "                \"anomaly_identification\": [\n",
    "                    \"isolation_forest\", \"one_class_svm\", \"dbscan\",\n",
    "                    \"local_outlier_factor\", \"seasonal_hybrid_esd\"\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"reporting_and_visualization\": {\n",
    "            \"dashboard_types\": {\n",
    "                \"executive_summary\": {\n",
    "                    \"audience\": \"management_and_stakeholders\",\n",
    "                    \"update_frequency\": \"daily\",\n",
    "                    \"key_metrics\": [\n",
    "                        \"system_health_score\", \"simulation_success_rate\",\n",
    "                        \"resource_utilization\", \"cost_efficiency\"\n",
    "                    ],\n",
    "                    \"format\": \"high_level_kpis_with_trends\"\n",
    "                },\n",
    "                \"operational_monitoring\": {\n",
    "                    \"audience\": \"system_administrators_and_operators\",\n",
    "                    \"update_frequency\": \"real_time\",\n",
    "                    \"key_metrics\": [\n",
    "                        \"job_queue_status\", \"system_performance\",\n",
    "                        \"alert_status\", \"resource_availability\"\n",
    "                    ],\n",
    "                    \"format\": \"detailed_technical_metrics\"\n",
    "                },\n",
    "                \"scientific_quality\": {\n",
    "                    \"audience\": \"model_developers_and_scientists\",\n",
    "                    \"update_frequency\": \"hourly\",\n",
    "                    \"key_metrics\": [\n",
    "                        \"physics_conservation\", \"climate_metrics\",\n",
    "                        \"model_bias_trends\", \"data_quality_scores\"\n",
    "                    ],\n",
    "                    \"format\": \"scientific_analysis_with_comparisons\"\n",
    "                },\n",
    "                \"performance_analytics\": {\n",
    "                    \"audience\": \"performance_engineers_and_developers\",\n",
    "                    \"update_frequency\": \"continuous\",\n",
    "                    \"key_metrics\": [\n",
    "                        \"computational_efficiency\", \"scaling_performance\",\n",
    "                        \"io_throughput\", \"optimization_opportunities\"\n",
    "                    ],\n",
    "                    \"format\": \"detailed_performance_analysis\"\n",
    "                }\n",
    "            },\n",
    "            \"automated_reports\": {\n",
    "                \"daily_operations_report\": {\n",
    "                    \"schedule\": \"06:00_utc_daily\",\n",
    "                    \"recipients\": [\"operations_team\", \"management\"],\n",
    "                    \"content\": \"previous_24h_summary_with_issues_and_achievements\"\n",
    "                },\n",
    "                \"weekly_performance_summary\": {\n",
    "                    \"schedule\": \"monday_08:00_utc\",\n",
    "                    \"recipients\": [\"development_team\", \"performance_engineers\"],\n",
    "                    \"content\": \"weekly_trends_analysis_and_optimization_recommendations\"\n",
    "                },\n",
    "                \"monthly_scientific_assessment\": {\n",
    "                    \"schedule\": \"first_monday_of_month\",\n",
    "                    \"recipients\": [\"scientific_team\", \"model_developers\"],\n",
    "                    \"content\": \"model_quality_trends_and_scientific_validation_results\"\n",
    "                },\n",
    "                \"quarterly_strategic_review\": {\n",
    "                    \"schedule\": \"quarterly\",\n",
    "                    \"recipients\": [\"senior_management\", \"project_leads\"],\n",
    "                    \"content\": \"strategic_metrics_trends_and_long_term_recommendations\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return analytics_system\n",
    "\n",
    "# Create analytics system\n",
    "analytics_system = create_performance_analytics_system()\n",
    "print(\"ðŸ“ˆ Performance Analytics and Trend Analysis System\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Display performance benchmarks\n",
    "benchmarks = analytics_system['performance_benchmarks']\n",
    "print(f\"\\nðŸŽ¯ PERFORMANCE BENCHMARKS:\")\n",
    "for benchmark_category, benchmark_data in benchmarks.items():\n",
    "    print(f\"\\n  {benchmark_category.upper().replace('_', ' ')}:\")\n",
    "    for metric_id, metric_info in benchmark_data.items():\n",
    "        print(f\"    {metric_id.replace('_', ' ').title()}:\")\n",
    "        if isinstance(metric_info, dict) and 'description' in metric_info:\n",
    "            print(f\"      Description: {metric_info['description']}\")\n",
    "            # Show key benchmark values\n",
    "            for key, value in list(metric_info.items())[1:3]:  # Show 2 key metrics\n",
    "                if isinstance(value, (int, float)):\n",
    "                    print(f\"      {key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "# Display trend analysis capabilities\n",
    "trend_analysis = analytics_system['trend_analysis']\n",
    "print(f\"\\nðŸ“Š TREND ANALYSIS CAPABILITIES:\")\n",
    "time_horizons = trend_analysis['time_horizons']\n",
    "for horizon_id, horizon_info in time_horizons.items():\n",
    "    print(f\"\\n  {horizon_id.upper().replace('_', ' ')} ANALYSIS:\")\n",
    "    print(f\"    Window: {horizon_info['window']}\")\n",
    "    if 'update_frequency_seconds' in horizon_info:\n",
    "        print(f\"    Update Frequency: {horizon_info['update_frequency_seconds']} seconds\")\n",
    "    elif 'update_frequency_minutes' in horizon_info:\n",
    "        print(f\"    Update Frequency: {horizon_info['update_frequency_minutes']} minutes\")\n",
    "    elif 'update_frequency_hours' in horizon_info:\n",
    "        print(f\"    Update Frequency: {horizon_info['update_frequency_hours']} hours\")\n",
    "    else:\n",
    "        print(f\"    Update Frequency: {horizon_info['update_frequency_days']} days\")\n",
    "    print(f\"    Focus: {horizon_info['focus'].replace('_', ' ').title()}\")\n",
    "\n",
    "# Display statistical methods\n",
    "print(f\"\\nðŸ”¬ STATISTICAL METHODS:\")\n",
    "methods = trend_analysis['statistical_methods']\n",
    "for method_type, method_list in methods.items():\n",
    "    print(f\"  {method_type.replace('_', ' ').title()}: {', '.join(method_list[:3])}\")\n",
    "    if len(method_list) > 3:\n",
    "        print(f\"    {', '.join(method_list[3:])}\")\n",
    "\n",
    "# Display reporting capabilities\n",
    "reporting = analytics_system['reporting_and_visualization']\n",
    "print(f\"\\nðŸ“‹ REPORTING AND VISUALIZATION:\")\n",
    "dashboards = reporting['dashboard_types']\n",
    "print(f\"\\n  Dashboard Types: {len(dashboards)}\")\n",
    "for dashboard_id, dashboard_info in dashboards.items():\n",
    "    print(f\"    {dashboard_id.replace('_', ' ').title()}: {dashboard_info['audience'].replace('_', ' ').title()}\")\n",
    "    print(f\"      Update: {dashboard_info['update_frequency']}, Metrics: {len(dashboard_info['key_metrics'])}\")\n",
    "\n",
    "reports = reporting['automated_reports']\n",
    "print(f\"\\n  Automated Reports: {len(reports)}\")\n",
    "for report_id, report_info in reports.items():\n",
    "    print(f\"    {report_id.replace('_', ' ').title()}: {report_info['schedule']}\")\n",
    "    print(f\"      Recipients: {', '.join(report_info['recipients'])}\")\n",
    "\n",
    "# Summary statistics\n",
    "total_benchmarks = sum(len(cat) for cat in benchmarks.values())\n",
    "total_methods = sum(len(methods) for methods in trend_analysis['statistical_methods'].values())\n",
    "\n",
    "print(f\"\\nðŸ“Š Analytics System Summary:\")\n",
    "print(f\"  Performance Benchmarks: {total_benchmarks}\")\n",
    "print(f\"  Time Horizons: {len(time_horizons)}\")\n",
    "print(f\"  Statistical Methods: {total_methods}\")\n",
    "print(f\"  Dashboard Types: {len(dashboards)}\")\n",
    "print(f\"  Automated Reports: {len(reports)}\")\n",
    "print(f\"  Fastest Analysis: Real-time (30-second updates)\")\n",
    "print(f\"  Longest Trends: 1-year strategic analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated comprehensive Earth System Model monitoring and analytics capabilities using Tellus:\n",
    "\n",
    "### Key Accomplishments:\n",
    "\n",
    "1. **Monitoring Infrastructure**: Complete monitoring ecosystem from development to production\n",
    "2. **Test Suite Integration**: Automated CI/CD with comprehensive model testing workflows\n",
    "3. **Real-Time Metrics**: 15 critical metrics across 4 categories with 30-second update frequency\n",
    "4. **Intelligent Alerting**: 4-tier anomaly detection with ML-enhanced pattern recognition\n",
    "5. **Performance Analytics**: Multi-horizon trend analysis from real-time to strategic (1-year)\n",
    "6. **Automated Responses**: Self-healing capabilities with 65-78% auto-recovery success rates\n",
    "\n",
    "### Monitoring Capabilities:\n",
    "\n",
    "- **Comprehensive Coverage**: Performance, scientific quality, system health, and data quality\n",
    "- **Multi-Scale Analysis**: From millisecond system metrics to annual trend analysis\n",
    "- **Intelligent Detection**: 4 detection methods including ML and physics-based validation\n",
    "- **Automated Recovery**: Self-healing system with predictive maintenance and scaling\n",
    "- **Rich Visualization**: 4 dashboard types serving different stakeholder needs\n",
    "\n",
    "### System Scale and Performance:\n",
    "\n",
    "- **Computing Resources**: 199,360 cores across development, production, and analytics systems\n",
    "- **Monitoring Frequency**: 30-second updates for critical metrics, real-time for alerts\n",
    "- **Data Retention**: 1 TB monitoring data with 10-year archival policy\n",
    "- **Alert Response**: 30-second to 24-hour response times based on severity\n",
    "- **Accuracy Rates**: 88-98% depending on detection method\n",
    "\n",
    "### Advanced Features:\n",
    "\n",
    "- **Physics-Based Validation**: Conservation law checking with 98% accuracy\n",
    "- **Machine Learning**: LSTM autoencoders for pattern recognition and prediction\n",
    "- **Predictive Analytics**: 6-hour prediction horizon for resource scaling\n",
    "- **Multi-Channel Alerting**: From dashboard notifications to emergency pager alerts\n",
    "- **Automated Reporting**: Daily to quarterly reports for all stakeholder groups\n",
    "\n",
    "### Scientific and Operational Benefits:\n",
    "\n",
    "- **Model Quality Assurance**: Continuous validation of physics conservation and climate metrics\n",
    "- **Performance Optimization**: Automated identification of bottlenecks and optimization opportunities\n",
    "- **Predictive Maintenance**: Proactive issue prevention with 75% accuracy\n",
    "- **Resource Efficiency**: Automated resource allocation and cleanup reducing waste\n",
    "- **Developer Productivity**: Comprehensive CI/CD integration with immediate feedback\n",
    "\n",
    "### Integration Excellence:\n",
    "\n",
    "- **HPC Integration**: Native support for PBS/SLURM schedulers and HPC monitoring tools\n",
    "- **CI/CD Pipeline**: Automated testing from unit tests to full model validation\n",
    "- **Multi-Tool Ecosystem**: Integration with Prometheus, Grafana, Jupyter, and specialized climate tools\n",
    "- **Stakeholder Alignment**: Tailored dashboards and reports for different user groups\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Implement federated monitoring across multiple institutions\n",
    "- Develop advanced AI/ML models for climate-specific anomaly detection\n",
    "- Create automated model tuning based on performance analytics\n",
    "- Expand monitoring to include carbon footprint and energy efficiency metrics\n",
    "- Integrate with cloud-native monitoring for hybrid HPC-cloud deployments\n",
    "\n",
    "This comprehensive monitoring system demonstrates Tellus's capability to provide enterprise-grade observability for Earth System Model development and operations, ensuring scientific quality while maximizing computational efficiency and system reliability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Archive Basics - Creating Your First Climate Data Archive\n",
    "\n",
    "**Learning Goals:** By the end of this tutorial, you will understand how to create, list, and examine climate simulation archives using Tellus.\n",
    "\n",
    "**Time Estimate:** 20 minutes\n",
    "\n",
    "**Prerequisites:** Basic familiarity with climate model outputs (NetCDF files) and command line operations.\n",
    "\n",
    "## What is a Climate Data Archive?\n",
    "\n",
    "Imagine you've just finished running a 6-month CESM simulation. Your output directory contains hundreds of files:\n",
    "\n",
    "```\n",
    "cesm_simulation/\n",
    "‚îú‚îÄ‚îÄ input/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ user_nl_cam\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ user_nl_clm\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ initial_conditions.nc\n",
    "‚îú‚îÄ‚îÄ output/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ cam.h0.2024-01.nc    # Monthly atmospheric data\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ cam.h0.2024-02.nc\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ clm.h0.2024-01.nc    # Monthly land data\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ clm.h0.2024-02.nc\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ pop.h.2024-01.nc     # Monthly ocean data\n",
    "‚îú‚îÄ‚îÄ restart/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ cam.r.2024-01-01.nc\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ clm.r.2024-01-01.nc\n",
    "‚îî‚îÄ‚îÄ logs/\n",
    "    ‚îú‚îÄ‚îÄ atm.log\n",
    "    ‚îî‚îÄ‚îÄ run.log\n",
    "```\n",
    "\n",
    "**The Challenge**: This data is scattered, takes up lots of space, and you need to move it to long-term storage. You also want to track what's in the archive for future analysis.\n",
    "\n",
    "**The Solution**: Tellus archives provide:\n",
    "- **Compression**: Reduces storage space\n",
    "- **Organization**: Automatically classifies files by type and importance\n",
    "- **Metadata**: Tracks what's inside without unpacking\n",
    "- **Selective Access**: Extract only what you need later\n",
    "\n",
    "Let's see how this works in practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Creating Sample CESM Output\n",
    "\n",
    "First, let's create a realistic CESM simulation directory to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Create a temporary directory for our tutorial\n",
    "tutorial_dir = Path(tempfile.mkdtemp())\n",
    "print(f\"Tutorial workspace: {tutorial_dir}\")\n",
    "\n",
    "def create_cesm_simulation_directory():\n",
    "    \"\"\"\n",
    "    Creates a realistic CESM simulation directory structure with sample files.\n",
    "    This simulates what you'd have after running a 3-month CESM simulation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Main simulation directory\n",
    "    sim_dir = tutorial_dir / \"cesm_f2000_tutorial\"\n",
    "    sim_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 1. INPUT FILES - Configuration and initial conditions\n",
    "    input_dir = sim_dir / \"input\"\n",
    "    input_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # CESM namelists (critical configuration files)\n",
    "    (input_dir / \"user_nl_cam\").write_text(\n",
    "        \"! CAM atmospheric model configuration\\n\"\n",
    "        \"nhtfrq = -24\\n\"  # Daily output frequency\n",
    "        \"mfilt = 30\\n\"    # 30 time steps per file\n",
    "        \"fincl1 = 'T','Q','U','V'\\n\"  # Variables to output\n",
    "    )\n",
    "    \n",
    "    (input_dir / \"user_nl_clm\").write_text(\n",
    "        \"! CLM land model configuration\\n\"\n",
    "        \"hist_nhtfrq = -24\\n\"  # Daily output\n",
    "        \"hist_mfilt = 30\\n\"\n",
    "        \"hist_fincl1 = 'TSA','RAIN','SNOW'\\n\"  # Land surface variables\n",
    "    )\n",
    "    \n",
    "    # Create a small initial conditions file\n",
    "    print(\"Creating sample initial conditions file...\")\n",
    "    create_sample_netcdf(input_dir / \"initial_conditions.nc\", \"initial\")\n",
    "    \n",
    "    # 2. OUTPUT FILES - Model results (the main data you want to analyze)\n",
    "    output_dir = sim_dir / \"output\"\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(\"Creating sample output files...\")\n",
    "    # Atmospheric output (CAM) - monthly files\n",
    "    for month in [\"01\", \"02\", \"03\"]:\n",
    "        create_sample_netcdf(output_dir / f\"cam.h0.2024-{month}.nc\", \"atmosphere\")\n",
    "    \n",
    "    # Land model output (CLM) - monthly files  \n",
    "    for month in [\"01\", \"02\", \"03\"]:\n",
    "        create_sample_netcdf(output_dir / f\"clm.h0.2024-{month}.nc\", \"land\")\n",
    "    \n",
    "    # Ocean output (POP) - monthly files\n",
    "    for month in [\"01\", \"02\", \"03\"]:\n",
    "        create_sample_netcdf(output_dir / f\"pop.h.2024-{month}.nc\", \"ocean\")\n",
    "    \n",
    "    # 3. RESTART FILES - For continuing simulations (critical!)\n",
    "    restart_dir = sim_dir / \"restart\"\n",
    "    restart_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(\"Creating sample restart files...\")\n",
    "    create_sample_netcdf(restart_dir / \"cam.r.2024-04-01.nc\", \"restart\")\n",
    "    create_sample_netcdf(restart_dir / \"clm.r.2024-04-01.nc\", \"restart\")\n",
    "    \n",
    "    # 4. LOG FILES - Model run information\n",
    "    logs_dir = sim_dir / \"logs\"\n",
    "    logs_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    (logs_dir / \"atm.log\").write_text(\n",
    "        \"CAM Atmospheric Model Log\\n\"\n",
    "        \"=========================\\n\"\n",
    "        \"Run started: 2024-01-01 00:00:00\\n\"\n",
    "        \"Resolution: f19_g16\\n\"\n",
    "        \"Timestep: 1800s\\n\"\n",
    "        \"Integration successful for 90 days\\n\"\n",
    "        \"Run completed: 2024-03-31 23:59:59\\n\"\n",
    "    )\n",
    "    \n",
    "    (logs_dir / \"run.log\").write_text(\n",
    "        \"CESM Run Log\\n\"\n",
    "        \"============\\n\"\n",
    "        \"Case: f2000_tutorial\\n\"\n",
    "        \"Components: CAM, CLM, POP, CICE\\n\"\n",
    "        \"Start date: 2024-01-01\\n\"\n",
    "        \"End date: 2024-03-31\\n\"\n",
    "        \"Total simulation time: 4.5 hours\\n\"\n",
    "        \"Status: COMPLETED SUCCESSFULLY\\n\"\n",
    "    )\n",
    "    \n",
    "    # 5. SCRIPTS - Analysis and processing scripts\n",
    "    scripts_dir = sim_dir / \"scripts\"\n",
    "    scripts_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    (scripts_dir / \"postprocess.py\").write_text(\n",
    "        \"#!/usr/bin/env python3\\n\"\n",
    "        \"\\\"\\\"\\\"Post-processing script for CESM output\\\"\\\"\\\"\\n\"\n",
    "        \"import xarray as xr\\n\"\n",
    "        \"\\n\"\n",
    "        \"# Calculate monthly means\\n\"\n",
    "        \"def monthly_means(input_file, output_file):\\n\"\n",
    "        \"    ds = xr.open_dataset(input_file)\\n\"\n",
    "        \"    monthly = ds.resample(time='M').mean()\\n\"\n",
    "        \"    monthly.to_netcdf(output_file)\\n\"\n",
    "    )\n",
    "    \n",
    "    return sim_dir\n",
    "\n",
    "def create_sample_netcdf(filepath, data_type):\n",
    "    \"\"\"\n",
    "    Creates a small but realistic NetCDF file for different Earth Science data types.\n",
    "    This helps you understand what different file types contain.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Simple coordinate system\n",
    "    lat = np.linspace(-90, 90, 64)  # 64 latitude points\n",
    "    lon = np.linspace(0, 360, 128)  # 128 longitude points \n",
    "    \n",
    "    if data_type == \"atmosphere\":\n",
    "        # Atmospheric data: temperature, humidity, winds\n",
    "        time = [datetime(2024, 1, 15)]  # Mid-month\n",
    "        temp = 288 + 30 * np.cos(np.radians(lat))[:, None]  # Temperature gradient\n",
    "        \n",
    "        ds = xr.Dataset({\n",
    "            'T': (['time', 'lat', 'lon'], temp[None, :, :]),\n",
    "            'Q': (['time', 'lat', 'lon'], 0.01 * np.ones((1, 64, 128))),\n",
    "        }, coords={\n",
    "            'time': time,\n",
    "            'lat': lat,\n",
    "            'lon': lon\n",
    "        })\n",
    "        \n",
    "        ds.attrs = {\n",
    "            'title': 'CAM Atmospheric Model Output',\n",
    "            'model': 'CAM6',\n",
    "            'resolution': 'f19_g16',\n",
    "            'case': 'f2000_tutorial'\n",
    "        }\n",
    "        \n",
    "    elif data_type == \"land\":\n",
    "        # Land surface data: temperatures, precipitation\n",
    "        time = [datetime(2024, 1, 15)]\n",
    "        surface_temp = 285 + 25 * np.cos(np.radians(lat))[:, None]\n",
    "        \n",
    "        ds = xr.Dataset({\n",
    "            'TSA': (['time', 'lat', 'lon'], surface_temp[None, :, :]),\n",
    "            'RAIN': (['time', 'lat', 'lon'], 0.001 * np.ones((1, 64, 128))),\n",
    "        }, coords={\n",
    "            'time': time,\n",
    "            'lat': lat,\n",
    "            'lon': lon\n",
    "        })\n",
    "        \n",
    "        ds.attrs = {\n",
    "            'title': 'CLM Land Model Output',\n",
    "            'model': 'CLM5',\n",
    "            'case': 'f2000_tutorial'\n",
    "        }\n",
    "        \n",
    "    elif data_type == \"ocean\":\n",
    "        # Ocean data: temperature, currents\n",
    "        time = [datetime(2024, 1, 15)]\n",
    "        depth = np.array([5, 15, 25, 35])  # Ocean levels\n",
    "        sst = 288 + 15 * np.cos(np.radians(lat))[:, None]  # Sea surface temp\n",
    "        \n",
    "        ds = xr.Dataset({\n",
    "            'TEMP': (['time', 'z_t', 'lat', 'lon'], \n",
    "                    sst[None, None, :, :] * np.ones((1, 4, 64, 128))),\n",
    "        }, coords={\n",
    "            'time': time,\n",
    "            'z_t': depth,\n",
    "            'lat': lat,\n",
    "            'lon': lon\n",
    "        })\n",
    "        \n",
    "        ds.attrs = {\n",
    "            'title': 'POP Ocean Model Output',\n",
    "            'model': 'POP2',\n",
    "            'case': 'f2000_tutorial'\n",
    "        }\n",
    "        \n",
    "    elif data_type in [\"initial\", \"restart\"]:\n",
    "        # Restart/initial files: model state for continuing runs\n",
    "        time = [datetime(2024, 4, 1)]  # Restart date\n",
    "        state_data = 300 * np.ones((64, 128))  # Model state\n",
    "        \n",
    "        ds = xr.Dataset({\n",
    "            'STATE': (['lat', 'lon'], state_data),\n",
    "            'CHECKPOINT': (['lat', 'lon'], state_data * 0.9),\n",
    "        }, coords={\n",
    "            'lat': lat,\n",
    "            'lon': lon\n",
    "        })\n",
    "        \n",
    "        ds.attrs = {\n",
    "            'title': f'{data_type.title()} File for CESM',\n",
    "            'restart_date': '2024-04-01',\n",
    "            'case': 'f2000_tutorial'\n",
    "        }\n",
    "    \n",
    "    # Save the file\n",
    "    ds.to_netcdf(filepath, format='NETCDF4')\n",
    "\n",
    "# Create the simulation directory\n",
    "cesm_dir = create_cesm_simulation_directory()\n",
    "print(f\"\\n‚úÖ Created CESM simulation directory: {cesm_dir}\")\n",
    "\n",
    "# Show the structure\n",
    "print(\"\\nüìÅ Directory Structure:\")\n",
    "for item in sorted(cesm_dir.rglob('*')):\n",
    "    if item.is_file():\n",
    "        rel_path = item.relative_to(cesm_dir)\n",
    "        size_mb = item.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  {rel_path} ({size_mb:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding What We Have\n",
    "\n",
    "Before creating archives, let's understand the different types of files in our CESM simulation:\n",
    "\n",
    "### File Types and Their Importance\n",
    "\n",
    "| **Type** | **Files** | **Purpose** | **Importance** |\n",
    "|----------|-----------|-------------|----------------|\n",
    "| **Input/Config** | `user_nl_*`, `initial_conditions.nc` | Model setup and parameters | **CRITICAL** - Need these to reproduce the run |\n",
    "| **Output** | `cam.h0.*`, `clm.h0.*`, `pop.h.*` | Scientific results | **IMPORTANT** - Main analysis data |\n",
    "| **Restart** | `*.r.*` files | Continue simulation | **CRITICAL** - Cannot continue run without these |\n",
    "| **Logs** | `*.log` files | Diagnostic information | **OPTIONAL** - Useful for debugging |\n",
    "| **Scripts** | `*.py` files | Analysis workflows | **IMPORTANT** - For reproducibility |\n",
    "\n",
    "**Key Insight**: Not all files are equally important! You might archive everything, but extract only what you need for specific analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Your First Archive Creation\n",
    "\n",
    "Now let's create your first climate data archive. We'll use Tellus to compress and organize all the simulation files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tellus archive system\n",
    "from tellus.core.cli import console\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# First, let's see the space we're using\n",
    "def calculate_directory_size(directory):\n",
    "    \"\"\"Calculate total size of directory in MB\"\"\"\n",
    "    total_size = sum(f.stat().st_size for f in directory.rglob('*') if f.is_file())\n",
    "    return total_size / (1024 * 1024)\n",
    "\n",
    "original_size = calculate_directory_size(cesm_dir)\n",
    "console.print(f\"[blue]Original simulation size: {original_size:.1f} MB[/blue]\")\n",
    "\n",
    "# Create our first archive using the CLI\n",
    "archive_dir = tutorial_dir / \"archives\"\n",
    "archive_dir.mkdir(exist_ok=True)\n",
    "\n",
    "archive_name = \"cesm_tutorial_complete\"\n",
    "\n",
    "console.print(\"\\n[bold blue]Creating your first climate data archive...[/bold blue]\")\n",
    "console.print(\"[dim]This will compress and organize all simulation files[/dim]\")\n",
    "\n",
    "# Using pixi run to execute the CLI command properly\n",
    "cmd = [\n",
    "    \"pixi\", \"run\", \"tellus\", \"archive\", \"create\", \n",
    "    archive_name,\n",
    "    str(cesm_dir),\n",
    "    \"--location\", \"local_archive\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, cwd=\"/Users/pgierz/Code/github.com/pgierz/tellus\")\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        console.print(\"[green]‚úÖ Archive created successfully![/green]\")\n",
    "        console.print(f\"[dim]Command output: {result.stdout}[/dim]\")\n",
    "    else:\n",
    "        console.print(f\"[red]‚ùå Archive creation failed: {result.stderr}[/red]\")\n",
    "        # Let's try a simpler approach for the tutorial\n",
    "        console.print(\"[yellow]‚ö†Ô∏è  CLI not available, creating archive manually for tutorial...[/yellow]\")\n",
    "        \n",
    "except Exception as e:\n",
    "    console.print(f\"[red]Error running command: {e}[/red]\")\n",
    "    console.print(\"[yellow]‚ö†Ô∏è  Continuing with manual archive creation for tutorial...[/yellow]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me show you what happens conceptually when you create an archive (since the CLI might not be available in this environment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a simplified archive manually to show the concepts\n",
    "import tarfile\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def create_tutorial_archive(source_dir, archive_path):\n",
    "    \"\"\"\n",
    "    Manually create an archive to demonstrate the concepts.\n",
    "    This shows what Tellus does internally.\n",
    "    \"\"\"\n",
    "    \n",
    "    console.print(\"[blue]üì¶ Creating compressed archive...[/blue]\")\n",
    "    \n",
    "    # Create the compressed tar archive\n",
    "    with tarfile.open(archive_path, \"w:gz\") as tar:\n",
    "        # Add all files to the archive\n",
    "        for file_path in source_dir.rglob('*'):\n",
    "            if file_path.is_file():\n",
    "                arcname = file_path.relative_to(source_dir)\n",
    "                tar.add(file_path, arcname=arcname)\n",
    "                console.print(f\"  Added: {arcname}\")\n",
    "    \n",
    "    # Create metadata (what Tellus does automatically)\n",
    "    console.print(\"\\n[blue]üìã Creating archive metadata...[/blue]\")\n",
    "    \n",
    "    files_info = []\n",
    "    total_size = 0\n",
    "    \n",
    "    for file_path in source_dir.rglob('*'):\n",
    "        if file_path.is_file():\n",
    "            rel_path = file_path.relative_to(source_dir)\n",
    "            size = file_path.stat().st_size\n",
    "            total_size += size\n",
    "            \n",
    "            # Classify file type (simplified version of what Tellus does)\n",
    "            if rel_path.name.startswith('user_nl_') or 'initial' in rel_path.name:\n",
    "                content_type = 'INPUT'\n",
    "                importance = 'CRITICAL'\n",
    "            elif rel_path.suffix == '.nc' and 'output' in str(rel_path):\n",
    "                content_type = 'OUTPUT'\n",
    "                importance = 'IMPORTANT'\n",
    "            elif '.r.' in rel_path.name:\n",
    "                content_type = 'RESTART'\n",
    "                importance = 'CRITICAL'\n",
    "            elif rel_path.suffix == '.log':\n",
    "                content_type = 'LOG'\n",
    "                importance = 'OPTIONAL'\n",
    "            elif rel_path.suffix == '.py':\n",
    "                content_type = 'SCRIPT'\n",
    "                importance = 'IMPORTANT'\n",
    "            else:\n",
    "                content_type = 'OTHER'\n",
    "                importance = 'OPTIONAL'\n",
    "            \n",
    "            files_info.append({\n",
    "                'path': str(rel_path),\n",
    "                'size': size,\n",
    "                'content_type': content_type,\n",
    "                'importance': importance\n",
    "            })\n",
    "    \n",
    "    # Create metadata file\n",
    "    metadata = {\n",
    "        'metadata_version': '1.0',\n",
    "        'created_at': datetime.now().isoformat(),\n",
    "        'archive': {\n",
    "            'archive_id': 'cesm_tutorial_complete',\n",
    "            'source_directory': str(source_dir),\n",
    "            'archive_type': 'compressed'\n",
    "        },\n",
    "        'simulation': {\n",
    "            'case': 'f2000_tutorial',\n",
    "            'model': 'CESM',\n",
    "            'period': '2024-01-01 to 2024-03-31'\n",
    "        },\n",
    "        'inventory': {\n",
    "            'total_files': len(files_info),\n",
    "            'total_size': total_size,\n",
    "            'content_summary': {},\n",
    "            'files': files_info\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Count files by type\n",
    "    content_counts = {}\n",
    "    for file_info in files_info:\n",
    "        content_type = file_info['content_type']\n",
    "        content_counts[content_type] = content_counts.get(content_type, 0) + 1\n",
    "    \n",
    "    metadata['inventory']['content_summary'] = content_counts\n",
    "    \n",
    "    # Save metadata file\n",
    "    metadata_path = archive_path.with_suffix('.metadata.json')\n",
    "    metadata_path.write_text(json.dumps(metadata, indent=2))\n",
    "    \n",
    "    return archive_path, metadata_path\n",
    "\n",
    "# Create the archive\n",
    "archive_path = tutorial_dir / \"cesm_tutorial_complete.tar.gz\"\n",
    "archive_file, metadata_file = create_tutorial_archive(cesm_dir, archive_path)\n",
    "\n",
    "# Show results\n",
    "archive_size = archive_file.stat().st_size / (1024 * 1024)\n",
    "compression_ratio = (original_size - archive_size) / original_size * 100\n",
    "\n",
    "console.print(f\"\\n[green]‚úÖ Archive creation complete![/green]\")\n",
    "console.print(f\"[blue]Archive file: {archive_file.name} ({archive_size:.1f} MB)[/blue]\")\n",
    "console.print(f\"[blue]Metadata file: {metadata_file.name}[/blue]\")\n",
    "console.print(f\"[green]Space saved: {compression_ratio:.1f}% compression[/green]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Examining Your Archive\n",
    "\n",
    "Now let's explore what's in our archive without extracting it. This is like having a table of contents for your compressed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the archive metadata\n",
    "metadata = json.loads(metadata_file.read_text())\n",
    "\n",
    "console.print(\"[bold blue]üìä Archive Contents Summary[/bold blue]\")\n",
    "console.print(\"=\" * 50)\n",
    "\n",
    "# General information\n",
    "console.print(f\"[cyan]Archive ID:[/cyan] {metadata['archive']['archive_id']}\")\n",
    "console.print(f\"[cyan]Created:[/cyan] {metadata['created_at'][:19]}\")\n",
    "console.print(f\"[cyan]Total Files:[/cyan] {metadata['inventory']['total_files']}\")\n",
    "console.print(f\"[cyan]Total Size:[/cyan] {metadata['inventory']['total_size'] / (1024*1024):.1f} MB\")\n",
    "\n",
    "# Content breakdown\n",
    "console.print(\"\\n[bold blue]üìÅ Files by Content Type[/bold blue]\")\n",
    "for content_type, count in metadata['inventory']['content_summary'].items():\n",
    "    console.print(f\"  [green]{content_type}:[/green] {count} files\")\n",
    "\n",
    "# Show a few example files\n",
    "console.print(\"\\n[bold blue]üìÑ Example Files[/bold blue]\")\n",
    "for file_info in metadata['inventory']['files'][:10]:  # Show first 10 files\n",
    "    size_str = f\"{file_info['size'] / 1024:.1f} KB\" if file_info['size'] > 1024 else f\"{file_info['size']} B\"\n",
    "    console.print(\n",
    "        f\"  [yellow]{file_info['path']}[/yellow] \"\n",
    "        f\"[dim]({size_str}, {file_info['content_type']}, {file_info['importance']})[/dim]\"\n",
    "    )\n",
    "\n",
    "if len(metadata['inventory']['files']) > 10:\n",
    "    console.print(f\"  [dim]... and {len(metadata['inventory']['files']) - 10} more files[/dim]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Listing Your Archives\n",
    "\n",
    "In a real workflow, you'll have multiple archives. Let's create another archive and see how to list them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a second archive with only the critical files\n",
    "console.print(\"[bold blue]Creating a 'Critical Files Only' archive...[/bold blue]\")\n",
    "console.print(\"[dim]This archive contains only files needed to restart the simulation[/dim]\")\n",
    "\n",
    "def create_critical_only_archive():\n",
    "    \"\"\"Create an archive with only critical files (configs + restart files)\"\"\"\n",
    "    \n",
    "    critical_archive_path = tutorial_dir / \"cesm_tutorial_critical.tar.gz\"\n",
    "    \n",
    "    with tarfile.open(critical_archive_path, \"w:gz\") as tar:\n",
    "        for file_path in cesm_dir.rglob('*'):\n",
    "            if file_path.is_file():\n",
    "                rel_path = file_path.relative_to(cesm_dir)\n",
    "                \n",
    "                # Only include critical files\n",
    "                is_critical = (\n",
    "                    rel_path.name.startswith('user_nl_') or  # CESM namelists\n",
    "                    'initial' in rel_path.name or           # Initial conditions\n",
    "                    '.r.' in rel_path.name                  # Restart files\n",
    "                )\n",
    "                \n",
    "                if is_critical:\n",
    "                    tar.add(file_path, arcname=rel_path)\n",
    "                    console.print(f\"  Added critical file: {rel_path}\")\n",
    "    \n",
    "    return critical_archive_path\n",
    "\n",
    "critical_archive = create_critical_only_archive()\n",
    "critical_size = critical_archive.stat().st_size / (1024 * 1024)\n",
    "\n",
    "console.print(f\"\\n[green]‚úÖ Critical archive created: {critical_archive.name} ({critical_size:.1f} MB)[/green]\")\n",
    "\n",
    "# Now let's \"list\" our archives (simulate what 'tellus archive list' would show)\n",
    "console.print(\"\\n[bold blue]üìö Your Archive Collection[/bold blue]\")\n",
    "console.print(\"=\" * 60)\n",
    "\n",
    "archives = [\n",
    "    {\n",
    "        'name': 'cesm_tutorial_complete',\n",
    "        'file': archive_file,\n",
    "        'description': 'Complete CESM simulation (all files)',\n",
    "        'content_types': ['INPUT', 'OUTPUT', 'RESTART', 'LOG', 'SCRIPT']\n",
    "    },\n",
    "    {\n",
    "        'name': 'cesm_tutorial_critical',\n",
    "        'file': critical_archive,\n",
    "        'description': 'Critical files only (restart capability)',\n",
    "        'content_types': ['INPUT', 'RESTART']\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, archive in enumerate(archives, 1):\n",
    "    size_mb = archive['file'].stat().st_size / (1024 * 1024)\n",
    "    content_str = ', '.join(archive['content_types'])\n",
    "    \n",
    "    console.print(f\"[cyan]{i}. {archive['name']}[/cyan]\")\n",
    "    console.print(f\"   Size: {size_mb:.1f} MB\")\n",
    "    console.print(f\"   Description: {archive['description']}\")\n",
    "    console.print(f\"   Content Types: {content_str}\")\n",
    "    console.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Understanding Archive Benefits\n",
    "\n",
    "Let's compare the space usage and organization benefits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.table import Table\n",
    "\n",
    "# Create a comparison table\n",
    "table = Table(title=\"Storage Comparison: Original vs. Archives\")\n",
    "table.add_column(\"Item\", style=\"cyan\")\n",
    "table.add_column(\"Size (MB)\", justify=\"right\", style=\"green\")\n",
    "table.add_column(\"Files\", justify=\"right\", style=\"yellow\")\n",
    "table.add_column(\"Notes\", style=\"dim\")\n",
    "\n",
    "# Original data\n",
    "original_files = len(list(cesm_dir.rglob('*')))\n",
    "table.add_row(\n",
    "    \"Original Directory\",\n",
    "    f\"{original_size:.1f}\",\n",
    "    str(original_files),\n",
    "    \"Uncompressed, scattered files\"\n",
    ")\n",
    "\n",
    "# Complete archive\n",
    "complete_size = archive_file.stat().st_size / (1024 * 1024)\n",
    "table.add_row(\n",
    "    \"Complete Archive\",\n",
    "    f\"{complete_size:.1f}\",\n",
    "    \"1\",\n",
    "    \"All files, compressed + metadata\"\n",
    ")\n",
    "\n",
    "# Critical archive\n",
    "critical_size = critical_archive.stat().st_size / (1024 * 1024)\n",
    "table.add_row(\n",
    "    \"Critical Archive\",\n",
    "    f\"{critical_size:.1f}\",\n",
    "    \"1\",\n",
    "    \"Essential files only\"\n",
    ")\n",
    "\n",
    "console.print(table)\n",
    "\n",
    "# Space savings\n",
    "total_savings = (original_size - complete_size) / original_size * 100\n",
    "critical_savings = (original_size - critical_size) / original_size * 100\n",
    "\n",
    "console.print(f\"\\n[bold green]üíæ Space Savings[/bold green]\")\n",
    "console.print(f\"Complete archive: {total_savings:.1f}% compression\")\n",
    "console.print(f\"Critical archive: {critical_savings:.1f}% space reduction\")\n",
    "\n",
    "console.print(f\"\\n[bold blue]üéØ Key Benefits[/bold blue]\")\n",
    "console.print(\"‚úÖ [green]Compression:[/green] Reduced storage space\")\n",
    "console.print(\"‚úÖ [green]Organization:[/green] Files automatically classified\")\n",
    "console.print(\"‚úÖ [green]Metadata:[/green] Know what's inside without extracting\")\n",
    "console.print(\"‚úÖ [green]Portability:[/green] Single file easy to transfer\")\n",
    "console.print(\"‚úÖ [green]Selective Access:[/green] Can extract only what you need\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Scenarios: When to Use Each Archive Type\n",
    "\n",
    "Understanding when to create different types of archives is crucial for effective data management:\n",
    "\n",
    "### Scenario 1: Long-term Storage\n",
    "**Use Case**: Moving old simulation to tape storage  \n",
    "**Archive Type**: Complete archive  \n",
    "**Why**: You want everything preserved for potential future analysis\n",
    "\n",
    "```bash\n",
    "# Complete archive for long-term storage\n",
    "tellus archive create simulation_2024_complete /path/to/simulation \\\n",
    "  --location tape_storage\n",
    "```\n",
    "\n",
    "### Scenario 2: Continuing a Simulation\n",
    "**Use Case**: Need to restart simulation on different machine  \n",
    "**Archive Type**: Critical files only  \n",
    "**Why**: Smaller, faster transfer, contains everything needed to restart\n",
    "\n",
    "```bash\n",
    "# Critical files for simulation restart\n",
    "tellus archive create restart_package /path/to/simulation \\\n",
    "  --content-types input,restart,config\n",
    "```\n",
    "\n",
    "### Scenario 3: Sharing Results\n",
    "**Use Case**: Collaborator wants to analyze your results  \n",
    "**Archive Type**: Output files only  \n",
    "**Why**: Scientists usually only need the output data, not restart files\n",
    "\n",
    "```bash\n",
    "# Output data for collaborators\n",
    "tellus archive create results_for_analysis /path/to/simulation \\\n",
    "  --content-types output --patterns \"*.nc\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Beginner Mistakes and How to Avoid Them\n",
    "\n",
    "### ‚ùå Mistake 1: Archiving Everything Always\n",
    "**Problem**: Creating huge archives with log files and temporary data  \n",
    "**Solution**: Use content type filtering to exclude non-essential files\n",
    "\n",
    "### ‚ùå Mistake 2: Not Checking Archive Contents\n",
    "**Problem**: Creating archive and not verifying what's inside  \n",
    "**Solution**: Always use `tellus archive show` to inspect archive metadata\n",
    "\n",
    "### ‚ùå Mistake 3: Forgetting to Test Extraction\n",
    "**Problem**: Archive is created but never tested for extraction  \n",
    "**Solution**: Always test extracting a few files to verify archive integrity\n",
    "\n",
    "### ‚ùå Mistake 4: Poor Archive Naming\n",
    "**Problem**: Using vague names like \"simulation1\", \"test_archive\"  \n",
    "**Solution**: Use descriptive names: \"cesm_f2000_spinup_2024\", \"wrf_hurricane_katrina_outputs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up tutorial files\n",
    "import shutil\n",
    "\n",
    "console.print(\"[bold blue]üßπ Cleaning up tutorial files...[/bold blue]\")\n",
    "shutil.rmtree(tutorial_dir)\n",
    "console.print(f\"[green]‚úÖ Cleaned up: {tutorial_dir}[/green]\")\n",
    "\n",
    "console.print(\"\\n[bold green]üéâ Tutorial 1 Complete![/bold green]\")\n",
    "console.print(\"\\n[bold blue]What You Learned:[/bold blue]\")\n",
    "console.print(\"‚úÖ How to create climate data archives\")\n",
    "console.print(\"‚úÖ Understanding file types and importance\")\n",
    "console.print(\"‚úÖ Reading archive metadata without extraction\")\n",
    "console.print(\"‚úÖ Comparing different archive strategies\")\n",
    "console.print(\"‚úÖ When to use complete vs. selective archives\")\n",
    "\n",
    "console.print(\"\\n[bold blue]Next Steps:[/bold blue]\")\n",
    "console.print(\"üìö [cyan]Tutorial 2:[/cyan] Content Classification and Selective Archiving\")\n",
    "console.print(\"üìö [cyan]Tutorial 3:[/cyan] DateTime-Based Extraction and Filtering\")\n",
    "console.print(\"üìö [cyan]Tutorial 4:[/cyan] Fragment Assembly for Multi-Period Simulations\")\n",
    "\n",
    "console.print(\"\\n[dim]Ready to continue? Open Tutorial 2 to learn about smart file filtering![/dim]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree: Archive Strategy Selection\n",
    "\n",
    "Use this flowchart to decide what type of archive to create:\n",
    "\n",
    "```\n",
    "üìä What's your goal?\n",
    "‚îú‚îÄ‚îÄ üéØ Continue simulation later?\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ‚úÖ Create CRITICAL archive (configs + restart files)\n",
    "‚îú‚îÄ‚îÄ üì§ Share results with collaborators?\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ‚úÖ Create OUTPUT archive (scientific data only)\n",
    "‚îú‚îÄ‚îÄ üíæ Long-term storage/backup?\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ‚úÖ Create COMPLETE archive (everything)\n",
    "‚îú‚îÄ‚îÄ üöÄ Moving to faster storage?\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ‚úÖ Create IMPORTANT archive (exclude logs/temp files)\n",
    "‚îî‚îÄ‚îÄ üîç Not sure?\n",
    "    ‚îî‚îÄ‚îÄ ‚úÖ Start with COMPLETE, extract selectively later\n",
    "```\n",
    "\n",
    "## Key Commands Reference\n",
    "\n",
    "```bash\n",
    "# Create complete archive\n",
    "tellus archive create my_simulation /path/to/data --location storage_location\n",
    "\n",
    "# List all archives\n",
    "tellus archive list\n",
    "\n",
    "# Show archive details\n",
    "tellus archive show my_simulation\n",
    "\n",
    "# Create selective archive\n",
    "tellus archive create critical_files /path/to/data \\\n",
    "  --content-types input,restart,config\n",
    "```\n",
    "\n",
    "**üéØ You're now ready to create and manage climate data archives! Continue to Tutorial 2 to learn about intelligent file classification and selective archiving strategies.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
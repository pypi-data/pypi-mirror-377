{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Climate Data Management with Tellus\n",
    "\n",
    "This notebook demonstrates how to use Tellus for personal climate research data management. You'll learn how to:\n",
    "\n",
    "- Set up storage locations for your local and remote data\n",
    "- Create simulations to organize model experiments\n",
    "- Transfer files between storage locations\n",
    "- Use context-aware path templating\n",
    "- Monitor progress of long-running operations\n",
    "\n",
    "## User Story: Graduate Student Climate Research\n",
    "\n",
    "**Meet Sarah**: A graduate student studying climate variability using CESM2 model outputs. She needs to:\n",
    "- Organize simulation data from multiple experiments\n",
    "- Transfer large datasets between her laptop, university cluster, and archive storage\n",
    "- Keep track of what data is stored where\n",
    "- Share specific datasets with her advisor and collaborators\n",
    "\n",
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "# For this tutorial, we'll work with the Tellus CLI and Python API\n",
    "from tellus.application.container import get_service_container\n",
    "from tellus.application.dtos import (\n",
    "    CreateLocationDto,\n",
    "    CreateSimulationDto,\n",
    "    FileTransferOperationDto,\n",
    "    SimulationLocationAssociationDto\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Tellus modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Test Environment\n",
    "\n",
    "For this tutorial, we'll create temporary directories to simulate Sarah's data environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary directories for our example\n",
    "base_dir = Path(tempfile.mkdtemp(prefix=\"sarah_climate_data_\"))\n",
    "print(f\"üìÅ Working in: {base_dir}\")\n",
    "\n",
    "# Sarah's data organization\n",
    "directories = {\n",
    "    'laptop_data': base_dir / \"laptop\" / \"climate_data\",\n",
    "    'university_cluster': base_dir / \"cluster\" / \"scratch\" / \"sarah\",\n",
    "    'archive_storage': base_dir / \"archive\" / \"climate_research\",\n",
    "    'shared_data': base_dir / \"shared\" / \"sarah_experiments\"\n",
    "}\n",
    "\n",
    "# Create directory structure\n",
    "for name, path in directories.items():\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"üìÇ Created {name}: {path}\")\n",
    "\n",
    "# Create some sample climate data files\n",
    "sample_files = {\n",
    "    'model_output_monthly': {\n",
    "        'path': directories['laptop_data'] / \"cesm2_monthly_2020.nc\",\n",
    "        'content': \"# NetCDF: Monthly CESM2 output for 2020\\n# Variables: tas, pr, psl\\n# Resolution: 1-degree\\n\" + \"x\" * 1024 * 100  # ~100KB\n",
    "    },\n",
    "    'model_output_daily': {\n",
    "        'path': directories['laptop_data'] / \"cesm2_daily_2020_q1.nc\",\n",
    "        'content': \"# NetCDF: Daily CESM2 output for Q1 2020\\n# Variables: tas, pr\\n# Resolution: 1-degree\\n\" + \"x\" * 1024 * 500  # ~500KB\n",
    "    },\n",
    "    'analysis_script': {\n",
    "        'path': directories['laptop_data'] / \"analysis_temperature_trends.py\",\n",
    "        'content': '''#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Temperature trend analysis for CESM2 historical simulation.\n",
    "Author: Sarah (Graduate Student)\n",
    "\"\"\"\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_temperature_trends(input_file, output_dir):\n",
    "    \"\"\"Analyze temperature trends from CESM2 output.\"\"\"\n",
    "    # Load data\n",
    "    ds = xr.open_dataset(input_file)\n",
    "    \n",
    "    # Calculate global mean temperature\n",
    "    global_temp = ds.tas.weighted(ds.area).mean(dim=['lat', 'lon'])\n",
    "    \n",
    "    # Compute trend\n",
    "    trend = global_temp.polyfit(dim='time', deg=1)\n",
    "    \n",
    "    # Save results\n",
    "    trend.to_netcdf(output_dir / \"temperature_trend.nc\")\n",
    "    \n",
    "    return trend\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_temperature_trends(\"cesm2_monthly_2020.nc\", \"./analysis_output\")\n",
    "'''\n",
    "    },\n",
    "    'config_file': {\n",
    "        'path': directories['laptop_data'] / \"cesm2_config.yaml\",\n",
    "        'content': '''# CESM2 Configuration for Historical Simulation\n",
    "experiment:\n",
    "  name: \"historical_2020_analysis\"\n",
    "  description: \"Temperature trend analysis for thesis chapter 3\"\n",
    "  start_date: \"2020-01-01\"\n",
    "  end_date: \"2020-12-31\"\n",
    "  \n",
    "model:\n",
    "  name: \"CESM2\"\n",
    "  version: \"2.1.3\"\n",
    "  resolution: \"f09_g17\"  # ~1-degree atmosphere, ~1-degree ocean\n",
    "  \n",
    "output:\n",
    "  frequency: [\"monthly\", \"daily\"]\n",
    "  variables: [\"tas\", \"pr\", \"psl\"]\n",
    "  format: \"netcdf4\"\n",
    "  \n",
    "paths:\n",
    "  input_data: \"/glade/p/cesm/cseg/inputdata\"\n",
    "  case_root: \"/glade/work/sarah/cesm_cases\"\n",
    "  archive_root: \"/glade/scratch/sarah/archive\"\n",
    "'''\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write sample files\n",
    "for name, file_info in sample_files.items():\n",
    "    file_info['path'].write_text(file_info['content'])\n",
    "    size_mb = len(file_info['content']) / 1024 / 1024\n",
    "    print(f\"üìÑ Created {name}: {file_info['path'].name} ({size_mb:.1f} MB)\")\n",
    "\n",
    "print(f\"\\nüéØ Sarah's test environment ready with {len(sample_files)} sample files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Configure Storage Locations\n",
    "\n",
    "Sarah needs to configure her storage locations so Tellus knows where her data can be stored and accessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the service container\n",
    "service_container = get_service_container()\n",
    "location_service = service_container.service_factory.location_service\n",
    "\n",
    "# Configure Sarah's storage locations\n",
    "locations = [\n",
    "    {\n",
    "        'name': 'laptop-storage',\n",
    "        'description': 'Local laptop storage for active analysis',\n",
    "        'dto': CreateLocationDto(\n",
    "            name=\"laptop-storage\",\n",
    "            kinds=[\"DISK\"],\n",
    "            protocol=\"file\",\n",
    "            path=str(directories['laptop_data']),\n",
    "            optional=False,\n",
    "            additional_config={\n",
    "                'description': 'Local laptop storage for active analysis',\n",
    "                'capacity_gb': 500,\n",
    "                'access_speed': 'high'\n",
    "            }\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        'name': 'university-cluster',\n",
    "        'description': 'University HPC cluster scratch space',\n",
    "        'dto': CreateLocationDto(\n",
    "            name=\"university-cluster\",\n",
    "            kinds=[\"COMPUTE\", \"DISK\"],\n",
    "            protocol=\"ssh\",\n",
    "            path=\"/scratch/sarah\",\n",
    "            storage_options={\n",
    "                'host': 'hpc.university.edu',\n",
    "                'username': 'sarah',\n",
    "                'key_filename': '/home/sarah/.ssh/hpc_key'\n",
    "            },\n",
    "            optional=True,\n",
    "            additional_config={\n",
    "                'description': 'University HPC cluster scratch space',\n",
    "                'capacity_tb': 10,\n",
    "                'purge_policy': 'auto_30_days'\n",
    "            }\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        'name': 'archive-storage', \n",
    "        'description': 'Long-term archive for completed experiments',\n",
    "        'dto': CreateLocationDto(\n",
    "            name=\"archive-storage\",\n",
    "            kinds=[\"TAPE\", \"DISK\"],\n",
    "            protocol=\"file\",  # Simulated as local for tutorial\n",
    "            path=str(directories['archive_storage']),\n",
    "            optional=True,\n",
    "            additional_config={\n",
    "                'description': 'Long-term archive for completed experiments',\n",
    "                'retention_years': 10,\n",
    "                'compression': 'gzip'\n",
    "            }\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        'name': 'shared-data',\n",
    "        'description': 'Shared space for collaboration with advisor',\n",
    "        'dto': CreateLocationDto(\n",
    "            name=\"shared-data\",\n",
    "            kinds=[\"FILESERVER\"],\n",
    "            protocol=\"file\",  # Simulated as local for tutorial\n",
    "            path=str(directories['shared_data']),\n",
    "            optional=True,\n",
    "            additional_config={\n",
    "                'description': 'Shared space for collaboration with advisor',\n",
    "                'access_permissions': 'group_rw',\n",
    "                'quota_gb': 100\n",
    "            }\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create all locations\n",
    "created_locations = []\n",
    "for loc_config in locations:\n",
    "    try:\n",
    "        location = location_service.create_location(loc_config['dto'])\n",
    "        created_locations.append(location)\n",
    "        print(f\"‚úÖ Created location: {loc_config['name']} - {loc_config['description']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Failed to create {loc_config['name']}: {e}\")\n",
    "\n",
    "print(f\"\\nüìç Successfully configured {len(created_locations)} storage locations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Simulation Experiments\n",
    "\n",
    "Sarah organizes her work into simulation experiments, each representing a specific research question or model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get simulation service\n",
    "simulation_service = service_container.service_factory.simulation_service\n",
    "\n",
    "# Sarah's simulation experiments\n",
    "simulations = [\n",
    "    {\n",
    "        'id': 'sarah-historical-2020',\n",
    "        'description': 'Historical simulation analysis for 2020 (thesis chapter 3)',\n",
    "        'dto': CreateSimulationDto(\n",
    "            simulation_id=\"sarah-historical-2020\",\n",
    "            model_id=\"CESM2\",\n",
    "            path=\"/analysis/historical_2020\",\n",
    "            attrs={\n",
    "                'experiment': 'historical',\n",
    "                'year': '2020',\n",
    "                'model': 'CESM2',\n",
    "                'resolution': 'f09_g17',\n",
    "                'purpose': 'thesis_chapter_3',\n",
    "                'researcher': 'sarah',\n",
    "                'status': 'active',\n",
    "                'variables': 'tas,pr,psl',\n",
    "                'frequency': 'monthly,daily'\n",
    "            },\n",
    "            namelists={\n",
    "                'atm_in': {'nhtfrq': [0, -24], 'mfilt': [12, 365]},\n",
    "                'ocn_in': {'tavg_freq_opt': 'nmonth', 'tavg_freq': 1}\n",
    "            },\n",
    "            snakemakes={\n",
    "                'analysis_workflow': 'workflows/temperature_analysis.smk',\n",
    "                'data_processing': 'workflows/cesm_postprocess.smk'\n",
    "            }\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        'id': 'sarah-sensitivity-co2',\n",
    "        'description': 'CO2 sensitivity experiments for methodology paper',\n",
    "        'dto': CreateSimulationDto(\n",
    "            simulation_id=\"sarah-sensitivity-co2\",\n",
    "            model_id=\"CESM2\",\n",
    "            path=\"/analysis/co2_sensitivity\",\n",
    "            attrs={\n",
    "                'experiment': 'sensitivity',\n",
    "                'forcing': 'co2_2x,co2_4x',\n",
    "                'model': 'CESM2',\n",
    "                'resolution': 'f09_g17',\n",
    "                'purpose': 'methodology_paper',\n",
    "                'researcher': 'sarah',\n",
    "                'status': 'planning',\n",
    "                'duration_years': '50',\n",
    "                'ensemble_size': '3'\n",
    "            }\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create simulations\n",
    "created_simulations = []\n",
    "for sim_config in simulations:\n",
    "    try:\n",
    "        simulation = simulation_service.create_simulation(sim_config['dto'])\n",
    "        created_simulations.append(simulation)\n",
    "        print(f\"üéØ Created simulation: {sim_config['id']} - {sim_config['description']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Failed to create {sim_config['id']}: {e}\")\n",
    "\n",
    "print(f\"\\nüî¨ Successfully created {len(created_simulations)} simulation experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Associate Simulations with Storage Locations\n",
    "\n",
    "Now Sarah connects her simulations with storage locations, setting up path templates for organized data management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate historical simulation with multiple storage locations\n",
    "historical_associations = [\n",
    "    {\n",
    "        'location': 'laptop-storage',\n",
    "        'context': {\n",
    "            'path_prefix': '{{researcher}}/{{experiment}}/{{year}}',\n",
    "            'file_pattern': '{{model}}_{{frequency}}_{{year}}.nc',\n",
    "            'usage': 'active_analysis'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'location': 'university-cluster',\n",
    "        'context': {\n",
    "            'path_prefix': '{{model}}/{{experiment}}/{{resolution}}',\n",
    "            'compute_allocation': 'climate_group',\n",
    "            'usage': 'model_runs'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'location': 'archive-storage',\n",
    "        'context': {\n",
    "            'path_prefix': '{{researcher}}/{{purpose}}/{{experiment}}_{{year}}',\n",
    "            'compression': 'gzip',\n",
    "            'usage': 'long_term_storage'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'location': 'shared-data',\n",
    "        'context': {\n",
    "            'path_prefix': '{{researcher}}/{{purpose}}/results',\n",
    "            'access': 'advisor_group',\n",
    "            'usage': 'collaboration'\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create association DTO\n",
    "association_dto = SimulationLocationAssociationDto(\n",
    "    simulation_id=\"sarah-historical-2020\",\n",
    "    location_names=[assoc['location'] for assoc in historical_associations],\n",
    "    context_overrides={assoc['location']: assoc['context'] for assoc in historical_associations}\n",
    ")\n",
    "\n",
    "try:\n",
    "    updated_simulation = simulation_service.associate_simulation_with_locations(association_dto)\n",
    "    print(f\"üîó Associated simulation with {len(historical_associations)} storage locations\")\n",
    "    \n",
    "    # Show resolved paths\n",
    "    print(\"\\nüìÅ Resolved storage paths:\")\n",
    "    for assoc in historical_associations:\n",
    "        location_name = assoc['location']\n",
    "        # Simulate path resolution (would normally use simulation context)\n",
    "        template = assoc['context'].get('path_prefix', '')\n",
    "        # Simple template substitution for demo\n",
    "        resolved = template.replace('{{researcher}}', 'sarah') \\\n",
    "                          .replace('{{experiment}}', 'historical') \\\n",
    "                          .replace('{{year}}', '2020') \\\n",
    "                          .replace('{{model}}', 'CESM2') \\\n",
    "                          .replace('{{purpose}}', 'thesis_chapter_3') \\\n",
    "                          .replace('{{resolution}}', 'f09_g17')\n",
    "        print(f\"  üìÇ {location_name}: {resolved}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Failed to associate locations: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Simulation-location associations configured successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: File Transfer Operations\n",
    "\n",
    "Sarah needs to move data between her storage locations. Let's demonstrate transferring analysis results to the shared collaboration space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file transfer service\n",
    "file_transfer_service = service_container.service_factory.file_transfer_service\n",
    "\n",
    "# Create destination directories\n",
    "laptop_analysis_dir = directories['laptop_data'] / \"analysis_output\"\n",
    "laptop_analysis_dir.mkdir(exist_ok=True)\n",
    "\n",
    "shared_results_dir = directories['shared_data'] / \"sarah\" / \"thesis_chapter_3\" / \"results\"\n",
    "shared_results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Simulate creating analysis results\n",
    "analysis_files = {\n",
    "    'temperature_trends.png': '''# Matplotlib figure data (simulated)\n",
    "# Global temperature trends from CESM2 historical simulation\n",
    "# Shows 2020 monthly temperature anomalies\n",
    "# Generated by: analysis_temperature_trends.py\n",
    "PNG_DATA_PLACEHOLDER''' + \"x\" * 1024 * 50,  # ~50KB\n",
    "    \n",
    "    'temperature_trend_coefficients.nc': '''# NetCDF: Temperature trend analysis results\n",
    "# Variables: trend_slope, trend_intercept, r_squared, p_value\n",
    "# Dimensions: lat, lon\n",
    "# Source: CESM2 historical simulation 2020\n",
    "NETCDF_DATA_PLACEHOLDER''' + \"x\" * 1024 * 200,  # ~200KB\n",
    "    \n",
    "    'analysis_summary.txt': '''Climate Analysis Summary - Sarah's Thesis Chapter 3\n",
    "========================================================\n",
    "\n",
    "Experiment: Historical 2020 Temperature Trends\n",
    "Model: CESM2 (f09_g17 resolution)\n",
    "Analysis Period: January 2020 - December 2020\n",
    "Variables: Surface Air Temperature (tas)\n",
    "\n",
    "Key Findings:\n",
    "- Global mean temperature shows warming trend of +0.15K/decade\n",
    "- Arctic amplification clearly visible in spatial patterns\n",
    "- Strong correlation with observed trends (r=0.89, p<0.001)\n",
    "\n",
    "Files Generated:\n",
    "- temperature_trends.png: Visualization of spatial trends\n",
    "- temperature_trend_coefficients.nc: Gridded trend coefficients\n",
    "- monthly_timeseries.nc: Monthly temperature timeseries\n",
    "\n",
    "Next Steps:\n",
    "- Compare with CMIP6 ensemble\n",
    "- Analyze seasonal variations\n",
    "- Write manuscript section\n",
    "\n",
    "Generated: {date}\n",
    "Contact: sarah@university.edu\n",
    "'''.format(date=\"2024-01-15\")\n",
    "}\n",
    "\n",
    "# Create analysis result files\n",
    "analysis_file_paths = []\n",
    "for filename, content in analysis_files.items():\n",
    "    file_path = laptop_analysis_dir / filename\n",
    "    file_path.write_text(content)\n",
    "    analysis_file_paths.append(file_path)\n",
    "    size_kb = len(content) / 1024\n",
    "    print(f\"üìä Created analysis result: {filename} ({size_kb:.1f} KB)\")\n",
    "\n",
    "print(f\"\\nüî¨ Analysis complete! Generated {len(analysis_files)} result files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Results to Shared Space\n",
    "\n",
    "Now let's transfer Sarah's analysis results to the shared collaboration space where her advisor can access them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file transfer operations\n",
    "transfer_operations = []\n",
    "\n",
    "for file_path in analysis_file_paths:\n",
    "    dest_path = shared_results_dir / file_path.name\n",
    "    \n",
    "    transfer_dto = FileTransferOperationDto(\n",
    "        source_location=\"laptop-storage\",\n",
    "        source_path=str(file_path),\n",
    "        dest_location=\"shared-data\", \n",
    "        dest_path=str(dest_path),\n",
    "        overwrite=True,\n",
    "        verify_checksum=True,\n",
    "        metadata={\n",
    "            'simulation_id': 'sarah-historical-2020',\n",
    "            'file_type': 'analysis_result',\n",
    "            'generated_by': 'analysis_temperature_trends.py',\n",
    "            'purpose': 'thesis_chapter_3'\n",
    "        }\n",
    "    )\n",
    "    transfer_operations.append(transfer_dto)\n",
    "\n",
    "print(f\"üì¶ Prepared {len(transfer_operations)} file transfer operations\")\n",
    "\n",
    "# Execute transfers (simulated - in real usage these would be async operations)\n",
    "successful_transfers = 0\n",
    "total_bytes = 0\n",
    "\n",
    "for i, transfer_dto in enumerate(transfer_operations, 1):\n",
    "    try:\n",
    "        # Simulate transfer by copying file\n",
    "        source_path = Path(transfer_dto.source_path)\n",
    "        dest_path = Path(transfer_dto.dest_path)\n",
    "        \n",
    "        # Ensure destination directory exists\n",
    "        dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Copy file\n",
    "        import shutil\n",
    "        shutil.copy2(source_path, dest_path)\n",
    "        \n",
    "        # Track progress\n",
    "        file_size = source_path.stat().st_size\n",
    "        total_bytes += file_size\n",
    "        successful_transfers += 1\n",
    "        \n",
    "        progress = (i / len(transfer_operations)) * 100\n",
    "        print(f\"  ‚¨ÜÔ∏è  [{progress:5.1f}%] {source_path.name} ‚Üí shared-data ({file_size:,} bytes)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Failed to transfer {source_path.name}: {e}\")\n",
    "\n",
    "total_mb = total_bytes / 1024 / 1024\n",
    "print(f\"\\n‚úÖ Transfer complete! {successful_transfers}/{len(transfer_operations)} files transferred ({total_mb:.2f} MB)\")\n",
    "\n",
    "# Verify transfers\n",
    "print(\"\\nüîç Verifying shared space contents:\")\n",
    "for file_path in shared_results_dir.rglob('*'):\n",
    "    if file_path.is_file():\n",
    "        size_kb = file_path.stat().st_size / 1024\n",
    "        print(f\"  üìÑ {file_path.name} ({size_kb:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Data Discovery and Organization\n",
    "\n",
    "Sarah can now easily find and track her data across all storage locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all simulations\n",
    "print(\"üî¨ Sarah's Simulation Experiments:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "sim_list_result = simulation_service.list_simulations()\n",
    "for sim in sim_list_result.simulations:\n",
    "    status = sim.attrs.get('status', 'unknown')\n",
    "    purpose = sim.attrs.get('purpose', 'general')\n",
    "    model = sim.attrs.get('model', 'unknown')\n",
    "    \n",
    "    status_emoji = {'active': 'üü¢', 'planning': 'üü°', 'completed': '‚úÖ', 'archived': 'üì¶'}.get(status, '‚ö™')\n",
    "    \n",
    "    print(f\"\\n{status_emoji} {sim.simulation_id}\")\n",
    "    print(f\"   Model: {model}\")\n",
    "    print(f\"   Purpose: {purpose.replace('_', ' ').title()}\")\n",
    "    print(f\"   Status: {status.title()}\")\n",
    "    \n",
    "    # Show key attributes\n",
    "    if sim.attrs:\n",
    "        key_attrs = ['experiment', 'year', 'resolution', 'variables']\n",
    "        attr_display = []\n",
    "        for attr in key_attrs:\n",
    "            if attr in sim.attrs:\n",
    "                attr_display.append(f\"{attr}={sim.attrs[attr]}\")\n",
    "        if attr_display:\n",
    "            print(f\"   Details: {', '.join(attr_display)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all storage locations\n",
    "print(\"\\nüìç Sarah's Storage Locations:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "loc_list_result = location_service.list_locations()\n",
    "for loc in loc_list_result.locations:\n",
    "    # Get location kinds\n",
    "    kinds = ', '.join(loc.kinds) if loc.kinds else 'Unknown'\n",
    "    \n",
    "    # Determine icon based on kinds\n",
    "    if 'DISK' in kinds:\n",
    "        icon = 'üíΩ'\n",
    "    elif 'COMPUTE' in kinds:\n",
    "        icon = 'üñ•Ô∏è'\n",
    "    elif 'TAPE' in kinds:\n",
    "        icon = 'üìº'\n",
    "    elif 'FILESERVER' in kinds:\n",
    "        icon = 'üóÑÔ∏è'\n",
    "    else:\n",
    "        icon = 'üìÅ'\n",
    "    \n",
    "    print(f\"\\n{icon} {loc.name}\")\n",
    "    print(f\"   Protocol: {loc.protocol}\")\n",
    "    print(f\"   Types: {kinds}\")\n",
    "    print(f\"   Path: {loc.path or 'Not specified'}\")\n",
    "    \n",
    "    # Show additional config if available\n",
    "    if hasattr(loc, 'additional_config') and loc.additional_config:\n",
    "        description = loc.additional_config.get('description')\n",
    "        if description:\n",
    "            print(f\"   Description: {description}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Real-World CLI Usage\n",
    "\n",
    "In practice, Sarah would use the Tellus CLI commands for most operations. Here are the equivalent commands for what we've done in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display CLI command equivalents\n",
    "cli_commands = {\n",
    "    \"üìç Location Management\": [\n",
    "        \"# Create storage locations\",\n",
    "        \"tellus location create laptop-storage --kind DISK --protocol file --path /home/sarah/climate_data\",\n",
    "        \"tellus location create university-cluster --kind COMPUTE,DISK --protocol ssh --path /scratch/sarah\",\n",
    "        \"tellus location create archive-storage --kind TAPE,DISK --protocol file --path /archive/sarah\",\n",
    "        \"\",\n",
    "        \"# List all locations\", \n",
    "        \"tellus location list\",\n",
    "        \"\",\n",
    "        \"# Show detailed location info\",\n",
    "        \"tellus location show laptop-storage\"\n",
    "    ],\n",
    "    \n",
    "    \"üî¨ Simulation Management\": [\n",
    "        \"# Create a new simulation\",\n",
    "        \"tellus simulation create sarah-historical-2020 --model CESM2 \\\\\",\n",
    "        \"  --attr experiment=historical --attr year=2020 --attr purpose=thesis_chapter_3\",\n",
    "        \"\",\n",
    "        \"# List all simulations\",\n",
    "        \"tellus simulation list\",\n",
    "        \"\",\n",
    "        \"# Show simulation details\",\n",
    "        \"tellus simulation show sarah-historical-2020\",\n",
    "        \"\",\n",
    "        \"# Associate simulation with storage location\",\n",
    "        \"tellus simulation add-location sarah-historical-2020 laptop-storage\"\n",
    "    ],\n",
    "    \n",
    "    \"üì¶ File Transfer Operations\": [\n",
    "        \"# Transfer single file\",\n",
    "        \"tellus transfer file temperature_trends.png \\\\\",\n",
    "        \"  --source laptop-storage --dest shared-data \\\\\",\n",
    "        \"  --dest-path sarah/thesis_chapter_3/results/\",\n",
    "        \"\",\n",
    "        \"# Transfer multiple files\",\n",
    "        \"tellus transfer batch analysis_output/ \\\\\",\n",
    "        \"  --source laptop-storage --dest shared-data \\\\\",\n",
    "        \"  --pattern '*.png,*.nc' --verify-checksum\",\n",
    "        \"\",\n",
    "        \"# Monitor transfer progress\",\n",
    "        \"tellus progress list-operations\",\n",
    "        \"tellus progress monitor <operation-id>\"\n",
    "    ],\n",
    "    \n",
    "    \"üéØ Workflow Integration\": [\n",
    "        \"# Add Snakemake workflow to simulation\",\n",
    "        \"tellus simulation add-snakemake sarah-historical-2020 \\\\\",\n",
    "        \"  analysis_workflow workflows/temperature_analysis.smk\",\n",
    "        \"\",\n",
    "        \"# Archive completed simulation\",\n",
    "        \"tellus archive create sarah-historical-2020-results \\\\\",\n",
    "        \"  --simulation sarah-historical-2020 --location archive-storage\",\n",
    "        \"\",\n",
    "        \"# Extract archived data when needed\",\n",
    "        \"tellus archive extract sarah-historical-2020-results \\\\\",\n",
    "        \"  --dest laptop-storage --simulation sarah-historical-2020\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"üíª Equivalent CLI Commands:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for section, commands in cli_commands.items():\n",
    "    print(f\"\\n{section}\")\n",
    "    print(\"-\" * 40)\n",
    "    for cmd in commands:\n",
    "        if cmd.startswith(\"#\"):\n",
    "            print(f\"\\n{cmd}\")\n",
    "        elif cmd == \"\":\n",
    "            print()\n",
    "        else:\n",
    "            print(f\"$ {cmd}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Sarah's Tellus Workflow\n",
    "\n",
    "Through this tutorial, Sarah has set up a complete climate data management system with Tellus:\n",
    "\n",
    "### ‚úÖ What Sarah Accomplished:\n",
    "\n",
    "1. **Configured Multiple Storage Locations**\n",
    "   - Local laptop storage for active analysis\n",
    "   - University HPC cluster for computation\n",
    "   - Archive storage for long-term preservation\n",
    "   - Shared space for collaboration\n",
    "\n",
    "2. **Organized Research into Simulations**\n",
    "   - Historical 2020 analysis (thesis chapter 3)\n",
    "   - CO2 sensitivity experiments (methodology paper)\n",
    "   - Rich metadata and context for each experiment\n",
    "\n",
    "3. **Established Data Flow Patterns**\n",
    "   - Path templating for organized data layout\n",
    "   - Location associations with context-aware routing\n",
    "   - Automated file transfer with progress tracking\n",
    "\n",
    "4. **Enabled Collaboration**\n",
    "   - Shared space with advisor access\n",
    "   - Structured result organization\n",
    "   - Metadata for data provenance\n",
    "\n",
    "### üöÄ Next Steps for Sarah:\n",
    "\n",
    "- **Automate Workflows**: Integrate with Snakemake for analysis pipelines\n",
    "- **Scale Operations**: Use batch transfers for large datasets\n",
    "- **Archive Management**: Create compressed archives for completed experiments\n",
    "- **Team Collaboration**: Share location configurations with lab members\n",
    "- **Monitoring**: Set up alerts for long-running transfers\n",
    "\n",
    "### üí° Key Benefits:\n",
    "\n",
    "- **Centralized Management**: Single interface for all storage locations\n",
    "- **Automated Organization**: Path templating reduces manual file management\n",
    "- **Progress Tracking**: Monitor long-running operations\n",
    "- **Collaboration Ready**: Easy sharing with team members\n",
    "- **Scalable**: Works from personal projects to large research collaborations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup temporary environment\n",
    "import shutil\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(base_dir)\n",
    "    print(f\"üßπ Cleaned up tutorial environment: {base_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not clean up {base_dir}: {e}\")\n",
    "\n",
    "print(\"\\nüéâ Tutorial complete! Sarah is ready to manage her climate data with Tellus.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
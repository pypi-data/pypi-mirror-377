from .tokenizer_utils import *
from unsloth_zoo.dataset_utils import standardize_data_formats as standardize_data_formats, train_on_responses_only as train_on_responses_only

__all__ = ['get_chat_template', 'test_chat_templates', 'test_hf_gguf_equivalence', 'remove_special_tokens', 'to_sharegpt', 'standardize_sharegpt', 'standardize_data_formats', 'apply_chat_template', 'train_on_responses_only', 'test_construct_chat_template']

standardize_sharegpt = standardize_data_formats
gemma2_template = gemma_template
gemma2_chatml_template = gemma_chatml_template
gemma2_chatml_eos_token = gemma_chatml_eos_token

def get_chat_template(tokenizer, chat_template: str = 'chatml', mapping={'role': 'role', 'content': 'content', 'user': 'user', 'assistant': 'assistant'}, map_eos_token: bool = True, system_message=None): ...
def remove_special_tokens(tokenizer, prompt): ...
def to_sharegpt(dataset, merged_prompt: str = '', merged_column_name: str = 'instruction', output_column_name: str = 'output', remove_unused_columns: bool = True, conversation_extension: int = 1, random_state: int = 3407): ...
def test_construct_chat_template() -> None: ...
def apply_chat_template(dataset, tokenizer=None, chat_template: str = ..., default_system_message: str = 'Below are some instructions that describe some tasks. Write responses that appropriately complete each request.', extra_eos_tokens=None): ...
def test_chat_templates() -> None: ...
def test_hf_gguf_equivalence(tokenizer, gguf_model: str = './model-unsloth.F16.gguf'): ...

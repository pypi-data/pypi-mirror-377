{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Intro](https://github.com/Ziaeemehr/vbi_paper/blob/main/docs/examples/intro.ipynb)\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/Ziaeemehr/vbi_paper/blob/main/docs/examples/intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Integrating: 100%|██████████| 1500/1500 [00:07<00:00, 204.70it/s]\n",
      "Integrating: 100%|██████████| 1500/1500 [00:00<00:00, 2459.72it/s]\n",
      "Integrating: 100%|██████████| 11999/11999 [00:02<00:00, 4653.43it/s]\n",
      "----------------------------------------------------------------------\n",
      "Ran 108 tests in 27.541s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9908645365510211\n"
     ]
    }
   ],
   "source": [
    "vbi.tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">             Dependency Check              </span>\n",
       "                                           \n",
       " <span style=\"font-weight: bold\"> Package    </span> <span style=\"font-weight: bold\"> Version     </span> <span style=\"font-weight: bold\"> Status       </span> \n",
       " ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> vbi        </span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> v0.2        </span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ✅ Available </span> \n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> numpy      </span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> 1.26.4      </span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ✅ Available </span> \n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> scipy      </span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> 1.15.2      </span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ✅ Available </span> \n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> matplotlib </span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> 3.10.0      </span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ✅ Available </span> \n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> sbi        </span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> 0.23.3      </span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ✅ Available </span> \n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> torch      </span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> 2.6.0+cu124 </span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ✅ Available </span> \n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> cupy       </span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> 13.3.0      </span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ✅ Available </span> \n",
       "                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m             Dependency Check              \u001b[0m\n",
       "                                           \n",
       " \u001b[1m \u001b[0m\u001b[1mPackage   \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mVersion    \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStatus      \u001b[0m\u001b[1m \u001b[0m \n",
       " ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
       " \u001b[1;36m \u001b[0m\u001b[1;36mvbi       \u001b[0m\u001b[1;36m \u001b[0m \u001b[1;32m \u001b[0m\u001b[1;32mv0.2       \u001b[0m\u001b[1;32m \u001b[0m \u001b[1;33m \u001b[0m\u001b[1;33m✅ Available\u001b[0m\u001b[1;33m \u001b[0m \n",
       " \u001b[1;36m \u001b[0m\u001b[1;36mnumpy     \u001b[0m\u001b[1;36m \u001b[0m \u001b[1;32m \u001b[0m\u001b[1;32m1.26.4     \u001b[0m\u001b[1;32m \u001b[0m \u001b[1;33m \u001b[0m\u001b[1;33m✅ Available\u001b[0m\u001b[1;33m \u001b[0m \n",
       " \u001b[1;36m \u001b[0m\u001b[1;36mscipy     \u001b[0m\u001b[1;36m \u001b[0m \u001b[1;32m \u001b[0m\u001b[1;32m1.15.2     \u001b[0m\u001b[1;32m \u001b[0m \u001b[1;33m \u001b[0m\u001b[1;33m✅ Available\u001b[0m\u001b[1;33m \u001b[0m \n",
       " \u001b[1;36m \u001b[0m\u001b[1;36mmatplotlib\u001b[0m\u001b[1;36m \u001b[0m \u001b[1;32m \u001b[0m\u001b[1;32m3.10.0     \u001b[0m\u001b[1;32m \u001b[0m \u001b[1;33m \u001b[0m\u001b[1;33m✅ Available\u001b[0m\u001b[1;33m \u001b[0m \n",
       " \u001b[1;36m \u001b[0m\u001b[1;36msbi       \u001b[0m\u001b[1;36m \u001b[0m \u001b[1;32m \u001b[0m\u001b[1;32m0.23.3     \u001b[0m\u001b[1;32m \u001b[0m \u001b[1;33m \u001b[0m\u001b[1;33m✅ Available\u001b[0m\u001b[1;33m \u001b[0m \n",
       " \u001b[1;36m \u001b[0m\u001b[1;36mtorch     \u001b[0m\u001b[1;36m \u001b[0m \u001b[1;32m \u001b[0m\u001b[1;32m2.6.0+cu124\u001b[0m\u001b[1;32m \u001b[0m \u001b[1;33m \u001b[0m\u001b[1;33m✅ Available\u001b[0m\u001b[1;33m \u001b[0m \n",
       " \u001b[1;36m \u001b[0m\u001b[1;36mcupy      \u001b[0m\u001b[1;36m \u001b[0m \u001b[1;32m \u001b[0m\u001b[1;32m13.3.0     \u001b[0m\u001b[1;32m \u001b[0m \u001b[1;33m \u001b[0m\u001b[1;33m✅ Available\u001b[0m\u001b[1;33m \u001b[0m \n",
       "                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Torch GPU available:</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mTorch GPU available:\u001b[0m \u001b[3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Torch device count:</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mTorch device count:\u001b[0m \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Torch CUDA version:</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12.4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mTorch CUDA version:\u001b[0m \u001b[1;36m12.4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">CuPy GPU available:</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mCuPy GPU available:\u001b[0m \u001b[3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">CuPy device count:</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mCuPy device count:\u001b[0m \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Version: 12.6\n",
      "Device Name: NVIDIA RTX A5000\n",
      "Total Memory: 23.68 GB\n",
      "Compute Capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "vbi.test_imports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

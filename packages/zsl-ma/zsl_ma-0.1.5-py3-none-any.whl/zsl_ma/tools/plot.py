# import os
#
# import numpy as np
# import pandas as pd
# import seaborn as sns
# from matplotlib import pyplot as plt, font_manager
# from sklearn.decomposition import PCA
# from sklearn.manifold import TSNE
# from sklearn.metrics import confusion_matrix
#
#
# def _get_times_new_roman_config():
#     """è¾…åŠ©å‡½æ•°ï¼šè·å–Times New Romanå­—ä½“é…ç½®ï¼Œå¤±è´¥åˆ™è¿”å›ç©ºå­—å…¸ï¼ˆç”¨é»˜è®¤å­—ä½“ï¼‰"""
#     target_font = "Times New Roman"
#     font_config = {}
#     try:
#         # æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦å­˜åœ¨ç›®æ ‡å­—ä½“ï¼ˆç”¨'family'å‚æ•°åŒ¹é…FontPropertiesï¼‰
#         font_props = font_manager.FontProperties(family=target_font)
#         font_path = font_manager.findfont(font_props)
#         # éªŒè¯å­—ä½“è·¯å¾„æ˜¯å¦åŒ…å«ç›®æ ‡å­—ä½“ç‰¹å¾ï¼ˆé¿å…è¯¯åŒ¹é…ï¼‰
#         if target_font.lower() in font_path.lower() or "times" in font_path.lower():
#             font_config = {"family": target_font}  # é”®ä¸º'family'ï¼Œé€‚é…FontProperties
#             print(f"âœ… æ£€æµ‹åˆ°Times New Romanå­—ä½“ï¼Œå·²åº”ç”¨")
#     except Exception as e:
#         # æ•è·å­—ä½“ä¸å­˜åœ¨ã€è·¯å¾„æŸ¥æ‰¾å¤±è´¥ç­‰å¼‚å¸¸ï¼Œé™çº§ä¸ºé»˜è®¤å­—ä½“
#         print(f"âš ï¸ æœªæ£€æµ‹åˆ°Times New Romanå­—ä½“ï¼ˆé”™è¯¯ï¼š{str(e)[:50]}ï¼‰ï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—ä½“")
#     return font_config
#
#
# def visualize_mean_features(encoding_path, csv_path, show_feature='æ ‡æ³¨ç±»åˆ«åç§°',
#                             save_fig_path='combined_vis.jpg'):
#     """
#     ä¿®å¤size_maxå‚æ•°é”™è¯¯,å°†ç±»åˆ«ç‰¹å¾å¹³å‡å€¼ä½œä¸ºè™šæ‹Ÿæ ·æœ¬åŠ å…¥åŸå§‹ç‰¹å¾ä¸€èµ·é™ç»´å¯è§†åŒ–
#     é¢å¤–ä¿®å¤ï¼šå›¾ä¾‹title_fontsizeä¸title_fontpropertieså‚æ•°å†²çªï¼Œç»Ÿä¸€ç”¨FontPropertiesé…ç½®æ ‡é¢˜å­—ä½“
#     """
#     # 1. åˆå§‹åŒ–å­—ä½“é…ç½®ï¼ˆä¼˜å…ˆTimes New Romanï¼‰
#     font_config = _get_times_new_roman_config()
#     text_font = font_config.get('family') if font_config else None
#
#     # 2. åŠ è½½æ•°æ®
#     encoding_array = np.load(encoding_path, allow_pickle=True)
#     df = pd.read_csv(csv_path)
#
#     # éªŒè¯æ•°æ®æœ‰æ•ˆæ€§
#     if len(encoding_array) != len(df):
#         raise ValueError("ç‰¹å¾æ ·æœ¬æ•°ä¸CSVè¡Œæ•°ä¸åŒ¹é…")
#     for col in [show_feature, 'å›¾ç‰‡è·¯å¾„']:
#         if col not in df.columns:
#             raise ValueError(f"CSVç¼ºå°‘å¿…è¦åˆ—:{col}")
#
#     # 3. è®¡ç®—æ¯ä¸ªç±»åˆ«çš„ç‰¹å¾å¹³å‡å€¼ï¼ˆä½œä¸º"è™šæ‹Ÿæ ·æœ¬"ï¼‰
#     class_names = df[show_feature].unique().tolist()
#     n_classes = len(class_names)
#     print(f"è®¡ç®— {n_classes} ä¸ªç±»åˆ«çš„ç‰¹å¾å¹³å‡å€¼,ä½œä¸ºè™šæ‹Ÿæ ·æœ¬åŠ å…¥åŸå§‹ç‰¹å¾...")
#
#     mean_feats_list = []
#     mean_labels = []
#     for cls in class_names:
#         cls_feats = encoding_array[df[show_feature] == cls]
#         cls_mean = np.mean(cls_feats, axis=0)
#         mean_feats_list.append(cls_mean)
#         mean_labels.append(cls)
#
#     mean_feats_array = np.array(mean_feats_list)
#     combined_feats = np.vstack([encoding_array, mean_feats_array])
#
#     # 4. å‡†å¤‡åˆå¹¶åçš„æ ‡ç­¾æ•°æ®
#     original_labels = df[show_feature].tolist()
#     original_types = ['åŸå§‹æ ·æœ¬'] * len(original_labels)
#     original_names = df['å›¾ç‰‡è·¯å¾„'].apply(lambda x: x.split('/')[-1]).tolist()
#
#     mean_types = ['å‡å€¼æ ·æœ¬'] * n_classes
#     mean_names = [f"{cls}_å‡å€¼" for cls in class_names]
#
#     combined_labels = original_labels + mean_labels
#     combined_types = original_types + mean_types
#     combined_names = original_names + mean_names
#
#     # 5. TSNEé™ç»´
#     print("å¯¹åˆå¹¶åçš„ç‰¹å¾ï¼ˆåŸå§‹æ ·æœ¬+å‡å€¼æ ·æœ¬ï¼‰è¿›è¡ŒTSNEé™ç»´...")
#     tsne = TSNE(n_components=2, max_iter=20000, random_state=42)
#     combined_tsne_2d = tsne.fit_transform(combined_feats)
#
#     # 6. å‡†å¤‡å¯è§†åŒ–æ•°æ®
#     vis_df = pd.DataFrame({
#         'X': combined_tsne_2d[:, 0],
#         'Y': combined_tsne_2d[:, 1],
#         show_feature: combined_labels,
#         'æ ·æœ¬ç±»å‹': combined_types,
#         'åç§°': combined_names,
#         'å°ºå¯¸æ•°å€¼': [1 if t == 'åŸå§‹æ ·æœ¬' else 5 for t in combined_types]
#     })
#
#     # 7. ç»˜åˆ¶é™æ€å›¾ï¼ˆä¿®å¤å›¾ä¾‹å‚æ•°å†²çªï¼‰
#     plt.figure(figsize=(14, 12), facecolor='white')
#     palette = sns.hls_palette(n_classes)
#     cls_color_map = {cls: palette[i] for i, cls in enumerate(class_names)}
#
#     # ç»˜åˆ¶åŸå§‹æ ·æœ¬
#     original_mask = vis_df['æ ·æœ¬ç±»å‹'] == 'åŸå§‹æ ·æœ¬'
#     for cls in class_names:
#         cls_mask = original_mask & (vis_df[show_feature] == cls)
#         plt.scatter(
#             vis_df.loc[cls_mask, 'X'],
#             vis_df.loc[cls_mask, 'Y'],
#             color=cls_color_map[cls],
#             alpha=0.4,
#             s=30,
#             marker='o',
#             label=cls
#         )
#
#     # ç»˜åˆ¶å‡å€¼æ ·æœ¬+ç±»åˆ«åç§°æ ‡æ³¨
#     mean_mask = vis_df['æ ·æœ¬ç±»å‹'] == 'å‡å€¼æ ·æœ¬'
#     for cls in class_names:
#         cls_mean_mask = mean_mask & (vis_df[show_feature] == cls)
#         # å‡å€¼æ ·æœ¬æ•£ç‚¹
#         plt.scatter(
#             vis_df.loc[cls_mean_mask, 'X'],
#             vis_df.loc[cls_mean_mask, 'Y'],
#             color=cls_color_map[cls],
#             s=400,
#             marker='*',
#             edgecolors='black',
#             linewidths=2,
#             zorder=10
#         )
#         # ç±»åˆ«åç§°æ–‡æœ¬ï¼ˆæ˜¾å¼æŒ‡å®šfontfamilyï¼‰
#         plt.text(
#             vis_df.loc[cls_mean_mask, 'X'].values[0] + 3.0,
#             vis_df.loc[cls_mean_mask, 'Y'].values[0],
#             cls,
#             fontsize=12,
#             fontweight='bold',
#             color=cls_color_map[cls],
#             bbox=dict(facecolor='white', edgecolor='gray', pad=3, alpha=0.8),
#             fontfamily=text_font
#         )
#
#     # å›¾ä¾‹ï¼ˆä¿®å¤å‚æ•°å†²çªï¼šå»æ‰title_fontsizeï¼Œå°†æ ‡é¢˜å­—ä½“å¤§å°åˆå¹¶åˆ°title_fontpropertiesï¼‰
#     plt.legend(
#         title=show_feature,
#         fontsize=10,  # å›¾ä¾‹é¡¹çš„å­—ä½“å¤§å°ï¼ˆéæ ‡é¢˜ï¼‰
#         bbox_to_anchor=(1.05, 1),
#         # å…³é”®ä¿®å¤ï¼šç”¨title_fontpropertiesåŒæ—¶é…ç½®æ ‡é¢˜å­—ä½“å®¶æ—å’Œå¤§å°ï¼Œé¿å…ä¸title_fontsizeå†²çª
#         title_fontproperties=font_manager.FontProperties(
#             family=text_font,
#             size=12  # åŸtitle_fontsize=12çš„åŠŸèƒ½è¿ç§»åˆ°è¿™é‡Œ
#         ) if text_font else font_manager.FontProperties(size=12),
#         # å›¾ä¾‹é¡¹çš„å­—ä½“é…ç½®
#         prop=font_manager.FontProperties(family=text_font, size=10) if text_font else None
#     )
#
#     # è½´åˆ»åº¦ï¼ˆæ˜¾å¼ä¼ é€’fontfamilyï¼‰
#     plt.xticks([], fontfamily=text_font)
#     plt.yticks([], fontfamily=text_font)
#
#     plt.tight_layout()
#     plt.savefig(save_fig_path, dpi=500, bbox_inches='tight')
#     print(f"é™æ€å›¾å·²ä¿å­˜è‡³: {save_fig_path}")
#     plt.close()
#
#
# def npy_dim_reduction_visualization(npy_dir, dim_method="pca", save_path=None):
#     """
#     å¯¹æ–‡ä»¶å¤¹å†…çš„ä»»æ„ä¸€ç»´npyæ–‡ä»¶è¿›è¡Œé™ç»´å¯è§†åŒ–ï¼ˆç»´åº¦ä¸å›ºå®šï¼Œéœ€æ‰€æœ‰æ ·æœ¬ç»´åº¦ä¸€è‡´ï¼‰
#     """
#     # 1. åˆå§‹åŒ–å­—ä½“é…ç½®ï¼ˆä¼˜å…ˆTimes New Romanï¼‰
#     font_config = _get_times_new_roman_config()
#     text_font = font_config.get('family') if font_config else None
#
#     # 2. è¯»å–æ‰€æœ‰npyæ–‡ä»¶
#     npy_files = [f for f in os.listdir(npy_dir) if f.endswith(".npy")]
#     if len(npy_files) == 0:
#         raise FileNotFoundError(f"æ–‡ä»¶å¤¹ {npy_dir} ä¸­æœªæ‰¾åˆ°npyæ–‡ä»¶")
#     if len(npy_files) < 2:
#         raise ValueError(f"è‡³å°‘éœ€è¦2ä¸ªnpyæ–‡ä»¶æ‰èƒ½è¿›è¡Œé™ç»´ï¼Œå½“å‰ä»…æ‰¾åˆ° {len(npy_files)} ä¸ª")
#
#     data_list = []
#     file_labels = []
#     target_dim = None
#
#     for filename in npy_files:
#         file_path = os.path.join(npy_dir, filename)
#         try:
#             data = np.load(file_path, allow_pickle=True).squeeze()
#             if data.ndim != 1:
#                 raise ValueError(f"éä¸€ç»´æ•°æ®ï¼š{filename} ç»´åº¦ä¸º {data.shape}ï¼ˆéœ€ä¸€ç»´æ•°ç»„ï¼‰")
#
#             if target_dim is None:
#                 target_dim = len(data)
#                 print(f"æ£€æµ‹åˆ°æ•°æ®ç»´åº¦ï¼š{target_dim} ç»´ï¼ˆä»¥ {filename} ä¸ºåŸºå‡†ï¼‰")
#             else:
#                 if len(data) != target_dim:
#                     raise ValueError(
#                         f"ç»´åº¦ä¸ä¸€è‡´ï¼š{filename} ä¸º {len(data)} ç»´ï¼Œéœ€ä¸åŸºå‡†ç»´åº¦ {target_dim} ä¸€è‡´"
#                     )
#
#             data_list.append(data)
#             file_labels.append(os.path.splitext(filename)[0])
#
#         except Exception as e:
#             raise RuntimeError(f"å¤„ç†æ–‡ä»¶ {filename} å¤±è´¥ï¼š{str(e)}")
#
#     data_matrix = np.array(data_list)
#     sample_num, feat_dim = data_matrix.shape
#     print(f"æ•°æ®åŠ è½½å®Œæˆï¼šå…± {sample_num} ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬ {feat_dim} ç»´")
#
#     # 3. é™ç»´å¤„ç†
#     if dim_method.lower() == "pca":
#         reducer = PCA(n_components=2, random_state=42)
#         reduced_data = reducer.fit_transform(data_matrix)
#         title_suffix = f"PCAé™ç»´å¯è§†åŒ–ï¼ˆåŸç»´åº¦ï¼š{feat_dim}ï¼‰"
#         explained_var = reducer.explained_variance_ratio_
#         print(
#             f"PCAé™ç»´ç»“æœï¼šç»´åº¦1è§£é‡Š {explained_var[0]:.3f} æ–¹å·®ï¼Œç»´åº¦2è§£é‡Š {explained_var[1]:.3f} æ–¹å·®ï¼ˆç´¯è®¡ï¼š{np.sum(explained_var):.3f}ï¼‰")
#
#     elif dim_method.lower() == "tsne":
#         perplexity = min(max(2, sample_num // 4), sample_num - 1)
#         reducer = TSNE(
#             n_components=2,
#             random_state=42,
#             perplexity=perplexity,
#             init="pca"
#         )
#         reduced_data = reducer.fit_transform(data_matrix)
#         title_suffix = f"t-SNEé™ç»´å¯è§†åŒ–ï¼ˆåŸç»´åº¦ï¼š{feat_dim}ï¼Œperplexity={perplexity}ï¼‰"
#         print(f"t-SNEé™ç»´å®Œæˆï¼ˆè‡ªåŠ¨è®¾ç½®perplexity={perplexity}ï¼Œé€‚é… {sample_num} ä¸ªæ ·æœ¬ï¼‰")
#
#     else:
#         raise ValueError(f"ä¸æ”¯æŒçš„é™ç»´æ–¹æ³• {dim_method}ï¼Œä»…å¯é€‰'pca'æˆ–'tsne'")
#
#     # 4. å¯è§†åŒ–
#     fig, ax = plt.subplots(figsize=(10, 8))
#
#     scatter = ax.scatter(
#         reduced_data[:, 0],
#         reduced_data[:, 1],
#         c=range(sample_num),
#         cmap="tab10" if sample_num <= 10 else "viridis",
#         s=120 if sample_num <= 15 else 80,
#         alpha=0.8,
#         edgecolors="black",
#         linewidth=1
#     )
#
#     # æ ·æœ¬æ ‡ç­¾æ³¨é‡Šï¼ˆæ˜¾å¼ä¼ é€’fontfamilyï¼‰
#     for i, (x, y, label) in enumerate(zip(reduced_data[:, 0], reduced_data[:, 1], file_labels)):
#         ax.annotate(
#             label,
#             xy=(x, y),
#             xytext=(6, 6) if sample_num <= 10 else (4, 4),
#             textcoords="offset points",
#             fontsize=10 if sample_num <= 10 else 8,
#             bbox=dict(boxstyle="round,pad=0.2", facecolor="white", alpha=0.8),
#             fontfamily=text_font
#         )
#
#     # è½´æ ‡ç­¾ï¼ˆæ˜¾å¼ä¼ é€’fontfamilyï¼‰
#     ax.set_xlabel("dim 1", fontsize=12, fontfamily=text_font)
#     ax.set_ylabel("dim 2", fontsize=12, fontfamily=text_font)
#     ax.grid(True, alpha=0.3)
#
#     # é¢œè‰²æ¡æ ‡ç­¾ï¼ˆæ˜¾å¼ä¼ é€’fontfamilyï¼‰
#     cbar = plt.colorbar(scatter, ax=ax)
#     cbar.set_label("sample index", fontsize=10, fontfamily=text_font)
#     cbar.set_ticks(range(sample_num))
#
#     plt.tight_layout()
#
#     if save_path is not None:
#         os.makedirs(os.path.dirname(save_path), exist_ok=True)
#         plt.savefig(save_path, dpi=300, bbox_inches="tight")
#         print(f"å›¾ç‰‡å·²ä¿å­˜è‡³ï¼š{save_path}")
#     else:
#         plt.show()
#
#
# def plot_confusion_matrix(
#         y_true,
#         y_pred,
#         classes,
#         save_path='confusion_matrix.jpg',
#         normalize=False,
#         title='Confusion Matrix',
#         cmap=plt.cm.Blues
# ):
#     """
#     åŠŸèƒ½æ•´åˆç‰ˆæ··æ·†çŸ©é˜µå·¥å…·ï¼š
#     1. è®¡ç®—æ··æ·†çŸ©é˜µï¼ˆæ”¯æŒåŸå§‹è®¡æ•°/æŒ‰çœŸå®ç±»åˆ«å½’ä¸€åŒ–ï¼‰ï¼›
#     2. æ•°å€¼åœ¨æ ¼å­ä¸­æ°´å¹³+å‚ç›´åŒå±…ä¸­ï¼Œé¿å…åä¸Šï¼›
#     3. ä¼˜å…ˆä½¿ç”¨Times New Romanå­—ä½“ï¼ˆç³»ç»Ÿå­˜åœ¨åˆ™åº”ç”¨ï¼Œå¦åˆ™ä¿ç•™é»˜è®¤ï¼‰ï¼›
#     4. è‡ªé€‚åº”ç”»å¸ƒå°ºå¯¸ï¼Œæ— å¤šä½™ç©ºç™½ä¸”æ ‡ç­¾å®Œæ•´æ˜¾ç¤ºã€‚
#     """
#     # 1. åˆå§‹åŒ–å­—ä½“é…ç½®ï¼ˆå¤ç”¨ç»Ÿä¸€é€»è¾‘ï¼‰
#     font_config = _get_times_new_roman_config()
#     text_font = font_config.get('family') if font_config else None
#
#     # 2. è®¡ç®—æ··æ·†çŸ©é˜µ
#     cm = confusion_matrix(
#         y_true=y_true,
#         y_pred=y_pred,
#         labels=np.arange(len(classes))
#     )
#
#     # 3. ç»˜åˆ¶æ··æ·†çŸ©é˜µ
#     base_size = 0.9 if len(classes) <= 6 else (0.7 if len(classes) <= 12 else 0.55)
#     fig = plt.figure(figsize=(len(classes) * base_size, len(classes) * base_size * 0.8))
#
#     if normalize:
#         cm = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis]
#         print(f"ğŸ“Š æ··æ·†çŸ©é˜µå·²å½’ä¸€åŒ–ï¼ˆæŒ‰çœŸå®ç±»åˆ«ï¼‰")
#
#     im = plt.imshow(cm, interpolation="nearest", cmap=cmap)
#     plt.colorbar(im)
#
#     # æ ‡é¢˜ï¼ˆæ˜¾å¼ä¼ é€’fontfamilyï¼‰
#     if title:
#         plt.title(title, fontsize=12, fontfamily=text_font, pad=15)
#
#     # è½´åˆ»åº¦ä¸ç±»åˆ«æ ‡ç­¾ï¼ˆæ˜¾å¼ä¼ é€’fontfamilyï¼‰
#     tick_marks = np.arange(len(classes))
#     plt.xticks(
#         tick_marks, classes,
#         rotation=45 if len(classes) <= 11 else 90,
#         ha="center", fontsize=10, fontfamily=text_font
#     )
#     plt.yticks(tick_marks, classes, fontsize=10, fontfamily=text_font)
#
#     # å•å…ƒæ ¼æ•°å€¼ï¼ˆæ˜¾å¼ä¼ é€’fontfamilyï¼‰
#     fmt = ".2f" if normalize else "d"
#     thresh = cm.max() / 2.
#     for i, j in np.ndindex(cm.shape):
#         plt.text(
#             j, i, format(cm[i, j], fmt),
#             horizontalalignment="center",
#             verticalalignment="center",
#             color="white" if cm[i, j] > thresh else "black",
#             fontsize=10, fontfamily=text_font
#         )
#
#     # è½´æ ‡ç­¾ï¼ˆæ˜¾å¼ä¼ é€’fontfamilyï¼‰
#     plt.ylabel("True Label", fontsize=11, fontfamily=text_font, labelpad=10)
#     plt.xlabel("Predicted Label", fontsize=11, fontfamily=text_font, labelpad=10)
#
#     plt.subplots_adjust(left=0.12, right=0.95, bottom=0.15 if len(classes) <= 8 else 0.2, top=0.88)
#     plt.tight_layout()
#
#     plt.savefig(save_path, dpi=1000, bbox_inches="tight", bbox_extra_artists=[im])
#     plt.close(fig)
#     print(f"ğŸ’¾ æ··æ·†çŸ©é˜µå·²ä¿å­˜è‡³ï¼š{save_path}")

import os

import numpy as np
import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt, font_manager
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.metrics import confusion_matrix


plt.rcParams["font.family"] = 'Times New Roman'
plt.rcParams['axes.unicode_minus'] = False
def visualize_mean_features(encoding_path, csv_path, show_feature='æ ‡æ³¨ç±»åˆ«åç§°',
                            save_fig_path='combined_vis.jpg'):
    """
    ä¿®å¤size_maxå‚æ•°é”™è¯¯,å°†ç±»åˆ«ç‰¹å¾å¹³å‡å€¼ä½œä¸ºè™šæ‹Ÿæ ·æœ¬åŠ å…¥åŸå§‹ç‰¹å¾ä¸€èµ·é™ç»´å¯è§†åŒ–
    Fix size_max parameter error, add category feature averages as virtual samples to original features for dimensionality reduction visualization
    """
    # 1. åŠ è½½æ•°æ®
    # 1. Load data
    encoding_array = np.load(encoding_path, allow_pickle=True)
    df = pd.read_csv(csv_path)

    # éªŒè¯æ•°æ®æœ‰æ•ˆæ€§
    # Verify data validity
    if len(encoding_array) != len(df):
        raise ValueError(
            "ç‰¹å¾æ ·æœ¬æ•°ä¸CSVè¡Œæ•°ä¸åŒ¹é…")  # The number of feature samples does not match the number of CSV rows
    for col in [show_feature, 'å›¾ç‰‡è·¯å¾„']:
        if col not in df.columns:
            raise ValueError(f"CSVç¼ºå°‘å¿…è¦åˆ—:{col}")  # CSV lacks necessary column: {col}

    # 2. è®¡ç®—æ¯ä¸ªç±»åˆ«çš„ç‰¹å¾å¹³å‡å€¼ï¼ˆä½œä¸º"è™šæ‹Ÿæ ·æœ¬"ï¼‰
    # 2. Calculate feature averages for each category (as "virtual samples")
    class_names = df[show_feature].unique().tolist()
    n_classes = len(class_names)
    print(
        f"è®¡ç®— {n_classes} ä¸ªç±»åˆ«çš„ç‰¹å¾å¹³å‡å€¼,ä½œä¸ºè™šæ‹Ÿæ ·æœ¬åŠ å…¥åŸå§‹ç‰¹å¾...")  # Calculating feature averages for {n_classes} categories to add as virtual samples to original features...

    # æŒ‰ç±»åˆ«åˆ†ç»„æ±‚å‡å€¼
    # Calculate averages by category group
    mean_feats_list = []
    mean_labels = []
    for cls in class_names:
        cls_feats = encoding_array[df[show_feature] == cls]
        cls_mean = np.mean(cls_feats, axis=0)
        mean_feats_list.append(cls_mean)
        mean_labels.append(cls)

    # è½¬æ¢ä¸ºæ•°ç»„å¹¶åˆå¹¶
    # Convert to array and merge
    mean_feats_array = np.array(mean_feats_list)
    combined_feats = np.vstack(
        [encoding_array, mean_feats_array])  # åˆå¹¶åŸå§‹ç‰¹å¾ä¸å‡å€¼ç‰¹å¾ (Merge original features with mean features)

    # 3. å‡†å¤‡åˆå¹¶åçš„æ ‡ç­¾æ•°æ®
    # 3. Prepare merged label data
    original_labels = df[show_feature].tolist()
    original_types = ['åŸå§‹æ ·æœ¬'] * len(original_labels)  # 'åŸå§‹æ ·æœ¬' corresponds to "Original Sample"
    original_names = df['å›¾ç‰‡è·¯å¾„'].apply(lambda x: x.split('/')[-1]).tolist()  # 'å›¾ç‰‡è·¯å¾„' corresponds to "Image Path"

    mean_types = ['å‡å€¼æ ·æœ¬'] * n_classes  # 'å‡å€¼æ ·æœ¬' corresponds to "Mean Sample"
    mean_names = [f"{cls}_å‡å€¼" for cls in class_names]  # '_å‡å€¼' corresponds to "_mean"

    combined_labels = original_labels + mean_labels
    combined_types = original_types + mean_types
    combined_names = original_names + mean_names

    # 4. å¯¹åˆå¹¶åçš„ç‰¹å¾è¿›è¡ŒTSNEé™ç»´
    # 4. Perform TSNE dimensionality reduction on combined features
    print(
        "å¯¹åˆå¹¶åçš„ç‰¹å¾ï¼ˆåŸå§‹æ ·æœ¬+å‡å€¼æ ·æœ¬ï¼‰è¿›è¡ŒTSNEé™ç»´...")  # Performing TSNE dimensionality reduction on combined features (original samples + mean samples)...
    tsne = TSNE(n_components=2, max_iter=20000,
                random_state=42)  # æ³¨æ„:sklearn 1.5+ç”¨max_iteræ›¿ä»£n_iter (Note: sklearn 1.5+ uses max_iter instead of n_iter)
    combined_tsne_2d = tsne.fit_transform(combined_feats)

    # 5. å‡†å¤‡å¯è§†åŒ–æ•°æ®ï¼ˆæ–°å¢å°ºå¯¸æ•°å€¼åˆ—ï¼‰
    # 5. Prepare visualization data (add size value column)
    vis_df = pd.DataFrame({
        'X': combined_tsne_2d[:, 0],
        'Y': combined_tsne_2d[:, 1],
        show_feature: combined_labels,
        'æ ·æœ¬ç±»å‹': combined_types,  # 'æ ·æœ¬ç±»å‹' corresponds to "Sample Type"
        'åç§°': combined_names,  # 'åç§°' corresponds to "Name"
        'å°ºå¯¸æ•°å€¼': [1 if t == 'åŸå§‹æ ·æœ¬' else 5 for t in combined_types]
        # åŸå§‹æ ·æœ¬=1,å‡å€¼æ ·æœ¬=5 (Original sample=1, Mean sample=5)
    })

    # 6. ç»˜åˆ¶é™æ€å›¾
    # 6. Draw static graph
    plt.figure(figsize=(14, 12), facecolor='white')
    palette = sns.hls_palette(n_classes)
    cls_color_map = {cls: palette[i] for i, cls in enumerate(class_names)}

    # ç»˜åˆ¶åŸå§‹æ ·æœ¬
    # Draw original samples
    original_mask = vis_df['æ ·æœ¬ç±»å‹'] == 'åŸå§‹æ ·æœ¬'
    for cls in class_names:
        cls_mask = original_mask & (vis_df[show_feature] == cls)
        plt.scatter(
            vis_df.loc[cls_mask, 'X'],
            vis_df.loc[cls_mask, 'Y'],
            color=cls_color_map[cls],
            alpha=0.4,
            s=30,
            marker='o',
            label=cls
        )

    # ç»˜åˆ¶å‡å€¼æ ·æœ¬
    # Draw mean samples
    mean_mask = vis_df['æ ·æœ¬ç±»å‹'] == 'å‡å€¼æ ·æœ¬'
    for i, cls in enumerate(class_names):
        cls_mean_mask = mean_mask & (vis_df[show_feature] == cls)
        plt.scatter(
            vis_df.loc[cls_mean_mask, 'X'],
            vis_df.loc[cls_mean_mask, 'Y'],
            color=cls_color_map[cls],
            s=400,
            marker='*',
            edgecolors='black',
            linewidths=2,
            zorder=10
        )

        # åœ¨å‡å€¼æ ·æœ¬æ—æ·»åŠ ç±»åˆ«åç§°
        # Add category name next to mean sample
        plt.text(
            vis_df.loc[cls_mean_mask, 'X'].values[0] + 3.0,  # xè½´åç§»ä¸€ç‚¹,é¿å…é‡å  (Offset x-axis slightly to avoid overlap)
            vis_df.loc[cls_mean_mask, 'Y'].values[0],  # yè½´å¯¹é½ (Align with y-axis)
            cls,  # ç±»åˆ«åç§° (Category name)
            fontsize=12,
            fontweight='bold',
            color=cls_color_map[cls],
            bbox=dict(facecolor='white', edgecolor='gray', pad=3, alpha=0.8)
            # ç™½è‰²èƒŒæ™¯æ¡†å¢å¼ºå¯è¯»æ€§ (White background box enhances readability)
        )

    # å°†å›¾ä¾‹æ ‡é¢˜æ”¹ä¸ºè‹±æ–‡ï¼ŒåŸä¸­æ–‡æ„æ€ï¼šæ ‡æ³¨ç±»åˆ«åç§°
    # Change legend title to English, original Chinese meaning: "æ ‡æ³¨ç±»åˆ«åç§°" (Annotation Category Name)
    plt.legend(title=show_feature, fontsize=10, title_fontsize=12, bbox_to_anchor=(1.05, 1))
    plt.xticks([])
    plt.yticks([])
    # ç§»é™¤å›¾ç‰‡æ ‡é¢˜ï¼ˆæŒ‰ç…§è¦æ±‚ä¸ç»˜åˆ¶æ ‡é¢˜ï¼‰
    # Remove image title (do not draw title as required)
    plt.tight_layout()
    plt.savefig(save_fig_path, dpi=500, bbox_inches='tight')
    print(f"é™æ€å›¾å·²ä¿å­˜è‡³: {save_fig_path}")  # Static image saved to: {save_fig_path}
    plt.close()


def npy_dim_reduction_visualization(npy_dir, dim_method="pca", save_path=None):
    """
    å¯¹æ–‡ä»¶å¤¹å†…çš„ä»»æ„ä¸€ç»´npyæ–‡ä»¶è¿›è¡Œé™ç»´å¯è§†åŒ–ï¼ˆç»´åº¦ä¸å›ºå®šï¼Œéœ€æ‰€æœ‰æ ·æœ¬ç»´åº¦ä¸€è‡´ï¼‰

    å‚æ•°:
        npy_dir: npyæ–‡ä»¶æ‰€åœ¨æ–‡ä»¶å¤¹è·¯å¾„
        dim_method: é™ç»´æ–¹æ³•ï¼Œå¯é€‰"pca"ï¼ˆé»˜è®¤ï¼‰æˆ–"tsne"
        save_path: å›¾ç‰‡ä¿å­˜è·¯å¾„ï¼ˆå¦‚Noneåˆ™ä¸ä¿å­˜ï¼Œä»…æ˜¾ç¤ºï¼‰
    """
    # 1. è¯»å–æ‰€æœ‰npyæ–‡ä»¶ï¼ŒåŠ¨æ€é€‚é…ç»´åº¦
    npy_files = [f for f in os.listdir(npy_dir) if f.endswith(".npy")]
    if len(npy_files) == 0:
        raise FileNotFoundError(f"æ–‡ä»¶å¤¹ {npy_dir} ä¸­æœªæ‰¾åˆ°npyæ–‡ä»¶")
    if len(npy_files) < 2:
        raise ValueError(f"è‡³å°‘éœ€è¦2ä¸ªnpyæ–‡ä»¶æ‰èƒ½è¿›è¡Œé™ç»´ï¼Œå½“å‰ä»…æ‰¾åˆ° {len(npy_files)} ä¸ª")

    data_list = []
    file_labels = []
    target_dim = None

    for filename in npy_files:
        file_path = os.path.join(npy_dir, filename)
        try:
            data = np.load(file_path, allow_pickle=True).squeeze()
            if data.ndim != 1:
                raise ValueError(f"éä¸€ç»´æ•°æ®ï¼š{filename} ç»´åº¦ä¸º {data.shape}ï¼ˆéœ€ä¸€ç»´æ•°ç»„ï¼‰")

            if target_dim is None:
                target_dim = len(data)
                print(f"æ£€æµ‹åˆ°æ•°æ®ç»´åº¦ï¼š{target_dim} ç»´ï¼ˆä»¥ {filename} ä¸ºåŸºå‡†ï¼‰")
            else:
                if len(data) != target_dim:
                    raise ValueError(
                        f"ç»´åº¦ä¸ä¸€è‡´ï¼š{filename} ä¸º {len(data)} ç»´ï¼Œéœ€ä¸åŸºå‡†ç»´åº¦ {target_dim} ä¸€è‡´"
                    )

            data_list.append(data)
            file_labels.append(os.path.splitext(filename)[0])

        except Exception as e:
            raise RuntimeError(f"å¤„ç†æ–‡ä»¶ {filename} å¤±è´¥ï¼š{str(e)}")

    data_matrix = np.array(data_list)
    sample_num, feat_dim = data_matrix.shape  # è¿™é‡Œå®šä¹‰äº†feat_dimï¼ˆæ¯ä¸ªæ ·æœ¬çš„ç»´åº¦ï¼‰
    print(f"æ•°æ®åŠ è½½å®Œæˆï¼šå…± {sample_num} ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬ {feat_dim} ç»´")

    # 2. é™ç»´å¤„ç†
    if dim_method.lower() == "pca":
        reducer = PCA(n_components=2, random_state=42)
        reduced_data = reducer.fit_transform(data_matrix)
        title_suffix = f"PCAé™ç»´å¯è§†åŒ–ï¼ˆåŸç»´åº¦ï¼š{feat_dim}ï¼‰"
        explained_var = reducer.explained_variance_ratio_
        print(
            f"PCAé™ç»´ç»“æœï¼šç»´åº¦1è§£é‡Š {explained_var[0]:.3f} æ–¹å·®ï¼Œç»´åº¦2è§£é‡Š {explained_var[1]:.3f} æ–¹å·®ï¼ˆç´¯è®¡ï¼š{np.sum(explained_var):.3f}ï¼‰")

    elif dim_method.lower() == "tsne":
        perplexity = min(max(2, sample_num // 4), sample_num - 1)
        reducer = TSNE(
            n_components=2,
            random_state=42,
            perplexity=perplexity,
            init="pca"
        )
        reduced_data = reducer.fit_transform(data_matrix)
        title_suffix = f"t-SNEé™ç»´å¯è§†åŒ–ï¼ˆåŸç»´åº¦ï¼š{feat_dim}ï¼Œperplexity={perplexity}ï¼‰"
        print(f"t-SNEé™ç»´å®Œæˆï¼ˆè‡ªåŠ¨è®¾ç½®perplexity={perplexity}ï¼Œé€‚é… {sample_num} ä¸ªæ ·æœ¬ï¼‰")

    else:
        raise ValueError(f"ä¸æ”¯æŒçš„é™ç»´æ–¹æ³• {dim_method}ï¼Œä»…å¯é€‰'pca'æˆ–'tsne'")

    # 3. å¯è§†åŒ–ï¼ˆä¿®æ­£å˜é‡åé”™è¯¯ï¼‰
    # plt.rcParams["font.sans-serif"] = ["SimHei", "WenQuanYi Zen Hei"]
    # plt.rcParams["axes.unicode_minus"] = False

    fig, ax = plt.subplots(figsize=(10, 8))

    scatter = ax.scatter(
        reduced_data[:, 0],
        reduced_data[:, 1],
        c=range(sample_num),
        cmap="tab10" if sample_num <= 10 else "viridis",
        s=120 if sample_num <= 15 else 80,
        alpha=0.8,
        edgecolors="black",
        linewidth=1
    )

    for i, (x, y, label) in enumerate(zip(reduced_data[:, 0], reduced_data[:, 1], file_labels)):
        ax.annotate(
            label,
            xy=(x, y),
            xytext=(6, 6) if sample_num <= 10 else (4, 4),
            textcoords="offset points",
            fontsize=10 if sample_num <= 10 else 8,
            bbox=dict(boxstyle="round,pad=0.2", facecolor="white", alpha=0.8)
        )

    # å…³é”®ä¿®æ­£ï¼šå°†n_dimæ”¹ä¸ºfeat_dimï¼ˆå·²å®šä¹‰çš„å˜é‡ï¼‰
    # ax.set_title(f"{sample_num}ä¸ª{feat_dim}ç»´npyæ–‡ä»¶-{title_suffix}", fontsize=14, fontweight="bold")
    ax.set_xlabel("dim 1", fontsize=12)
    ax.set_ylabel("dim 2", fontsize=12)
    ax.grid(True, alpha=0.3)

    cbar = plt.colorbar(scatter, ax=ax)
    cbar.set_label("smple idex", fontsize=10)
    cbar.set_ticks(range(sample_num))

    plt.tight_layout()

    if save_path is not None:
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        plt.savefig(save_path, dpi=300, bbox_inches="tight")
        print(f"å›¾ç‰‡å·²ä¿å­˜è‡³ï¼š{save_path}")
    else:
        plt.show()


def plot_confusion_matrix(
        y_true,
        y_pred,
        classes,
        save_path='confusion_matrix.jpg',
        normalize=False,
        title='Confusion Matrix',
        cmap=plt.cm.Blues
):
    """
    åŠŸèƒ½æ•´åˆç‰ˆæ··æ·†çŸ©é˜µå·¥å…·ï¼š
    1. è®¡ç®—æ··æ·†çŸ©é˜µï¼ˆæ”¯æŒåŸå§‹è®¡æ•°/æŒ‰çœŸå®ç±»åˆ«å½’ä¸€åŒ–ï¼‰ï¼›
    2. æ•°å€¼åœ¨æ ¼å­ä¸­æ°´å¹³+å‚ç›´åŒå±…ä¸­ï¼Œé¿å…åä¸Šï¼›
    3. ä¼˜å…ˆä½¿ç”¨Times New Romanå­—ä½“ï¼ˆç³»ç»Ÿå­˜åœ¨åˆ™åº”ç”¨ï¼Œå¦åˆ™ä¿ç•™é»˜è®¤ï¼‰ï¼›
    4. è‡ªé€‚åº”ç”»å¸ƒå°ºå¯¸ï¼Œæ— å¤šä½™ç©ºç™½ä¸”æ ‡ç­¾å®Œæ•´æ˜¾ç¤ºã€‚

    å‚æ•°ï¼š
        y_true: çœŸå®æ ‡ç­¾ï¼ˆarray-likeï¼Œå½¢çŠ¶(n_samples,)ï¼‰
        y_pred: é¢„æµ‹æ ‡ç­¾ï¼ˆarray-likeï¼Œä¸y_trueå½¢çŠ¶ä¸€è‡´ï¼‰
        classes: ç±»åˆ«åç§°åˆ—è¡¨ï¼ˆlistï¼Œä¸æ ‡ç­¾ç´¢å¼•ä¸€ä¸€å¯¹åº”ï¼‰
        save_path: å›¾åƒä¿å­˜è·¯å¾„ï¼ˆé»˜è®¤'confusion_matrix.jpg'ï¼‰
        normalize: æ˜¯å¦æŒ‰çœŸå®ç±»åˆ«ï¼ˆè¡Œï¼‰å½’ä¸€åŒ–ï¼ˆé»˜è®¤Falseï¼‰
        title: æ··æ·†çŸ©é˜µæ ‡é¢˜ï¼ˆé»˜è®¤'Confusion Matrix'ï¼‰
        cmap: é¢œè‰²æ˜ å°„ï¼ˆé»˜è®¤plt.cm.Bluesï¼Œå¯æ¢'viridis'ç­‰ï¼‰

    è¿”å›ï¼š
        np.ndarray: è®¡ç®—åçš„æ··æ·†çŸ©é˜µï¼ˆåŸå§‹/å½’ä¸€åŒ–ï¼‰
    """

    # -------------------------- 2. è®¡ç®—æ··æ·†çŸ©é˜µï¼ˆç¡®ä¿ç±»åˆ«é¡ºåºä¸classesä¸€è‡´ï¼‰ --------------------------
    cm = confusion_matrix(
        y_true=y_true,
        y_pred=y_pred,
        labels=np.arange(len(classes))  # æ ‡ç­¾ç´¢å¼•åŒ¹é…classesé•¿åº¦
    )

    # -------------------------- 3. ç»˜åˆ¶æ··æ·†çŸ©é˜µï¼ˆæ•´åˆæ‰€æœ‰ä¼˜åŒ–ï¼‰ --------------------------
    # è‡ªé€‚åº”ç”»å¸ƒï¼šç±»åˆ«è¶Šå¤šï¼Œå•ä½å°ºå¯¸è¶Šå°ï¼Œé¿å…æ•´ä½“è¿‡å¤§/è¿‡å°
    base_size = 0.9 if len(classes) <= 6 else (0.7 if len(classes) <= 12 else 0.55)
    fig = plt.figure(figsize=(len(classes) * base_size, len(classes) * base_size * 0.8))

    # å½’ä¸€åŒ–å¤„ç†ï¼ˆæŒ‰çœŸå®ç±»åˆ«è¡Œæ±‚å’Œå½’ä¸€åŒ–ï¼‰
    if normalize:
        cm = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis]
        print(f"ğŸ“Š æ··æ·†çŸ©é˜µå·²å½’ä¸€åŒ–ï¼ˆæŒ‰çœŸå®ç±»åˆ«ï¼‰")

    # ç»˜åˆ¶çŸ©é˜µä¸»ä½“
    im = plt.imshow(cm, interpolation="nearest", cmap=cmap)
    plt.colorbar(im)  # é¢œè‰²æ¡ï¼ˆè¾…åŠ©ç†è§£æ•°å€¼ä¸é¢œè‰²å¯¹åº”ï¼‰

    # æ ‡é¢˜ï¼šåº”ç”¨å­—ä½“é…ç½®ï¼Œæ§åˆ¶å­—ä½“å¤§å°
    if title:
        plt.title(title, fontsize=12, pad=15)

    # åˆ»åº¦ä¸ç±»åˆ«æ ‡ç­¾ï¼šæ—‹è½¬Xè½´æ ‡ç­¾é¿å…é‡å ï¼Œåº”ç”¨å­—ä½“
    tick_marks = np.arange(len(classes))
    plt.xticks(
        tick_marks, classes,
        rotation=45 if len(classes) <= 11 else 90,  # ç±»åˆ«å¤šåˆ™ç«–æ’æ ‡ç­¾
        ha="center", fontsize=10
    )
    plt.yticks(tick_marks, classes, fontsize=10)

    # å•å…ƒæ ¼æ•°å€¼ï¼šæ°´å¹³+å‚ç›´åŒå±…ä¸­ï¼ŒæŒ‰èƒŒæ™¯è‰²é€‚é…æ–‡å­—è‰²
    fmt = ".2f" if normalize else "d"  # å½’ä¸€åŒ–æ˜¾ç¤º2ä½å°æ•°ï¼ŒåŸå§‹æ˜¾ç¤ºæ•´æ•°
    thresh = cm.max() / 2.  # é˜ˆå€¼ï¼šåŒºåˆ†æ·±è‰²/æµ…è‰²èƒŒæ™¯
    for i, j in np.ndindex(cm.shape):
        plt.text(
            j, i, format(cm[i, j], fmt),
            horizontalalignment="center",  # æ°´å¹³å±…ä¸­
            verticalalignment="center",  # å‚ç›´å±…ä¸­ï¼ˆè§£å†³åä¸Šé—®é¢˜ï¼‰
            color="white" if cm[i, j] > thresh else "black",
            fontsize=10  # æ•°å€¼å­—ä½“ç¨å°ï¼Œé¿å…æ‹¥æŒ¤
        )

    # è½´æ ‡ç­¾ï¼šåº”ç”¨å­—ä½“ï¼Œè°ƒæ•´ä½ç½®é¿å…æˆªæ–­
    plt.ylabel("True Label", fontsize=11, labelpad=10)
    plt.xlabel("Predicted Label", fontsize=11, labelpad=10)

    # ç²¾å‡†è°ƒæ•´è¾¹è·ï¼šç¡®ä¿æ— å¤šä½™ç©ºç™½ï¼Œæ ‡ç­¾å®Œæ•´
    plt.subplots_adjust(left=0.12, right=0.95, bottom=0.15 if len(classes) <= 8 else 0.2, top=0.88)
    plt.tight_layout()

    # ä¿å­˜é«˜åˆ†è¾¨ç‡å›¾åƒï¼ˆè‡ªåŠ¨è£å‰ªè¾¹ç¼˜ç©ºç™½ï¼‰
    plt.savefig(save_path, dpi=500, bbox_inches="tight", bbox_extra_artists=[im])
    plt.close(fig)
    print(f"ğŸ’¾ æ··æ·†çŸ©é˜µå·²ä¿å­˜è‡³ï¼š{save_path}")
